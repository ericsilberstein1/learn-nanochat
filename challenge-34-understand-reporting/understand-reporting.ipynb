{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b57e7e-db21-4ad1-8c87-5a409cf9b10b",
   "metadata": {},
   "source": [
    "## Understand and add reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea7a6c-6200-4301-bae2-50a672af9b15",
   "metadata": {},
   "source": [
    "All along I've been skipping the code that logs metrics to reports. I want to now look at what his reporting thing is and then go back to the train scripts and I think the eval scripts too and add the reporting. I hope this will reduce the pain (and risk of making errors) I've had after the last few runs of scrolling through logs in my notebooks and/or wandb to pull out accuracy numbers, validation loss numbers, etc.\n",
    "\n",
    "I'm making the headings in this notebook <span style='color:green'>green</span> to distinguish from the report headings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6f16d-ff79-4cf7-881f-3f3b4605ba93",
   "metadata": {},
   "source": [
    "### <span style='color:green'>Report.py</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417119b-58dd-41f8-babe-43a8c27479e4",
   "metadata": {},
   "source": [
    "Look at [report.py](https://github.com/karpathy/nanochat/blob/master/nanochat/report.py)\n",
    "\n",
    "It gets git info. That make sense. What is `git status --porcelain`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452ae362-ea40-4493-801b-d20e8f48e84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " M readme.md\n",
      "?? challenge-34-understand-reporting/\n",
      "?? scratch.ipynb\n",
      "?? scratch.txt\n"
     ]
    }
   ],
   "source": [
    "!git status --porcelain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6041af67-3c34-4935-9e0e-0aff91368983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       --show-stash\n",
      "           Show the number of entries currently stashed away.\n",
      "\n",
      "       --porcelain[=<version>]\n",
      "           Give the output in an easy-to-parse format for scripts. This is\n",
      "           similar to the short output, but will remain stable across Git\n",
      "           versions and regardless of user configuration. See below for\n",
      "--\n",
      "           ## branchname tracking info\n",
      "\n",
      "   Porcelain Format Version 1\n",
      "       Version 1 porcelain format is similar to the short format, but is\n",
      "       guaranteed not to change in a backwards-incompatible way between Git\n",
      "       versions or based on user configuration. This makes it ideal for\n",
      "       parsing by scripts. The description of the short format above also\n",
      "       describes the porcelain format, with a few exceptions:\n",
      "\n",
      "        1. The userâ€™s color.status configuration is not respected; color will\n",
      "           always be off.\n"
     ]
    }
   ],
   "source": [
    "!git status --help | grep -C 3 porcelain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55255611-1fe7-4de5-b627-e4fce8661678",
   "metadata": {},
   "source": [
    "So that's why it's called porcelain.\n",
    "\n",
    "Good reminder to add my scratch files to .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb3e802-c090-485b-9e6a-0033330fa870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " M .gitignore\n",
      " M readme.md\n",
      "?? challenge-34-understand-reporting/\n"
     ]
    }
   ],
   "source": [
    "!git status --porcelain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259b4cb-e9dd-4146-8f09-1ac4dbf2b8da",
   "metadata": {},
   "source": [
    "Looks like it also records a bunch of system info, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c16ea8-3663-45e3-bcf9-5b65bea4a934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Darwin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb681ea-d479-4854-967f-64474872cecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.cpu_count(logical=False), psutil.cpu_count(logical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7bbdf7-15e9-484c-b8fd-d5e28e4c1e73",
   "metadata": {},
   "source": [
    "Didn't realize my laptop is considered to have 8 physical CPUs. I guess those are CPU cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08a2992-39e4-4b0e-9ef4-20cc4398e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw.physicalcpu: 8\n",
      "hw.logicalcpu: 8\n"
     ]
    }
   ],
   "source": [
    "!sysctl hw.physicalcpu hw.logicalcpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e161ab5-c3b7-4bb5-b2a0-b19a700e2e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Chip: Apple M1\n"
     ]
    }
   ],
   "source": [
    "!system_profiler SPHardwareDataType | grep -i chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c0791e7-5023-466d-8420-6982626f365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Total Number of Cores: 8 (4 performance and 4 efficiency)\n"
     ]
    }
   ],
   "source": [
    "!system_profiler SPHardwareDataType | grep -i core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb018b0d-ef0b-4320-8f93-1820cddcb460",
   "metadata": {},
   "source": [
    "What is this `files-to-prompt` thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68520e7b-e981-4921-b046-6cf6b8f6808d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: files-to-prompt\n"
     ]
    }
   ],
   "source": [
    "!files-to-prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c125a-af0d-48cb-8f97-2d401ddc2875",
   "metadata": {},
   "source": [
    "Oh, it's a Simon Willison tool: https://github.com/simonw/files-to-prompt\n",
    "\n",
    "```\n",
    "Concatenate a directory full of files into a single prompt for use with LLMs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271d4d5-5b6a-4778-abdc-f1708549a6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe0db384-372b-4fba-a428-d3a55720794e",
   "metadata": {},
   "source": [
    "ok, I get the idea of this reporting stuff. It creates reports as markdown files and writes them to the `report` folder and also assembles a final report. I'll go ahead and copy most of it but I don't think by itself it's going to solve all my pain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80339339-95fc-491e-9c64-134d8a59fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_report import get_git_info, get_gpu_info, get_system_info, generate_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "034da1ef-ad1c-4e80-b88c-3dbf48f5b9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'commit': '33da382',\n",
       " 'branch': 'master',\n",
       " 'dirty': True,\n",
       " 'message': 'started and finished (?) challenge 33: add chat CLI'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_git_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3d884b-0fe2-450b-8d84-dc47eaa8c7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'available': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gpu_info() # will be more interesting on a machine with GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda4d38f-d534-4916-be74-b9ec79a54bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hostname': 'Erics-MacBook-Air-2.local',\n",
       " 'platform': 'Darwin',\n",
       " 'python_version': '3.10.18',\n",
       " 'torch_version': '2.9.0',\n",
       " 'cpu_count': 8,\n",
       " 'cpu_count_logical': 8,\n",
       " 'memory_gb': 16.0,\n",
       " 'user': 'ericsilberstein',\n",
       " 'nanochat_base_dir': 'out',\n",
       " 'working_dir': '/Users/ericsilberstein/Documents/ericsilberstein1-repos/learn-nanochat/challenge-34-understand-reporting'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_system_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa8cde-abc3-474f-96a9-a5a2c7372e40",
   "metadata": {},
   "source": [
    "Going to skip the cost and bloat stuff for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b866aa0-6f4e-4ded-b137-c06b04369a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# nanochat training report\n",
       "\n",
       "Generated: 2025-11-24 10:40:33\n",
       "\n",
       "## Environment\n",
       "\n",
       "### Git Information\n",
       "- Branch: master\n",
       "- Commit: 33da382 (dirty)\n",
       "- Message: started and finished (?) challenge 33: add chat CLI\n",
       "\n",
       "### Hardware\n",
       "- Platform: Darwin\n",
       "- CPUs: 8 cores (8 logical)\n",
       "- Memory: 16.0 GB\n",
       "- GPUs: None available\n",
       "\n",
       "### Software\n",
       "- Python: 3.10.18\n",
       "- PyTorch: 2.9.0\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(generate_header())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f0079-5e06-4167-b75a-f8e5efa89e9d",
   "metadata": {},
   "source": [
    "Looking at functions `extract()` and `extract_timestamp()`...so we'll be reading from markdown reports we wrote previously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dee84dea-ba94-4e5d-a089-5c073e83d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_report import get_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9870d8de-a8d2-4d5d-9c8b-74f2e60ca764",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = get_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85d6eb7d-b03b-4453-9d9e-491eb3c0580a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ericsilberstein/.cache/my_nanochat/report/test-report.md'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = report.log('test report', ['hello\\n', {'a': 1.2345, 'b': 12_345, 'c': 12}])\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969be3c9-1944-4e62-ba8c-ae014c8d6f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## test report\n",
      "timestamp: 2025-11-24 12:16:34\n",
      "\n",
      "hello\n",
      "- a: 1.2345\n",
      "- b: 12,345\n",
      "- c: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat {file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1df01d97-3c0e-4130-8960-1a8b83787f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm {file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc74513-ab03-42a0-ad09-4b5e74bf801b",
   "metadata": {},
   "source": [
    "Will also skip `report.generate()` for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7c94e29-057c-409c-bce0-8de54e1f2b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'a', 'b', 'd', 'c']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(['a', 'b', 'c', 'd', 'e'], key=lambda x: (x != 'e', x == 'c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9131055d-1a89-470c-b774-2a0caa0e995b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a vs b\n",
    "(True, False) == (True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "905e2e3d-678f-4165-a54b-df2a92a15ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c vs d\n",
    "(True, True) > (True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3a85c6c-bad2-402f-a5cb-64d107f03e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(10, 5) > (9, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccdd5464-07ea-471c-9eea-4f6722cc161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_report import get_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec16cdc-9b16-4d21-8853-f5e83b9c090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report to /Users/ericsilberstein/.cache/my_nanochat/report/report.md\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/header.md does not exist. Did you forget to run `nanochat reset`?\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/tokenizer-training.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/tokenizer-evaluation.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/base-model-training.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/base-model-loss.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/base-model-evaluation.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/midtraining.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-evaluation-mid.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-sft.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-evaluation-sft.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-rl.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-evaluation-rl.md does not exist, skipping\n",
      "Copying report.md to current directory for convenience\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/ericsilberstein/.cache/my_nanochat/report/report.md'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = get_report()\n",
    "report.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c65b04e-dd0f-43ba-99fe-7d4dbe4ab9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Summary\n",
      "\n",
      "| Metric          | BASE     | MID      | SFT      | RL       |\n",
      "|-----------------|----------|----------|----------|----------|\n",
      "\n",
      "Total wall clock time: unknown\n"
     ]
    }
   ],
   "source": [
    "!cat report.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6594559-dfc1-4488-ac52-a8047fd4b9b5",
   "metadata": {},
   "source": [
    "Now go back to all the train and eval scripts and write reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041c6d9-43a2-43db-919f-98e3d78d8b14",
   "metadata": {},
   "source": [
    "### <span style='color:green'>my_base_train.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07831c23-ced8-49a1-8c26-ca99f2b61def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74074f01-8f8d-465c-9b30-950d9d6a975d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding depth = 1\n",
      "overriding max_seq_len = 256\n",
      "overriding device_batch_size = 1\n",
      "overriding num_iterations = 10\n",
      "overriding total_batch_size = 256\n",
      "overriding eval_every = 5\n",
      "overriding eval_tokens = 1280\n",
      "overriding core_metric_every = 20\n",
      "overriding core_metric_max_per_task = 11\n",
      "overriding sample_every = 5\n",
      "user_config: {'run': 'dummy', 'device_type': '', 'depth': 1, 'max_seq_len': 256, 'num_iterations': 10, 'target_param_data_ratio': 20, 'device_batch_size': 1, 'total_batch_size': 256, 'embedding_lr': 0.2, 'unembedding_lr': 0.004, 'weight_decay': 0.0, 'matrix_lr': 0.02, 'grad_clip': 1.0, 'warmup_ratio': 0.0, 'warmdown_ratio': 0.2, 'final_lr_frac': 0.0, 'eval_every': 5, 'eval_tokens': 1280, 'core_metric_every': 20, 'core_metric_max_per_task': 11, 'sample_every': 5, 'model_tag': ''}\n",
      "Autodetected device type: mps\n",
      "This process is ddp_rank: 0, ddp_local_rank: 0, ddp_world_size: 1\n",
      "Vocab size: 65,536\n",
      "num_layers: 1\n",
      "model_dim: 64\n",
      "num_heads: 1\n",
      "num_kv_heads: 1\n",
      "Tokens / micro-batch / rank: 1 x 256 = 256\n",
      "Tokens / micro-batch: 256\n",
      "Total batch size 256 => gradient accumulation steps: 1\n",
      "GPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(65536, 64)\n",
      "    (h): ModuleList(\n",
      "      (0): Block(\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_q): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (c_k): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (c_v): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (c_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        )\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=64, out_features=256, bias=False)\n",
      "          (c_proj): Linear(in_features=256, out_features=64, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=64, out_features=65536, bias=False)\n",
      ")\n",
      "Number of parameters: 8,437,760\n",
      "Using user-provided number of iterations: 10\n",
      "Total number of training tokens: 2,560\n",
      "tokens : param ratio: 0.00 (he has note that Chinchilla is ~20)\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(64/768) = 3.464101615137755\n",
      "x.shape is [1, 256], y.shape is [1, 256] -- should match\n",
      "step 00000 | Validation bpb: 3.7003\n",
      "step 00000/00010 (0.00%) | loss: 11.090355 | grad norm: 0.5497 | lrm: 1.00 | dt: 717.16ms | tok/sec: 356 | mfu: -1.00 | total time: 0.00m\n",
      "step 00001/00010 (10.00%) | loss: 11.057328 | grad norm: 0.7747 | lrm: 1.00 | dt: 65.82ms | tok/sec: 3,889 | mfu: -1.00 | total time: 0.00m\n",
      "step 00002/00010 (20.00%) | loss: 11.011871 | grad norm: 0.8687 | lrm: 1.00 | dt: 58.00ms | tok/sec: 4,414 | mfu: -1.00 | total time: 0.00m\n",
      "step 00003/00010 (30.00%) | loss: 10.879259 | grad norm: 1.4716 | lrm: 1.00 | dt: 60.79ms | tok/sec: 4,211 | mfu: -1.00 | total time: 0.00m\n",
      "step 00004/00010 (40.00%) | loss: 10.726487 | grad norm: 1.7633 | lrm: 1.00 | dt: 62.72ms | tok/sec: 4,081 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005 | Validation bpb: 3.5498\n",
      "<|bos|>The capital of France is a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>The chemical symbol of gold is a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>If yesterday was Friday, then tomorrow will be a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>The opposite of hot is a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>The planets of the solar system are: at consideration transport the a longer\u0000 transport the a\n",
      "<|bos|>My favorite color is a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>If 5*x + 3 = 13, then x is a longer\u0000 transport the a longer\u0000 transport the\n",
      "step 00005/00010 (50.00%) | loss: 10.543755 | grad norm: 2.1503 | lrm: 1.00 | dt: 64.38ms | tok/sec: 3,976 | mfu: -1.00 | total time: 0.00m\n",
      "step 00006/00010 (60.00%) | loss: 10.498976 | grad norm: 2.4803 | lrm: 1.00 | dt: 56.82ms | tok/sec: 4,505 | mfu: -1.00 | total time: 0.00m\n",
      "step 00007/00010 (70.00%) | loss: 10.468405 | grad norm: 3.2435 | lrm: 1.00 | dt: 60.71ms | tok/sec: 4,216 | mfu: -1.00 | total time: 0.00m\n",
      "step 00008/00010 (80.00%) | loss: 10.357531 | grad norm: 3.0448 | lrm: 1.00 | dt: 63.62ms | tok/sec: 4,023 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009/00010 (90.00%) | loss: 10.180822 | grad norm: 3.0164 | lrm: 0.50 | dt: 70.10ms | tok/sec: 3,651 | mfu: -1.00 | total time: 0.00m\n",
      "step 00010 | Validation bpb: 3.3075\n",
      "Evaluating: hellaswag_zeroshot (0-shot, type: multiple_choice)... accuracy: 0.4545 | centered: 0.2727 | time: 0.82s\n",
      "Evaluating: jeopardy (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.38s\n",
      "Evaluating: bigbench_qa_wikidata (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.25s\n",
      "Evaluating: arc_easy (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.2121 | time: 1.80s\n",
      "Evaluating: arc_challenge (10-shot, type: multiple_choice)... accuracy: 0.0000 | centered: -0.3333 | time: 3.03s\n",
      "Evaluating: copa (0-shot, type: multiple_choice)... accuracy: 0.7273 | centered: 0.4545 | time: 0.44s\n",
      "Evaluating: commonsense_qa (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.1364 | time: 2.30s\n",
      "Evaluating: piqa (10-shot, type: multiple_choice)... accuracy: 0.4545 | centered: -0.0909 | time: 2.26s\n",
      "Evaluating: openbook_qa (0-shot, type: multiple_choice)... accuracy: 0.3636 | centered: 0.1515 | time: 0.66s\n",
      "Evaluating: lambada_openai (0-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.52s\n",
      "Evaluating: hellaswag (10-shot, type: multiple_choice)... accuracy: 0.4545 | centered: 0.2727 | time: 5.46s\n",
      "Evaluating: winograd (0-shot, type: schema)... accuracy: 0.5455 | centered: 0.0909 | time: 0.27s\n",
      "Evaluating: winogrande (0-shot, type: schema)... accuracy: 0.4545 | centered: -0.0909 | time: 0.27s\n",
      "Evaluating: bigbench_dyck_languages (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.54s\n",
      "Evaluating: agi_eval_lsat_ar (3-shot, type: multiple_choice)... accuracy: 0.2727 | centered: 0.0909 | time: 4.79s\n",
      "Evaluating: bigbench_cs_algorithms (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.80s\n",
      "Evaluating: bigbench_operators (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.60s\n",
      "Evaluating: bigbench_repeat_copy_logic (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.89s\n",
      "Evaluating: squad (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 2.36s\n",
      "Evaluating: coqa (0-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 1.44s\n",
      "Evaluating: boolq (10-shot, type: multiple_choice)... accuracy: 0.3636 | centered: -0.6746 | time: 4.46s\n",
      "Evaluating: bigbench_language_identification (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.0001 | time: 7.02s\n",
      "Step 00010: CORE metric: -0.0093\n",
      "<|bos|>The capital of France is the the the the the the the the the the\n",
      "<|bos|>The chemical symbol of gold is the the the the the the the the the the\n",
      "<|bos|>If yesterday was Friday, then tomorrow will be the the the the the the the the the the\n",
      "<|bos|>The opposite of hot is the the the the the the the the the the\n",
      "<|bos|>The planets of the solar system are:\u0000 the the the the the the the the the\n",
      "<|bos|>My favorite color is the the the the the the the the the the\n",
      "<|bos|>If 5*x + 3 = 13, then x is the the the the the the the the the the\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1/model_000010.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1/meta_000010.json\n",
      "saved optimizer to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1/optim_000010_rank0.pt\n",
      "Peak memory usage: 0.00MiB\n",
      "Total training time: 0.00m\n",
      "Minimum validation bpb: 3.3075\n"
     ]
    }
   ],
   "source": [
    "# need to use depth=1 so all the CORE metrics can be evaluted on my mac without OOM - see challenge 21\n",
    "!python -m scripts.my_base_train \\\n",
    "    --depth=1 \\\n",
    "    --max_seq_len=256 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --num_iterations=10 \\\n",
    "    --total_batch_size=256 \\\n",
    "    --eval_every=5 \\\n",
    "    --eval_tokens=1280 \\\n",
    "    --core_metric_every=20 \\\n",
    "    --core_metric_max_per_task=11 \\\n",
    "    --sample_every=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7d699af-0f5b-45ef-899b-d05e054a7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "from my_nanochat.my_common import get_base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "956b048b-afab-4135-aee9-40fffdc09964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base-model-training.md report.md\n"
     ]
    }
   ],
   "source": [
    "!ls {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8936feff-44af-4c57-948a-b5e9ecb53e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Base model training\n",
       "timestamp: 2025-11-24 15:34:09\n",
       "\n",
       "- run: dummy\n",
       "- device_type: \n",
       "- depth: 1\n",
       "- max_seq_len: 256\n",
       "- num_iterations: 10\n",
       "- target_param_data_ratio: 20\n",
       "- device_batch_size: 1\n",
       "- total_batch_size: 256\n",
       "- embedding_lr: 0.2000\n",
       "- unembedding_lr: 0.0040\n",
       "- weight_decay: 0.0000\n",
       "- matrix_lr: 0.0200\n",
       "- grad_clip: 1.0000\n",
       "- warmup_ratio: 0.0000\n",
       "- warmdown_ratio: 0.2000\n",
       "- final_lr_frac: 0.0000\n",
       "- eval_every: 5\n",
       "- eval_tokens: 1280\n",
       "- core_metric_every: 20\n",
       "- core_metric_max_per_task: 11\n",
       "- sample_every: 5\n",
       "- model_tag: \n",
       "- Number of parameters: 8,437,760\n",
       "- Calculated number of iterations: 10\n",
       "- Number of training tokens: 2560\n",
       "- Tokens : Params ratio: 0.0003\n",
       "- DDP world size: 1\n",
       "- warmup_ratio: 0.0000\n",
       "- warmdown_ratio: 0.2000\n",
       "- final_lr_frac: 0.0000\n",
       "- Minimum validation bpb: 3.3075\n",
       "- Final validation bpb: 3.3075\n",
       "- CORE metric estimate: -0.0093\n",
       "- Total training time: 0.00m\n",
       "- Peak memory usage: 0.00MiB\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open(os.path.join(get_base_dir(), 'report', 'base-model-training.md')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60deee87-3116-4c3a-b60a-76f3115bec90",
   "metadata": {},
   "source": [
    "### <span style='color:green'>my_base_eval.py</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667fac9f-c5c2-4555-afc2-ce342e29184e",
   "metadata": {},
   "source": [
    "Here I'll add both logging to a report and writing to a CSV file, both left out earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b323e3b2-473d-4d42-9fbc-4ad3ff8845f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1 with step 10\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "Evaluating: hellaswag_zeroshot (0-shot, type: multiple_choice)... accuracy: 0.4545 | centered: 0.2727 | time: 0.83s\n",
      "Evaluating: jeopardy (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.37s\n",
      "Evaluating: bigbench_qa_wikidata (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.25s\n",
      "Evaluating: arc_easy (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.2121 | time: 2.21s\n",
      "Evaluating: arc_challenge (10-shot, type: multiple_choice)... accuracy: 0.0000 | centered: -0.3333 | time: 2.86s\n",
      "Evaluating: copa (0-shot, type: multiple_choice)... accuracy: 0.7273 | centered: 0.4545 | time: 0.40s\n",
      "Evaluating: commonsense_qa (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.1364 | time: 2.31s\n",
      "Evaluating: piqa (10-shot, type: multiple_choice)... accuracy: 0.4545 | centered: -0.0909 | time: 2.57s\n",
      "Evaluating: openbook_qa (0-shot, type: multiple_choice)... accuracy: 0.3636 | centered: 0.1515 | time: 0.84s\n",
      "Evaluating: lambada_openai (0-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.58s\n",
      "Evaluating: hellaswag (10-shot, type: multiple_choice)... accuracy: 0.4545 | centered: 0.2727 | time: 6.95s\n",
      "Evaluating: winograd (0-shot, type: schema)... accuracy: 0.5455 | centered: 0.0909 | time: 0.39s\n",
      "Evaluating: winogrande (0-shot, type: schema)... accuracy: 0.4545 | centered: -0.0909 | time: 0.29s\n",
      "Evaluating: bigbench_dyck_languages (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.58s\n",
      "Evaluating: agi_eval_lsat_ar (3-shot, type: multiple_choice)... accuracy: 0.2727 | centered: 0.0909 | time: 4.85s\n",
      "Evaluating: bigbench_cs_algorithms (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.71s\n",
      "Evaluating: bigbench_operators (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.58s\n",
      "Evaluating: bigbench_repeat_copy_logic (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 1.16s\n",
      "Evaluating: squad (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 2.25s\n",
      "Evaluating: coqa (0-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 2.12s\n",
      "Evaluating: boolq (10-shot, type: multiple_choice)... accuracy: 0.3636 | centered: -0.6746 | time: 4.43s\n",
      "Evaluating: bigbench_language_identification (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.0001 | time: 8.02s\n",
      "CORE metric: -0.0093\n",
      "centered results:\n",
      "{\n",
      "    \"hellaswag_zeroshot\": 0.2727272907892863,\n",
      "    \"jeopardy\": 0.0,\n",
      "    \"bigbench_qa_wikidata\": 0.0,\n",
      "    \"arc_easy\": -0.21212120850880942,\n",
      "    \"arc_challenge\": -0.3333333333333333,\n",
      "    \"copa\": 0.4545454978942871,\n",
      "    \"commonsense_qa\": -0.13636363297700882,\n",
      "    \"piqa\": -0.09090906381607056,\n",
      "    \"openbook_qa\": 0.15151516596476236,\n",
      "    \"lambada_openai\": 0.0,\n",
      "    \"hellaswag\": 0.2727272907892863,\n",
      "    \"winograd\": 0.09090912342071533,\n",
      "    \"winogrande\": -0.09090906381607056,\n",
      "    \"bigbench_dyck_languages\": 0.0,\n",
      "    \"agi_eval_lsat_ar\": 0.09090910106897353,\n",
      "    \"bigbench_cs_algorithms\": 0.0,\n",
      "    \"bigbench_operators\": 0.0,\n",
      "    \"bigbench_repeat_copy_logic\": 0.0,\n",
      "    \"squad\": 0.0,\n",
      "    \"coqa\": 0.0,\n",
      "    \"boolq\": -0.6746411198063901,\n",
      "    \"bigbench_language_identification\": -0.00010000702046980552\n",
      "}\n",
      "================================================================================\n",
      "Model: base_model (step 10)\n",
      "================================================================================\n",
      "Task                               , Accuracy  , Centered  \n",
      "hellaswag_zeroshot                 , 0.454545  , 0.272727  \n",
      "jeopardy                           , 0.000000  , 0.000000  \n",
      "bigbench_qa_wikidata               , 0.000000  , 0.000000  \n",
      "arc_easy                           , 0.090909  , -0.212121 \n",
      "arc_challenge                      , 0.000000  , -0.333333 \n",
      "copa                               , 0.727273  , 0.454545  \n",
      "commonsense_qa                     , 0.090909  , -0.136364 \n",
      "piqa                               , 0.454545  , -0.090909 \n",
      "openbook_qa                        , 0.363636  , 0.151515  \n",
      "lambada_openai                     , 0.000000  , 0.000000  \n",
      "hellaswag                          , 0.454545  , 0.272727  \n",
      "winograd                           , 0.545455  , 0.090909  \n",
      "winogrande                         , 0.454545  , -0.090909 \n",
      "bigbench_dyck_languages            , 0.000000  , 0.000000  \n",
      "agi_eval_lsat_ar                   , 0.272727  , 0.090909  \n",
      "bigbench_cs_algorithms             , 0.000000  , 0.000000  \n",
      "bigbench_operators                 , 0.000000  , 0.000000  \n",
      "bigbench_repeat_copy_logic         , 0.000000  , 0.000000  \n",
      "squad                              , 0.000000  , 0.000000  \n",
      "coqa                               , 0.000000  , 0.000000  \n",
      "boolq                              , 0.363636  , -0.674641 \n",
      "bigbench_language_identification   , 0.090909  , -0.000100 \n",
      "CORE                               ,           , -0.009320 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_base_eval \\\n",
    "    --model-tag=d1 \\\n",
    "    --source=base \\\n",
    "    --max-per-task=11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aafd87-694a-4a6a-8f3c-fe54c5c193f0",
   "metadata": {},
   "source": [
    "^ Well, that's a lot easier to read! Hopefully see the ugly formatting of negatives once doing this for real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e99927d2-557d-4a46-8758-b38dc990d26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base-model-evaluation.md base-model-training.md   report.md\n"
     ]
    }
   ],
   "source": [
    "!ls {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0247d8db-9488-4c71-965f-67bd873d6b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Base model evaluation\n",
       "timestamp: 2025-11-24 15:58:21\n",
       "\n",
       "- Model: base_model (step 10)\n",
       "- CORE metric: -0.0093\n",
       "- hellaswag_zeroshot: 0.2727\n",
       "- jeopardy: 0.0000\n",
       "- bigbench_qa_wikidata: 0.0000\n",
       "- arc_easy: -0.2121\n",
       "- arc_challenge: -0.3333\n",
       "- copa: 0.4545\n",
       "- commonsense_qa: -0.1364\n",
       "- piqa: -0.0909\n",
       "- openbook_qa: 0.1515\n",
       "- lambada_openai: 0.0000\n",
       "- hellaswag: 0.2727\n",
       "- winograd: 0.0909\n",
       "- winogrande: -0.0909\n",
       "- bigbench_dyck_languages: 0.0000\n",
       "- agi_eval_lsat_ar: 0.0909\n",
       "- bigbench_cs_algorithms: 0.0000\n",
       "- bigbench_operators: 0.0000\n",
       "- bigbench_repeat_copy_logic: 0.0000\n",
       "- squad: 0.0000\n",
       "- coqa: 0.0000\n",
       "- boolq: -0.6746\n",
       "- bigbench_language_identification: -0.0001\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open(os.path.join(get_base_dir(), 'report', 'base-model-evaluation.md')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d90ac-67de-4326-9f17-db23ce9f6869",
   "metadata": {},
   "source": [
    "### <span style='color:green'>my_base_loss.py</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf3049-b1a4-4b2d-a952-00a717df9c91",
   "metadata": {},
   "source": [
    "I never created this script earlier. Will do now so can log loss. See that this script will also calculate loss on the training data with a bigger number of tokens than the training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f0cec64-19d6-4679-bec6-5f2d59de3981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding device_batch_size = 1\n",
      "overriding split_tokens = 2048\n",
      "overriding model_tag = d1\n",
      "user_config: {'device_batch_size': 1, 'split_tokens': 2048, 'device_type': ''}\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1 with step 10\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "train bpb: 1.9768\n",
      "val bpb: 3.1200\n",
      "<|bos|>The capital of France is the the the the the the the the the the the the the the the the\n",
      "<|bos|>The chemical symbol of gold is the the the the the the the the the the the the the the the the\n",
      "<|bos|>If yesterday was Friday, then tomorrow will be the the the the the the the the the the the the the the the the\n",
      "<|bos|>The opposite of hot is the the the the the the the the the the the the the the the the\n",
      "<|bos|>The planets of the solar system are:\u0000 the the the the the the the the the the the the the the the\n",
      "<|bos|>My favorite color is the the the the the the the the the the the the the the the the\n",
      "<|bos|>If 5*x + 3 = 13, then x is the the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_base_loss \\\n",
    "    --device_batch_size=1 \\\n",
    "    --split_tokens=2048 \\\n",
    "    --model_tag=d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b43fe93c-20c9-434f-b1c4-d9578b47fc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base-model-evaluation.md base-model-training.md\n",
      "base-model-loss.md       report.md\n"
     ]
    }
   ],
   "source": [
    "!ls {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd6cf04c-f6ea-4700-8da3-93c34eadab5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Base model loss\n",
       "timestamp: 2025-11-24 16:28:20\n",
       "\n",
       "- train bpb: 1.9768\n",
       "- val bpb: 3.1200\n",
       "- sample 0: <|bos|>The capital of France is the the the the the the the the the the the the the the the the\n",
       "- sample 1: <|bos|>The chemical symbol of gold is the the the the the the the the the the the the the the the the\n",
       "- sample 2: <|bos|>If yesterday was Friday, then tomorrow will be the the the the the the the the the the the the the the the the\n",
       "- sample 3: <|bos|>The opposite of hot is the the the the the the the the the the the the the the the the\n",
       "- sample 4: <|bos|>The planets of the solar system are:\u0000 the the the the the the the the the the the the the the the\n",
       "- sample 5: <|bos|>My favorite color is the the the the the the the the the the the the the the the the\n",
       "- sample 6: <|bos|>If 5*x + 3 = 13, then x is the the the the the the the the the the the the the the the the\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open(os.path.join(get_base_dir(), 'report', 'base-model-loss.md')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e711e66-cc41-41cb-b1cc-3af0fcade406",
   "metadata": {},
   "source": [
    "### <span style='color:green'>my_mid_train.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd6fef15-42af-468e-910e-9821e4ae56af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding model_tag = d1\n",
      "overriding num_iterations = 10\n",
      "overriding max_seq_len = 256\n",
      "overriding device_batch_size = 1\n",
      "overriding total_batch_size = 256\n",
      "overriding eval_every = 5\n",
      "overriding eval_tokens = 1024\n",
      "user_config: {'run': 'dummy', 'device_type': '', 'dtype': 'bfloat16', 'num_iterations': 10, 'max_seq_len': 256, 'device_batch_size': 1, 'unembedding_lr': 0.004, 'embedding_lr': 0.2, 'matrix_lr': 0.02, 'init_lr_frac': 1.0, 'weight_decay': 0.0, 'eval_every': 5, 'eval_tokens': 1024, 'total_batch_size': 256, 'dry_run': 0}\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1 with step 10\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "Tokens / micro-batch / rank: 1 x 256 = 256\n",
      "Tokens / micro-batch: 256\n",
      "Total batch size 256 => gradient accumulation steps: 1\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(64/768) = 3.464101615137755\n",
      "step 00000 | Validation bpb: 2.7541\n",
      "step 00001 (20.00%) | loss: 5.577998 | lrm: 1.00 | dt: 668.83ms | tok/sec: 382 | mfu: -1.00 | total time: 0.00m\n",
      "step 00002 (30.00%) | loss: 6.807689 | lrm: 1.00 | dt: 7.79ms | tok/sec: 32,875 | mfu: -1.00 | total time: 0.00m\n",
      "step 00003 (40.00%) | loss: 7.309566 | lrm: 1.00 | dt: 7.78ms | tok/sec: 32,909 | mfu: -1.00 | total time: 0.00m\n",
      "step 00004 (50.00%) | loss: 7.632079 | lrm: 1.00 | dt: 9.36ms | tok/sec: 27,362 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005 (60.00%) | loss: 7.796334 | lrm: 1.00 | dt: 9.52ms | tok/sec: 26,895 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005 | Validation bpb: 2.4898\n",
      "step 00006 (70.00%) | loss: 7.895180 | lrm: 1.00 | dt: 231.03ms | tok/sec: 1,108 | mfu: -1.00 | total time: 0.00m\n",
      "step 00007 (80.00%) | loss: 8.134184 | lrm: 1.00 | dt: 124.55ms | tok/sec: 2,055 | mfu: -1.00 | total time: 0.00m\n",
      "step 00008 (90.00%) | loss: 8.386306 | lrm: 0.50 | dt: 79.19ms | tok/sec: 3,232 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009 (100.00%) | loss: 8.469028 | lrm: 0.00 | dt: 18.51ms | tok/sec: 13,828 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009 | Validation bpb: 2.3758\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1/model_000009.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1/meta_000009.json\n",
      "saved optimizer to /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1/optim_000009_rank0.pt\n",
      "Peak memory usage: 0.00MiB\n",
      "Total training time: 0.00m\n",
      "Minimum validation bpb: 2.3758\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_mid_train \\\n",
    "    --model_tag=d1 \\\n",
    "    --num_iterations=10 \\\n",
    "    --max_seq_len=256 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --total_batch_size=256 \\\n",
    "    --eval_every=5 \\\n",
    "    --eval_tokens=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a77529e4-16e4-449b-8417-ef4afbaa904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base-model-evaluation.md base-model-training.md   report.md\n",
      "base-model-loss.md       midtraining.md\n"
     ]
    }
   ],
   "source": [
    "!ls {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05ca18a4-c45c-4fd8-9ee9-4ce5ef3903cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Midtraining\n",
       "timestamp: 2025-11-24 16:41:44\n",
       "\n",
       "- run: dummy\n",
       "- device_type: \n",
       "- dtype: bfloat16\n",
       "- num_iterations: 10\n",
       "- max_seq_len: 256\n",
       "- device_batch_size: 1\n",
       "- unembedding_lr: 0.0040\n",
       "- embedding_lr: 0.2000\n",
       "- matrix_lr: 0.0200\n",
       "- init_lr_frac: 1.0000\n",
       "- weight_decay: 0.0000\n",
       "- eval_every: 5\n",
       "- eval_tokens: 1024\n",
       "- total_batch_size: 256\n",
       "- dry_run: 0\n",
       "- Number of iterations: 9\n",
       "- DDP world size: 1\n",
       "- Minimum validation bpb: 2.3758\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open(os.path.join(get_base_dir(), 'report', 'midtraining.md')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d6e2b-8e4c-42a4-8e90-37eaba2050d0",
   "metadata": {},
   "source": [
    "### <span style='color:green'>my_chat_eval.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "260e4a62-73d0-4438-8f7e-57be5c84e2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1 with step 9\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Easy accuracy: 0.00%\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Challenge accuracy: 0.00%\n",
      "final: 2/5 (40.00%)\n",
      "MMLU accuracy: 40.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "GSM8K accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "HumanEval accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "SpellingBee accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_chat_eval \\\n",
    "    --source=mid \\\n",
    "    --batch-size=1 \\\n",
    "    --model-tag=d1 \\\n",
    "    --max-problems=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "347e2551-d3b8-4121-ac98-8cd90282651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base-model-evaluation.md base-model-training.md   midtraining.md\n",
      "base-model-loss.md       chat-evaluation-mid.md   report.md\n"
     ]
    }
   ],
   "source": [
    "!ls {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fc01884-3797-4f50-b336-ac966c6d56c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Chat evaluation mid\n",
       "timestamp: 2025-11-24 16:54:34\n",
       "\n",
       "- source: mid\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 1\n",
       "- model_tag: d1\n",
       "- step: None\n",
       "- max_problems: 5\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.0000\n",
       "- ARC-Challenge: 0.0000\n",
       "- MMLU: 0.4000\n",
       "- GSM8K: 0.0000\n",
       "- HumanEval: 0.0000\n",
       "- SpellingBee: 0.0000\n",
       "- ChatCORE metric: -0.0778\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open(os.path.join(get_base_dir(), 'report', 'chat-evaluation-mid.md')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a584ae6-9c92-40a5-b3c7-18345a850189",
   "metadata": {},
   "source": [
    "### <span style='color:green'>my_chat_sft.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1016bcf6-05d2-4c0c-953f-fb2b400147fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding model_tag = d1\n",
      "overriding num_iterations = 10\n",
      "overriding device_batch_size = 1\n",
      "overriding target_examples_per_step = 4\n",
      "overriding eval_every = 5\n",
      "overriding eval_steps = 10\n",
      "overriding eval_metrics_every = 5\n",
      "overriding eval_metrics_max_problems = 2\n",
      "overriding max_data_tokens = 1280\n",
      "user_config: {'run': 'dummy', 'source': 'mid', 'device_type': '', 'dtype': 'bfloat16', 'device_batch_size': 1, 'num_epochs': 1, 'num_iterations': 10, 'max_data_tokens': 1280, 'target_examples_per_step': 4, 'unembedding_lr': 0.004, 'embedding_lr': 0.2, 'matrix_lr': 0.02, 'weight_decay': 0.0, 'init_lr_frac': 0.02, 'eval_every': 5, 'eval_steps': 10, 'eval_metrics_every': 5, 'eval_metrics_max_problems': 2}\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1 with step 9\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "Target examples per step: 4\n",
      "Device batch size: 1\n",
      "Examples per step is device_batch_size * ddp_world_size: 1\n",
      " => grad accum steps: 4\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(64/768) = 3.464101615137755\n",
      "Step 00000 | Validation loss: 8.715442\n",
      "Step 00000/00010 | Training loss: 10.548104| lrm: 1.000000| num_tokens: 2,365\n",
      "Step 00001/00010 | Training loss: 8.870592| lrm: 0.900000| num_tokens: 2,195\n",
      "Step 00002/00010 | Training loss: 8.670555| lrm: 0.800000| num_tokens: 289\n",
      "Step 00003/00010 | Training loss: 9.800775| lrm: 0.700000| num_tokens: 186\n",
      "Step 00004/00010 | Training loss: 9.199461| lrm: 0.600000| num_tokens: 2,011\n",
      "Step 00005 | Validation loss: 8.676166\n",
      "final: 1/2 (50.00%)\n",
      "final: 0/2 (0.00%)\n",
      "Step 00005 | mmlu_acc: 0.500000, arc_easy_acc: 0.000000\n",
      "Step 00005/00010 | Training loss: 10.114852| lrm: 0.500000| num_tokens: 1,451\n",
      "Step 00006/00010 | Training loss: 8.588468| lrm: 0.400000| num_tokens: 520\n",
      "Step 00007/00010 | Training loss: 10.018353| lrm: 0.300000| num_tokens: 701\n",
      "Step 00008/00010 | Training loss: 10.304161| lrm: 0.200000| num_tokens: 1,347\n",
      "Step 00009 | Validation loss: 8.660782\n",
      "final: 1/2 (50.00%)\n",
      "final: 0/2 (0.00%)\n",
      "Step 00009 | mmlu_acc: 0.500000, arc_easy_acc: 0.000000\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d1/model_000009.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d1/meta_000009.json\n",
      "Saved model checkpoint to /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d1\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_chat_sft \\\n",
    "    --model_tag=d1 \\\n",
    "    --num_iterations=10 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --target_examples_per_step=4 \\\n",
    "    --eval_every=5 \\\n",
    "    --eval_steps=10 \\\n",
    "    --eval_metrics_every=5 \\\n",
    "    --eval_metrics_max_problems=2 \\\n",
    "    --max_data_tokens=1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc3574ca-7221-4209-8326-f1d0b7c2cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base-model-evaluation.md chat-evaluation-mid.md   report.md\n",
      "base-model-loss.md       chat-sft.md\n",
      "base-model-training.md   midtraining.md\n"
     ]
    }
   ],
   "source": [
    "!ls {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebcbd2a8-32de-4f4d-bd77-589122a4f64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Chat SFT\n",
       "timestamp: 2025-11-24 17:33:28\n",
       "\n",
       "- run: dummy\n",
       "- source: mid\n",
       "- device_type: \n",
       "- dtype: bfloat16\n",
       "- device_batch_size: 1\n",
       "- num_epochs: 1\n",
       "- num_iterations: 10\n",
       "- max_data_tokens: 1280\n",
       "- target_examples_per_step: 4\n",
       "- unembedding_lr: 0.0040\n",
       "- embedding_lr: 0.2000\n",
       "- matrix_lr: 0.0200\n",
       "- weight_decay: 0.0000\n",
       "- init_lr_frac: 0.0200\n",
       "- eval_every: 5\n",
       "- eval_steps: 10\n",
       "- eval_metrics_every: 5\n",
       "- eval_metrics_max_problems: 2\n",
       "- Training rows: 22,439\n",
       "- Number of iterations: 10\n",
       "- Training loss: 10.3042\n",
       "- Validation loss: 8.6608\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open(os.path.join(get_base_dir(), 'report', 'chat-sft.md')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888e369-71f2-47d3-860d-891a5962fb2d",
   "metadata": {},
   "source": [
    "Do chat_eval again for sft to get that report written too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "000d49e4-62d2-47dc-8145-a74ee2c59c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d1 with step 9\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Easy accuracy: 0.00%\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Challenge accuracy: 0.00%\n",
      "final: 2/5 (40.00%)\n",
      "MMLU accuracy: 40.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "GSM8K accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "HumanEval accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "SpellingBee accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_chat_eval \\\n",
    "    --source=sft \\\n",
    "    --batch-size=1 \\\n",
    "    --model-tag=d1 \\\n",
    "    --max-problems=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4e88491-865c-47bd-ba1b-8124bc1c442a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base-model-evaluation.md chat-evaluation-mid.md   midtraining.md\n",
      "base-model-loss.md       chat-evaluation-sft.md   report.md\n",
      "base-model-training.md   chat-sft.md\n"
     ]
    }
   ],
   "source": [
    "!ls {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73155388-eb78-4e5d-97fd-716c89eba510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Chat evaluation sft\n",
       "timestamp: 2025-11-24 17:36:54\n",
       "\n",
       "- source: sft\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 1\n",
       "- model_tag: d1\n",
       "- step: None\n",
       "- max_problems: 5\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.0000\n",
       "- ARC-Challenge: 0.0000\n",
       "- MMLU: 0.4000\n",
       "- GSM8K: 0.0000\n",
       "- HumanEval: 0.0000\n",
       "- SpellingBee: 0.0000\n",
       "- ChatCORE metric: -0.0778\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open(os.path.join(get_base_dir(), 'report', 'chat-evaluation-sft.md')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e22e0d-ca68-46a2-81b0-4493cb90f016",
   "metadata": {},
   "source": [
    "### <span style='color:green'>Generate full report</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6027b86-a951-48d4-be9f-c20a065a77e4",
   "metadata": {},
   "source": [
    "Generate the full report again. Add the main part to `my_report.py` first so I run it as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8631dce8-4fb5-406b-9361-29863f976a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report to /Users/ericsilberstein/.cache/my_nanochat/report/report.md\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/header.md does not exist. Did you forget to run `nanochat reset`?\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/tokenizer-training.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/tokenizer-evaluation.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-rl.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-evaluation-rl.md does not exist, skipping\n",
      "Copying report.md to current directory for convenience\n"
     ]
    }
   ],
   "source": [
    "!python -m my_nanochat.my_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5096540b-56aa-4bf5-915b-e1c211a53b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Base model training\n",
       "timestamp: 2025-11-24 15:34:09\n",
       "\n",
       "- run: dummy\n",
       "- device_type: \n",
       "- depth: 1\n",
       "- max_seq_len: 256\n",
       "- num_iterations: 10\n",
       "- target_param_data_ratio: 20\n",
       "- device_batch_size: 1\n",
       "- total_batch_size: 256\n",
       "- embedding_lr: 0.2000\n",
       "- unembedding_lr: 0.0040\n",
       "- weight_decay: 0.0000\n",
       "- matrix_lr: 0.0200\n",
       "- grad_clip: 1.0000\n",
       "- warmup_ratio: 0.0000\n",
       "- warmdown_ratio: 0.2000\n",
       "- final_lr_frac: 0.0000\n",
       "- eval_every: 5\n",
       "- eval_tokens: 1280\n",
       "- core_metric_every: 20\n",
       "- core_metric_max_per_task: 11\n",
       "- sample_every: 5\n",
       "- model_tag: \n",
       "- Number of parameters: 8,437,760\n",
       "- Calculated number of iterations: 10\n",
       "- Number of training tokens: 2560\n",
       "- Tokens : Params ratio: 0.0003\n",
       "- DDP world size: 1\n",
       "- warmup_ratio: 0.0000\n",
       "- warmdown_ratio: 0.2000\n",
       "- final_lr_frac: 0.0000\n",
       "- Minimum validation bpb: 3.3075\n",
       "- Final validation bpb: 3.3075\n",
       "- CORE metric estimate: -0.0093\n",
       "- Total training time: 0.00m\n",
       "- Peak memory usage: 0.00MiB\n",
       "\n",
       "\n",
       "## Base model loss\n",
       "timestamp: 2025-11-24 16:28:20\n",
       "\n",
       "- train bpb: 1.9768\n",
       "- val bpb: 3.1200\n",
       "- sample 0: <|bos|>The capital of France is the the the the the the the the the the the the the the the the\n",
       "- sample 1: <|bos|>The chemical symbol of gold is the the the the the the the the the the the the the the the the\n",
       "- sample 2: <|bos|>If yesterday was Friday, then tomorrow will be the the the the the the the the the the the the the the the the\n",
       "- sample 3: <|bos|>The opposite of hot is the the the the the the the the the the the the the the the the\n",
       "- sample 4: <|bos|>The planets of the solar system are:\u0000 the the the the the the the the the the the the the the the\n",
       "- sample 5: <|bos|>My favorite color is the the the the the the the the the the the the the the the the\n",
       "- sample 6: <|bos|>If 5*x + 3 = 13, then x is the the the the the the the the the the the the the the the the\n",
       "\n",
       "\n",
       "## Base model evaluation\n",
       "timestamp: 2025-11-24 15:58:21\n",
       "\n",
       "- Model: base_model (step 10)\n",
       "- CORE metric: -0.0093\n",
       "- hellaswag_zeroshot: 0.2727\n",
       "- jeopardy: 0.0000\n",
       "- bigbench_qa_wikidata: 0.0000\n",
       "- arc_easy: -0.2121\n",
       "- arc_challenge: -0.3333\n",
       "- copa: 0.4545\n",
       "- commonsense_qa: -0.1364\n",
       "- piqa: -0.0909\n",
       "- openbook_qa: 0.1515\n",
       "- lambada_openai: 0.0000\n",
       "- hellaswag: 0.2727\n",
       "- winograd: 0.0909\n",
       "- winogrande: -0.0909\n",
       "- bigbench_dyck_languages: 0.0000\n",
       "- agi_eval_lsat_ar: 0.0909\n",
       "- bigbench_cs_algorithms: 0.0000\n",
       "- bigbench_operators: 0.0000\n",
       "- bigbench_repeat_copy_logic: 0.0000\n",
       "- squad: 0.0000\n",
       "- coqa: 0.0000\n",
       "- boolq: -0.6746\n",
       "- bigbench_language_identification: -0.0001\n",
       "\n",
       "\n",
       "## Midtraining\n",
       "timestamp: 2025-11-24 16:41:44\n",
       "\n",
       "- run: dummy\n",
       "- device_type: \n",
       "- dtype: bfloat16\n",
       "- num_iterations: 10\n",
       "- max_seq_len: 256\n",
       "- device_batch_size: 1\n",
       "- unembedding_lr: 0.0040\n",
       "- embedding_lr: 0.2000\n",
       "- matrix_lr: 0.0200\n",
       "- init_lr_frac: 1.0000\n",
       "- weight_decay: 0.0000\n",
       "- eval_every: 5\n",
       "- eval_tokens: 1024\n",
       "- total_batch_size: 256\n",
       "- dry_run: 0\n",
       "- Number of iterations: 9\n",
       "- DDP world size: 1\n",
       "- Minimum validation bpb: 2.3758\n",
       "\n",
       "\n",
       "## Chat evaluation mid\n",
       "timestamp: 2025-11-24 16:54:34\n",
       "\n",
       "- source: mid\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 1\n",
       "- model_tag: d1\n",
       "- step: None\n",
       "- max_problems: 5\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.0000\n",
       "- ARC-Challenge: 0.0000\n",
       "- MMLU: 0.4000\n",
       "- GSM8K: 0.0000\n",
       "- HumanEval: 0.0000\n",
       "- SpellingBee: 0.0000\n",
       "- ChatCORE metric: -0.0778\n",
       "\n",
       "\n",
       "## Chat SFT\n",
       "timestamp: 2025-11-24 17:33:28\n",
       "\n",
       "- run: dummy\n",
       "- source: mid\n",
       "- device_type: \n",
       "- dtype: bfloat16\n",
       "- device_batch_size: 1\n",
       "- num_epochs: 1\n",
       "- num_iterations: 10\n",
       "- max_data_tokens: 1280\n",
       "- target_examples_per_step: 4\n",
       "- unembedding_lr: 0.0040\n",
       "- embedding_lr: 0.2000\n",
       "- matrix_lr: 0.0200\n",
       "- weight_decay: 0.0000\n",
       "- init_lr_frac: 0.0200\n",
       "- eval_every: 5\n",
       "- eval_steps: 10\n",
       "- eval_metrics_every: 5\n",
       "- eval_metrics_max_problems: 2\n",
       "- Training rows: 22,439\n",
       "- Number of iterations: 10\n",
       "- Training loss: 10.3042\n",
       "- Validation loss: 8.6608\n",
       "\n",
       "\n",
       "## Chat evaluation sft\n",
       "timestamp: 2025-11-24 17:36:54\n",
       "\n",
       "- source: sft\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 1\n",
       "- model_tag: d1\n",
       "- step: None\n",
       "- max_problems: 5\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.0000\n",
       "- ARC-Challenge: 0.0000\n",
       "- MMLU: 0.4000\n",
       "- GSM8K: 0.0000\n",
       "- HumanEval: 0.0000\n",
       "- SpellingBee: 0.0000\n",
       "- ChatCORE metric: -0.0778\n",
       "\n",
       "\n",
       "## Summary\n",
       "\n",
       "| Metric          | BASE     | MID      | SFT      | RL       |\n",
       "|-----------------|----------|----------|----------|----------|\n",
       "| CORE            | -0.0093  | -        | -        | -        |\n",
       "| ARC-Challenge   | -        | 0.0000   | 0.0000   | -        |\n",
       "| ARC-Easy        | -        | 0.0000   | 0.0000   | -        |\n",
       "| GSM8K           | -        | 0.0000   | 0.0000   | -        |\n",
       "| HumanEval       | -        | 0.0000   | 0.0000   | -        |\n",
       "| MMLU            | -        | 0.4000   | 0.4000   | -        |\n",
       "| ChatCORE        | -        | -0.0778  | -0.0778  | -        |\n",
       "\n",
       "Total wall clock time: unknown\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open('report.md').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f13b01-5728-4ea1-b110-42fcd818f86f",
   "metadata": {},
   "source": [
    "### <span style='color:green'>reset()</span>\n",
    "\n",
    "I forgot to add reset earlier but that's what records the start time and other overall headers, which is why we don't see info above like git branch, number of CPUs or python version. Add now. (Will stick with reset() but maybe start() would be be a better name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "206b3e78-d030-4149-b5ae-e136c5a25d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base-model-evaluation.md chat-evaluation-mid.md   midtraining.md\n",
      "base-model-loss.md       chat-evaluation-sft.md   report.md\n",
      "base-model-training.md   chat-sft.md\n"
     ]
    }
   ],
   "source": [
    "!ls {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7914bcc-3581-41b1-8cd1-c7f8d061c93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset report and wrote header to /Users/ericsilberstein/.cache/my_nanochat/report/header.md\n"
     ]
    }
   ],
   "source": [
    "!python -m my_nanochat.my_report reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8837c5c9-a0b3-40db-91fd-4ed5689b4ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header.md\n"
     ]
    }
   ],
   "source": [
    "!ls {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7462661-ee45-4fa2-b86d-d4fa741e0acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report to /Users/ericsilberstein/.cache/my_nanochat/report/report.md\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/tokenizer-training.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/tokenizer-evaluation.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/base-model-training.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/base-model-loss.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/base-model-evaluation.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/midtraining.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-evaluation-mid.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-sft.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-evaluation-sft.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-rl.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-evaluation-rl.md does not exist, skipping\n",
      "Copying report.md to current directory for convenience\n"
     ]
    }
   ],
   "source": [
    "!python -m my_nanochat.my_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d0319be6-747d-490a-8d0d-d3c7070997d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# nanochat training report\n",
       "\n",
       "Generated: 2025-11-24 17:53:37\n",
       "\n",
       "## Environment\n",
       "\n",
       "### Git Information\n",
       "- Branch: master\n",
       "- Commit: 33da382 (dirty)\n",
       "- Message: started and finished (?) challenge 33: add chat CLI\n",
       "\n",
       "### Hardware\n",
       "- Platform: Darwin\n",
       "- CPUs: 8 cores (8 logical)\n",
       "- Memory: 16.0 GB\n",
       "- GPUs: None available\n",
       "\n",
       "### Software\n",
       "- Python: 3.10.18\n",
       "- PyTorch: 2.9.0\n",
       "\n",
       "Run started: 2025-11-24 17:53:37\n",
       "\n",
       "--\n",
       "\n",
       "## Summary\n",
       "\n",
       "| Metric          | BASE     | MID      | SFT      | RL       |\n",
       "|-----------------|----------|----------|----------|----------|\n",
       "\n",
       "Total wall clock time: unknown\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open('report.md').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41446dd-e4b4-40b4-af47-cd46b9ef978e",
   "metadata": {},
   "source": [
    "### <span style='color:green'>Run everything so far</span>\n",
    "\n",
    "This will be similar to how things work in [speedrun.sh](https://github.com/karpathy/nanochat/blob/master/speedrun.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "372bb289-8386-45ab-a003-2711a5fbae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset report and wrote header to /Users/ericsilberstein/.cache/my_nanochat/report/header.md\n",
      "overriding depth = 1\n",
      "overriding max_seq_len = 256\n",
      "overriding device_batch_size = 1\n",
      "overriding num_iterations = 10\n",
      "overriding total_batch_size = 256\n",
      "overriding eval_every = 5\n",
      "overriding eval_tokens = 1280\n",
      "overriding core_metric_every = 20\n",
      "overriding core_metric_max_per_task = 11\n",
      "overriding sample_every = 5\n",
      "user_config: {'run': 'dummy', 'device_type': '', 'depth': 1, 'max_seq_len': 256, 'num_iterations': 10, 'target_param_data_ratio': 20, 'device_batch_size': 1, 'total_batch_size': 256, 'embedding_lr': 0.2, 'unembedding_lr': 0.004, 'weight_decay': 0.0, 'matrix_lr': 0.02, 'grad_clip': 1.0, 'warmup_ratio': 0.0, 'warmdown_ratio': 0.2, 'final_lr_frac': 0.0, 'eval_every': 5, 'eval_tokens': 1280, 'core_metric_every': 20, 'core_metric_max_per_task': 11, 'sample_every': 5, 'model_tag': ''}\n",
      "Autodetected device type: mps\n",
      "This process is ddp_rank: 0, ddp_local_rank: 0, ddp_world_size: 1\n",
      "Vocab size: 65,536\n",
      "num_layers: 1\n",
      "model_dim: 64\n",
      "num_heads: 1\n",
      "num_kv_heads: 1\n",
      "Tokens / micro-batch / rank: 1 x 256 = 256\n",
      "Tokens / micro-batch: 256\n",
      "Total batch size 256 => gradient accumulation steps: 1\n",
      "GPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(65536, 64)\n",
      "    (h): ModuleList(\n",
      "      (0): Block(\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_q): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (c_k): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (c_v): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (c_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        )\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=64, out_features=256, bias=False)\n",
      "          (c_proj): Linear(in_features=256, out_features=64, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=64, out_features=65536, bias=False)\n",
      ")\n",
      "Number of parameters: 8,437,760\n",
      "Using user-provided number of iterations: 10\n",
      "Total number of training tokens: 2,560\n",
      "tokens : param ratio: 0.00 (he has note that Chinchilla is ~20)\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(64/768) = 3.464101615137755\n",
      "x.shape is [1, 256], y.shape is [1, 256] -- should match\n",
      "step 00000 | Validation bpb: 3.7003\n",
      "step 00000/00010 (0.00%) | loss: 11.090355 | grad norm: 0.5497 | lrm: 1.00 | dt: 1060.22ms | tok/sec: 241 | mfu: -1.00 | total time: 0.00m\n",
      "step 00001/00010 (10.00%) | loss: 11.057328 | grad norm: 0.7747 | lrm: 1.00 | dt: 60.46ms | tok/sec: 4,233 | mfu: -1.00 | total time: 0.00m\n",
      "step 00002/00010 (20.00%) | loss: 11.011871 | grad norm: 0.8687 | lrm: 1.00 | dt: 60.39ms | tok/sec: 4,239 | mfu: -1.00 | total time: 0.00m\n",
      "step 00003/00010 (30.00%) | loss: 10.879244 | grad norm: 1.4716 | lrm: 1.00 | dt: 59.55ms | tok/sec: 4,299 | mfu: -1.00 | total time: 0.00m\n",
      "step 00004/00010 (40.00%) | loss: 10.726476 | grad norm: 1.7634 | lrm: 1.00 | dt: 59.19ms | tok/sec: 4,325 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005 | Validation bpb: 3.5498\n",
      "<|bos|>The capital of France is a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>The chemical symbol of gold is a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>If yesterday was Friday, then tomorrow will be a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>The opposite of hot is a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>The planets of the solar system are: at consideration transport the a longer\u0000 transport the a\n",
      "<|bos|>My favorite color is a longer\u0000 transport the a longer\u0000 transport the\n",
      "<|bos|>If 5*x + 3 = 13, then x is a longer\u0000 transport the a longer\u0000 transport the\n",
      "step 00005/00010 (50.00%) | loss: 10.543756 | grad norm: 2.1503 | lrm: 1.00 | dt: 63.83ms | tok/sec: 4,010 | mfu: -1.00 | total time: 0.00m\n",
      "step 00006/00010 (60.00%) | loss: 10.498963 | grad norm: 2.4801 | lrm: 1.00 | dt: 59.14ms | tok/sec: 4,328 | mfu: -1.00 | total time: 0.00m\n",
      "step 00007/00010 (70.00%) | loss: 10.468360 | grad norm: 3.2439 | lrm: 1.00 | dt: 59.57ms | tok/sec: 4,297 | mfu: -1.00 | total time: 0.00m\n",
      "step 00008/00010 (80.00%) | loss: 10.357336 | grad norm: 3.0442 | lrm: 1.00 | dt: 65.55ms | tok/sec: 3,905 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009/00010 (90.00%) | loss: 10.180583 | grad norm: 3.0154 | lrm: 0.50 | dt: 71.87ms | tok/sec: 3,562 | mfu: -1.00 | total time: 0.00m\n",
      "step 00010 | Validation bpb: 3.3074\n",
      "Evaluating: hellaswag_zeroshot (0-shot, type: multiple_choice)... accuracy: 0.4545 | centered: 0.2727 | time: 1.10s\n",
      "Evaluating: jeopardy (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.40s\n",
      "Evaluating: bigbench_qa_wikidata (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.26s\n",
      "Evaluating: arc_easy (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.2121 | time: 2.40s\n",
      "Evaluating: arc_challenge (10-shot, type: multiple_choice)... accuracy: 0.0000 | centered: -0.3333 | time: 2.62s\n",
      "Evaluating: copa (0-shot, type: multiple_choice)... accuracy: 0.7273 | centered: 0.4545 | time: 0.54s\n",
      "Evaluating: commonsense_qa (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.1364 | time: 2.16s\n",
      "Evaluating: piqa (10-shot, type: multiple_choice)... accuracy: 0.4545 | centered: -0.0909 | time: 2.45s\n",
      "Evaluating: openbook_qa (0-shot, type: multiple_choice)... accuracy: 0.3636 | centered: 0.1515 | time: 0.56s\n",
      "Evaluating: lambada_openai (0-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.56s\n",
      "Evaluating: hellaswag (10-shot, type: multiple_choice)... accuracy: 0.4545 | centered: 0.2727 | time: 5.61s\n",
      "Evaluating: winograd (0-shot, type: schema)... accuracy: 0.5455 | centered: 0.0909 | time: 0.33s\n",
      "Evaluating: winogrande (0-shot, type: schema)... accuracy: 0.4545 | centered: -0.0909 | time: 0.29s\n",
      "Evaluating: bigbench_dyck_languages (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.57s\n",
      "Evaluating: agi_eval_lsat_ar (3-shot, type: multiple_choice)... accuracy: 0.2727 | centered: 0.0909 | time: 4.51s\n",
      "Evaluating: bigbench_cs_algorithms (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.72s\n",
      "Evaluating: bigbench_operators (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.59s\n",
      "Evaluating: bigbench_repeat_copy_logic (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.97s\n",
      "Evaluating: squad (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 2.30s\n",
      "Evaluating: coqa (0-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 1.85s\n",
      "Evaluating: boolq (10-shot, type: multiple_choice)... accuracy: 0.3636 | centered: -0.6746 | time: 4.16s\n",
      "Evaluating: bigbench_language_identification (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.0001 | time: 6.68s\n",
      "Step 00010: CORE metric: -0.0093\n",
      "<|bos|>The capital of France is the the the the the the the the the the\n",
      "<|bos|>The chemical symbol of gold is the the the the the the the the the the\n",
      "<|bos|>If yesterday was Friday, then tomorrow will be the the the the the the the the the the\n",
      "<|bos|>The opposite of hot is the the the the the the the the the the\n",
      "<|bos|>The planets of the solar system are:\u0000 the the the the the the the the the\n",
      "<|bos|>My favorite color is the the the the the the the the the the\n",
      "<|bos|>If 5*x + 3 = 13, then x is the the the the the the the the the the\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1/model_000010.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1/meta_000010.json\n",
      "saved optimizer to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1/optim_000010_rank0.pt\n",
      "Peak memory usage: 0.00MiB\n",
      "Total training time: 0.00m\n",
      "Minimum validation bpb: 3.3074\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1 with step 10\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "Evaluating: hellaswag_zeroshot (0-shot, type: multiple_choice)... accuracy: 0.4545 | centered: 0.2727 | time: 0.92s\n",
      "Evaluating: jeopardy (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.39s\n",
      "Evaluating: bigbench_qa_wikidata (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.24s\n",
      "Evaluating: arc_easy (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.2121 | time: 1.86s\n",
      "Evaluating: arc_challenge (10-shot, type: multiple_choice)... accuracy: 0.0000 | centered: -0.3333 | time: 2.73s\n",
      "Evaluating: copa (0-shot, type: multiple_choice)... accuracy: 0.7273 | centered: 0.4545 | time: 0.37s\n",
      "Evaluating: commonsense_qa (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.1364 | time: 2.45s\n",
      "Evaluating: piqa (10-shot, type: multiple_choice)... accuracy: 0.4545 | centered: -0.0909 | time: 2.09s\n",
      "Evaluating: openbook_qa (0-shot, type: multiple_choice)... accuracy: 0.3636 | centered: 0.1515 | time: 0.64s\n",
      "Evaluating: lambada_openai (0-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.53s\n",
      "Evaluating: hellaswag (10-shot, type: multiple_choice)... accuracy: 0.4545 | centered: 0.2727 | time: 5.92s\n",
      "Evaluating: winograd (0-shot, type: schema)... accuracy: 0.5455 | centered: 0.0909 | time: 0.35s\n",
      "Evaluating: winogrande (0-shot, type: schema)... accuracy: 0.4545 | centered: -0.0909 | time: 0.27s\n",
      "Evaluating: bigbench_dyck_languages (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.55s\n",
      "Evaluating: agi_eval_lsat_ar (3-shot, type: multiple_choice)... accuracy: 0.2727 | centered: 0.0909 | time: 4.49s\n",
      "Evaluating: bigbench_cs_algorithms (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.68s\n",
      "Evaluating: bigbench_operators (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 0.55s\n",
      "Evaluating: bigbench_repeat_copy_logic (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 1.19s\n",
      "Evaluating: squad (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 2.27s\n",
      "Evaluating: coqa (0-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 1.68s\n",
      "Evaluating: boolq (10-shot, type: multiple_choice)... accuracy: 0.3636 | centered: -0.6746 | time: 4.79s\n",
      "Evaluating: bigbench_language_identification (10-shot, type: multiple_choice)... accuracy: 0.0909 | centered: -0.0001 | time: 7.36s\n",
      "================================================================================\n",
      "Model: base_model (step 10)\n",
      "================================================================================\n",
      "Task                               , Accuracy  , Centered  \n",
      "hellaswag_zeroshot                 , 0.454545  , 0.272727  \n",
      "jeopardy                           , 0.000000  , 0.000000  \n",
      "bigbench_qa_wikidata               , 0.000000  , 0.000000  \n",
      "arc_easy                           , 0.090909  , -0.212121 \n",
      "arc_challenge                      , 0.000000  , -0.333333 \n",
      "copa                               , 0.727273  , 0.454545  \n",
      "commonsense_qa                     , 0.090909  , -0.136364 \n",
      "piqa                               , 0.454545  , -0.090909 \n",
      "openbook_qa                        , 0.363636  , 0.151515  \n",
      "lambada_openai                     , 0.000000  , 0.000000  \n",
      "hellaswag                          , 0.454545  , 0.272727  \n",
      "winograd                           , 0.545455  , 0.090909  \n",
      "winogrande                         , 0.454545  , -0.090909 \n",
      "bigbench_dyck_languages            , 0.000000  , 0.000000  \n",
      "agi_eval_lsat_ar                   , 0.272727  , 0.090909  \n",
      "bigbench_cs_algorithms             , 0.000000  , 0.000000  \n",
      "bigbench_operators                 , 0.000000  , 0.000000  \n",
      "bigbench_repeat_copy_logic         , 0.000000  , 0.000000  \n",
      "squad                              , 0.000000  , 0.000000  \n",
      "coqa                               , 0.000000  , 0.000000  \n",
      "boolq                              , 0.363636  , -0.674641 \n",
      "bigbench_language_identification   , 0.090909  , -0.000100 \n",
      "CORE                               ,           , -0.009320 \n",
      "\n",
      "overriding device_batch_size = 1\n",
      "overriding split_tokens = 2048\n",
      "overriding model_tag = d1\n",
      "user_config: {'device_batch_size': 1, 'split_tokens': 2048, 'device_type': ''}\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1 with step 10\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "train bpb: 1.9767\n",
      "val bpb: 3.1199\n",
      "<|bos|>The capital of France is the the the the the the the the the the the the the the the the\n",
      "<|bos|>The chemical symbol of gold is the the the the the the the the the the the the the the the the\n",
      "<|bos|>If yesterday was Friday, then tomorrow will be the the the the the the the the the the the the the the the the\n",
      "<|bos|>The opposite of hot is the the the the the the the the the the the the the the the the\n",
      "<|bos|>The planets of the solar system are:\u0000 the the the the the the the the the the the the the the the\n",
      "<|bos|>My favorite color is the the the the the the the the the the the the the the the the\n",
      "<|bos|>If 5*x + 3 = 13, then x is the the the the the the the the the the the the the the the the\n",
      "overriding model_tag = d1\n",
      "overriding num_iterations = 10\n",
      "overriding max_seq_len = 256\n",
      "overriding device_batch_size = 1\n",
      "overriding total_batch_size = 256\n",
      "overriding eval_every = 5\n",
      "overriding eval_tokens = 1024\n",
      "user_config: {'run': 'dummy', 'device_type': '', 'dtype': 'bfloat16', 'num_iterations': 10, 'max_seq_len': 256, 'device_batch_size': 1, 'unembedding_lr': 0.004, 'embedding_lr': 0.2, 'matrix_lr': 0.02, 'init_lr_frac': 1.0, 'weight_decay': 0.0, 'eval_every': 5, 'eval_tokens': 1024, 'total_batch_size': 256, 'dry_run': 0}\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d1 with step 10\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "Tokens / micro-batch / rank: 1 x 256 = 256\n",
      "Tokens / micro-batch: 256\n",
      "Total batch size 256 => gradient accumulation steps: 1\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(64/768) = 3.464101615137755\n",
      "step 00000 | Validation bpb: 2.7541\n",
      "step 00001 (20.00%) | loss: 5.577855 | lrm: 1.00 | dt: 559.62ms | tok/sec: 457 | mfu: -1.00 | total time: 0.00m\n",
      "step 00002 (30.00%) | loss: 6.807157 | lrm: 1.00 | dt: 7.51ms | tok/sec: 34,097 | mfu: -1.00 | total time: 0.00m\n",
      "step 00003 (40.00%) | loss: 7.308724 | lrm: 1.00 | dt: 7.76ms | tok/sec: 32,999 | mfu: -1.00 | total time: 0.00m\n",
      "step 00004 (50.00%) | loss: 7.631470 | lrm: 1.00 | dt: 9.82ms | tok/sec: 26,056 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005 (60.00%) | loss: 7.795699 | lrm: 1.00 | dt: 12.73ms | tok/sec: 20,116 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005 | Validation bpb: 2.4899\n",
      "step 00006 (70.00%) | loss: 7.894709 | lrm: 1.00 | dt: 17.65ms | tok/sec: 14,504 | mfu: -1.00 | total time: 0.00m\n",
      "step 00007 (80.00%) | loss: 8.133986 | lrm: 1.00 | dt: 21.19ms | tok/sec: 12,079 | mfu: -1.00 | total time: 0.00m\n",
      "step 00008 (90.00%) | loss: 8.386695 | lrm: 0.50 | dt: 18.38ms | tok/sec: 13,927 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009 (100.00%) | loss: 8.469563 | lrm: 0.00 | dt: 19.99ms | tok/sec: 12,805 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009 | Validation bpb: 2.3761\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1/model_000009.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1/meta_000009.json\n",
      "saved optimizer to /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1/optim_000009_rank0.pt\n",
      "Peak memory usage: 0.00MiB\n",
      "Total training time: 0.00m\n",
      "Minimum validation bpb: 2.3761\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1 with step 9\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Easy accuracy: 0.00%\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Challenge accuracy: 0.00%\n",
      "final: 2/5 (40.00%)\n",
      "MMLU accuracy: 40.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "GSM8K accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "HumanEval accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "SpellingBee accuracy: 0.00%\n",
      "overriding model_tag = d1\n",
      "overriding num_iterations = 10\n",
      "overriding device_batch_size = 1\n",
      "overriding target_examples_per_step = 4\n",
      "overriding eval_every = 5\n",
      "overriding eval_steps = 10\n",
      "overriding eval_metrics_every = 5\n",
      "overriding eval_metrics_max_problems = 2\n",
      "overriding max_data_tokens = 1280\n",
      "user_config: {'run': 'dummy', 'source': 'mid', 'device_type': '', 'dtype': 'bfloat16', 'device_batch_size': 1, 'num_epochs': 1, 'num_iterations': 10, 'max_data_tokens': 1280, 'target_examples_per_step': 4, 'unembedding_lr': 0.004, 'embedding_lr': 0.2, 'matrix_lr': 0.02, 'weight_decay': 0.0, 'init_lr_frac': 0.02, 'eval_every': 5, 'eval_steps': 10, 'eval_metrics_every': 5, 'eval_metrics_max_problems': 2}\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d1 with step 9\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "Target examples per step: 4\n",
      "Device batch size: 1\n",
      "Examples per step is device_batch_size * ddp_world_size: 1\n",
      " => grad accum steps: 4\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(64/768) = 3.464101615137755\n",
      "Step 00000 | Validation loss: 8.716637\n",
      "Step 00000/00010 | Training loss: 10.548628| lrm: 1.000000| num_tokens: 2,365\n",
      "Step 00001/00010 | Training loss: 8.871406| lrm: 0.900000| num_tokens: 2,195\n",
      "Step 00002/00010 | Training loss: 8.671903| lrm: 0.800000| num_tokens: 289\n",
      "Step 00003/00010 | Training loss: 9.801077| lrm: 0.700000| num_tokens: 186\n",
      "Step 00004/00010 | Training loss: 9.135199| lrm: 0.600000| num_tokens: 2,011\n",
      "Step 00005 | Validation loss: 8.677261\n",
      "final: 1/2 (50.00%)\n",
      "final: 0/2 (0.00%)\n",
      "Step 00005 | mmlu_acc: 0.500000, arc_easy_acc: 0.000000\n",
      "Step 00005/00010 | Training loss: 10.117952| lrm: 0.500000| num_tokens: 1,451\n",
      "Step 00006/00010 | Training loss: 8.589089| lrm: 0.400000| num_tokens: 520\n",
      "Step 00007/00010 | Training loss: 10.020153| lrm: 0.300000| num_tokens: 701\n",
      "Step 00008/00010 | Training loss: 10.306732| lrm: 0.200000| num_tokens: 1,347\n",
      "Step 00009 | Validation loss: 8.661841\n",
      "final: 1/2 (50.00%)\n",
      "final: 0/2 (0.00%)\n",
      "Step 00009 | mmlu_acc: 0.500000, arc_easy_acc: 0.000000\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d1/model_000009.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d1/meta_000009.json\n",
      "Saved model checkpoint to /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d1\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d1 with step 9\n",
      "Building model with config: {'sequence_len': 256, 'vocab_size': 65536, 'n_layer': 1, 'n_head': 1, 'n_kv_head': 1, 'n_embd': 64}\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Easy accuracy: 0.00%\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Challenge accuracy: 0.00%\n",
      "final: 2/5 (40.00%)\n",
      "MMLU accuracy: 40.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "GSM8K accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "HumanEval accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "SpellingBee accuracy: 0.00%\n",
      "Generating report to /Users/ericsilberstein/.cache/my_nanochat/report/report.md\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/tokenizer-training.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/tokenizer-evaluation.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-rl.md does not exist, skipping\n",
      "Warning: /Users/ericsilberstein/.cache/my_nanochat/report/chat-evaluation-rl.md does not exist, skipping\n",
      "Copying report.md to current directory for convenience\n"
     ]
    }
   ],
   "source": [
    "!python -m my_nanochat.my_report reset\n",
    "\n",
    "!python -m scripts.my_base_train \\\n",
    "    --depth=1 \\\n",
    "    --max_seq_len=256 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --num_iterations=10 \\\n",
    "    --total_batch_size=256 \\\n",
    "    --eval_every=5 \\\n",
    "    --eval_tokens=1280 \\\n",
    "    --core_metric_every=20 \\\n",
    "    --core_metric_max_per_task=11 \\\n",
    "    --sample_every=5\n",
    "\n",
    "!python -m scripts.my_base_eval \\\n",
    "    --model-tag=d1 \\\n",
    "    --source=base \\\n",
    "    --max-per-task=11\n",
    "\n",
    "!python -m scripts.my_base_loss \\\n",
    "    --device_batch_size=1 \\\n",
    "    --split_tokens=2048 \\\n",
    "    --model_tag=d1\n",
    "\n",
    "!python -m scripts.my_mid_train \\\n",
    "    --model_tag=d1 \\\n",
    "    --num_iterations=10 \\\n",
    "    --max_seq_len=256 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --total_batch_size=256 \\\n",
    "    --eval_every=5 \\\n",
    "    --eval_tokens=1024\n",
    "\n",
    "!python -m scripts.my_chat_eval \\\n",
    "    --source=mid \\\n",
    "    --batch-size=1 \\\n",
    "    --model-tag=d1 \\\n",
    "    --max-problems=5\n",
    "\n",
    "!python -m scripts.my_chat_sft \\\n",
    "    --model_tag=d1 \\\n",
    "    --num_iterations=10 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --target_examples_per_step=4 \\\n",
    "    --eval_every=5 \\\n",
    "    --eval_steps=10 \\\n",
    "    --eval_metrics_every=5 \\\n",
    "    --eval_metrics_max_problems=2 \\\n",
    "    --max_data_tokens=1280\n",
    "\n",
    "!python -m scripts.my_chat_eval \\\n",
    "    --source=sft \\\n",
    "    --batch-size=1 \\\n",
    "    --model-tag=d1 \\\n",
    "    --max-problems=5\n",
    "\n",
    "!python -m my_nanochat.my_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c7b72b63-1621-4778-b311-8d87912fb87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 80\n",
      "-rw-r--r--  1 ericsilberstein  staff  5244 Nov 24 18:05 report.md\n",
      "-rw-r--r--  1 ericsilberstein  staff   423 Nov 24 18:05 chat-evaluation-sft.md\n",
      "-rw-r--r--  1 ericsilberstein  staff   524 Nov 24 18:04 chat-sft.md\n",
      "-rw-r--r--  1 ericsilberstein  staff   423 Nov 24 18:04 chat-evaluation-mid.md\n",
      "-rw-r--r--  1 ericsilberstein  staff   424 Nov 24 18:03 midtraining.md\n",
      "-rw-r--r--  1 ericsilberstein  staff   879 Nov 24 18:02 base-model-loss.md\n",
      "-rw-r--r--  1 ericsilberstein  staff   652 Nov 24 18:02 base-model-evaluation.md\n",
      "-rw-r--r--  1 ericsilberstein  staff   903 Nov 24 18:02 base-model-training.md\n",
      "-rw-r--r--  1 ericsilberstein  staff   392 Nov 24 18:01 header.md\n"
     ]
    }
   ],
   "source": [
    "!ls -lt {get_base_dir()}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc5e5a90-68dd-47e3-b63c-3411abae831d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# nanochat training report\n",
       "\n",
       "Generated: 2025-11-24 18:01:13\n",
       "\n",
       "## Environment\n",
       "\n",
       "### Git Information\n",
       "- Branch: master\n",
       "- Commit: 33da382 (dirty)\n",
       "- Message: started and finished (?) challenge 33: add chat CLI\n",
       "\n",
       "### Hardware\n",
       "- Platform: Darwin\n",
       "- CPUs: 8 cores (8 logical)\n",
       "- Memory: 16.0 GB\n",
       "- GPUs: None available\n",
       "\n",
       "### Software\n",
       "- Python: 3.10.18\n",
       "- PyTorch: 2.9.0\n",
       "\n",
       "Run started: 2025-11-24 18:01:13\n",
       "\n",
       "--\n",
       "\n",
       "## Base model training\n",
       "timestamp: 2025-11-24 18:02:01\n",
       "\n",
       "- run: dummy\n",
       "- device_type: \n",
       "- depth: 1\n",
       "- max_seq_len: 256\n",
       "- num_iterations: 10\n",
       "- target_param_data_ratio: 20\n",
       "- device_batch_size: 1\n",
       "- total_batch_size: 256\n",
       "- embedding_lr: 0.2000\n",
       "- unembedding_lr: 0.0040\n",
       "- weight_decay: 0.0000\n",
       "- matrix_lr: 0.0200\n",
       "- grad_clip: 1.0000\n",
       "- warmup_ratio: 0.0000\n",
       "- warmdown_ratio: 0.2000\n",
       "- final_lr_frac: 0.0000\n",
       "- eval_every: 5\n",
       "- eval_tokens: 1280\n",
       "- core_metric_every: 20\n",
       "- core_metric_max_per_task: 11\n",
       "- sample_every: 5\n",
       "- model_tag: \n",
       "- Number of parameters: 8,437,760\n",
       "- Calculated number of iterations: 10\n",
       "- Number of training tokens: 2560\n",
       "- Tokens : Params ratio: 0.0003\n",
       "- DDP world size: 1\n",
       "- warmup_ratio: 0.0000\n",
       "- warmdown_ratio: 0.2000\n",
       "- final_lr_frac: 0.0000\n",
       "- Minimum validation bpb: 3.3074\n",
       "- Final validation bpb: 3.3074\n",
       "- CORE metric estimate: -0.0093\n",
       "- Total training time: 0.00m\n",
       "- Peak memory usage: 0.00MiB\n",
       "\n",
       "\n",
       "## Base model loss\n",
       "timestamp: 2025-11-24 18:02:53\n",
       "\n",
       "- train bpb: 1.9767\n",
       "- val bpb: 3.1199\n",
       "- sample 0: <|bos|>The capital of France is the the the the the the the the the the the the the the the the\n",
       "- sample 1: <|bos|>The chemical symbol of gold is the the the the the the the the the the the the the the the the\n",
       "- sample 2: <|bos|>If yesterday was Friday, then tomorrow will be the the the the the the the the the the the the the the the the\n",
       "- sample 3: <|bos|>The opposite of hot is the the the the the the the the the the the the the the the the\n",
       "- sample 4: <|bos|>The planets of the solar system are:\u0000 the the the the the the the the the the the the the the the\n",
       "- sample 5: <|bos|>My favorite color is the the the the the the the the the the the the the the the the\n",
       "- sample 6: <|bos|>If 5*x + 3 = 13, then x is the the the the the the the the the the the the the the the the\n",
       "\n",
       "\n",
       "## Base model evaluation\n",
       "timestamp: 2025-11-24 18:02:48\n",
       "\n",
       "- Model: base_model (step 10)\n",
       "- CORE metric: -0.0093\n",
       "- hellaswag_zeroshot: 0.2727\n",
       "- jeopardy: 0.0000\n",
       "- bigbench_qa_wikidata: 0.0000\n",
       "- arc_easy: -0.2121\n",
       "- arc_challenge: -0.3333\n",
       "- copa: 0.4545\n",
       "- commonsense_qa: -0.1364\n",
       "- piqa: -0.0909\n",
       "- openbook_qa: 0.1515\n",
       "- lambada_openai: 0.0000\n",
       "- hellaswag: 0.2727\n",
       "- winograd: 0.0909\n",
       "- winogrande: -0.0909\n",
       "- bigbench_dyck_languages: 0.0000\n",
       "- agi_eval_lsat_ar: 0.0909\n",
       "- bigbench_cs_algorithms: 0.0000\n",
       "- bigbench_operators: 0.0000\n",
       "- bigbench_repeat_copy_logic: 0.0000\n",
       "- squad: 0.0000\n",
       "- coqa: 0.0000\n",
       "- boolq: -0.6746\n",
       "- bigbench_language_identification: -0.0001\n",
       "\n",
       "\n",
       "## Midtraining\n",
       "timestamp: 2025-11-24 18:03:03\n",
       "\n",
       "- run: dummy\n",
       "- device_type: \n",
       "- dtype: bfloat16\n",
       "- num_iterations: 10\n",
       "- max_seq_len: 256\n",
       "- device_batch_size: 1\n",
       "- unembedding_lr: 0.0040\n",
       "- embedding_lr: 0.2000\n",
       "- matrix_lr: 0.0200\n",
       "- init_lr_frac: 1.0000\n",
       "- weight_decay: 0.0000\n",
       "- eval_every: 5\n",
       "- eval_tokens: 1024\n",
       "- total_batch_size: 256\n",
       "- dry_run: 0\n",
       "- Number of iterations: 9\n",
       "- DDP world size: 1\n",
       "- Minimum validation bpb: 2.3761\n",
       "\n",
       "\n",
       "## Chat evaluation mid\n",
       "timestamp: 2025-11-24 18:04:15\n",
       "\n",
       "- source: mid\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 1\n",
       "- model_tag: d1\n",
       "- step: None\n",
       "- max_problems: 5\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.0000\n",
       "- ARC-Challenge: 0.0000\n",
       "- MMLU: 0.4000\n",
       "- GSM8K: 0.0000\n",
       "- HumanEval: 0.0000\n",
       "- SpellingBee: 0.0000\n",
       "- ChatCORE metric: -0.0778\n",
       "\n",
       "\n",
       "## Chat SFT\n",
       "timestamp: 2025-11-24 18:04:36\n",
       "\n",
       "- run: dummy\n",
       "- source: mid\n",
       "- device_type: \n",
       "- dtype: bfloat16\n",
       "- device_batch_size: 1\n",
       "- num_epochs: 1\n",
       "- num_iterations: 10\n",
       "- max_data_tokens: 1280\n",
       "- target_examples_per_step: 4\n",
       "- unembedding_lr: 0.0040\n",
       "- embedding_lr: 0.2000\n",
       "- matrix_lr: 0.0200\n",
       "- weight_decay: 0.0000\n",
       "- init_lr_frac: 0.0200\n",
       "- eval_every: 5\n",
       "- eval_steps: 10\n",
       "- eval_metrics_every: 5\n",
       "- eval_metrics_max_problems: 2\n",
       "- Training rows: 22,439\n",
       "- Number of iterations: 10\n",
       "- Training loss: 10.3067\n",
       "- Validation loss: 8.6618\n",
       "\n",
       "\n",
       "## Chat evaluation sft\n",
       "timestamp: 2025-11-24 18:05:48\n",
       "\n",
       "- source: sft\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 1\n",
       "- model_tag: d1\n",
       "- step: None\n",
       "- max_problems: 5\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.0000\n",
       "- ARC-Challenge: 0.0000\n",
       "- MMLU: 0.4000\n",
       "- GSM8K: 0.0000\n",
       "- HumanEval: 0.0000\n",
       "- SpellingBee: 0.0000\n",
       "- ChatCORE metric: -0.0778\n",
       "\n",
       "\n",
       "## Summary\n",
       "\n",
       "| Metric          | BASE     | MID      | SFT      | RL       |\n",
       "|-----------------|----------|----------|----------|----------|\n",
       "| CORE            | -0.0093  | -        | -        | -        |\n",
       "| ARC-Challenge   | -        | 0.0000   | 0.0000   | -        |\n",
       "| ARC-Easy        | -        | 0.0000   | 0.0000   | -        |\n",
       "| GSM8K           | -        | 0.0000   | 0.0000   | -        |\n",
       "| HumanEval       | -        | 0.0000   | 0.0000   | -        |\n",
       "| MMLU            | -        | 0.4000   | 0.4000   | -        |\n",
       "| ChatCORE        | -        | -0.0778  | -0.0778  | -        |\n",
       "\n",
       "Total wall clock time: 0h4m\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(open('report.md').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10a47b-f803-4b99-8b32-7410301062a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec7d8523-175a-447e-8db3-ba77b441b733",
   "metadata": {},
   "source": [
    "Code added/updated as part of this challenge:\n",
    "\n",
    "- Added `my_report.py`\n",
    "  \n",
    "- Added `my_base_loss.py`\n",
    "\n",
    "- Added logging to report in `my_base_train.py`, `my_base_eval.py`, `my_mid_train.py`, `my_chat_eval.py`, and `my_chat_sft.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97965a-3622-4ff7-bee5-692d07f831c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
