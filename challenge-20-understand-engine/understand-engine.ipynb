{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a32cb91-f96c-4fff-8ae3-71e9fe6d1823",
   "metadata": {},
   "source": [
    "I want to understand and then \"copy\" [engine.py](https://github.com/karpathy/nanochat/blob/master/nanochat/engine.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a35dca-68f4-4d35-a5e0-2be2a0641bef",
   "metadata": {},
   "source": [
    "I see at the bottom he does a sanity check: \"Quick inline test to make sure that the naive/slow model.generate function is equivalent to the faster Engine.generate function here.\" That reminds me that I never added generate() to 'my_gpt.py'. Let me do that first. Doing this in:\n",
    "\n",
    "`add-generate-to-gpt.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01929352-d629-4f7c-b12f-6a69b5ae08a8",
   "metadata": {},
   "source": [
    "I also see I need to start understanding KV cache and undo my assertions in `my_gpt.py` that it's None. Doing that in:\n",
    "\n",
    "`add-kv-cache-support-to-gpt.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e899d-4826-4855-bb63-2d616c5372a1",
   "metadata": {},
   "source": [
    "Now I'll work on adding the `Engine` class to `my_engine.py`. I'll do that in:\n",
    "\n",
    "`add-engine-to-engine.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199e66a-c60c-41de-a6a7-de79988ef5e3",
   "metadata": {},
   "source": [
    "And finally can go back to `my_base_train.py` and print out samples every so many steps as in his version. Try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "369a81c3-5aab-44dd-9c76-2c7034e533d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2ce6e781-4d50-4de6-ab30-064364199645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding depth = 4\n",
      "overriding max_seq_len = 128\n",
      "overriding device_batch_size = 1\n",
      "overriding num_iterations = 20\n",
      "overriding total_batch_size = 128\n",
      "overriding eval_every = 100\n",
      "overriding eval_tokens = 1280\n",
      "overriding sample_every = 5\n",
      "user_config: {'device_type': '', 'depth': 4, 'max_seq_len': 128, 'num_iterations': 20, 'device_batch_size': 1, 'total_batch_size': 128, 'embedding_lr': 0.2, 'unembedding_lr': 0.004, 'weight_decay': 0.0, 'matrix_lr': 0.02, 'grad_clip': 1.0, 'warmup_ratio': 0.0, 'warmdown_ratio': 0.2, 'final_lr_frac': 0.0, 'eval_every': 100, 'eval_tokens': 1280, 'core_metric_every': 2000, 'core_metric_max_per_task': 500, 'sample_every': 5, 'model_tag': ''}\n",
      "Autodetected device type: mps\n",
      "Vocab size: 65,537\n",
      "num_layers: 4\n",
      "model_dim: 256\n",
      "num_heads: 2\n",
      "num_kv_heads: 2\n",
      "Tokens / micro-batch / rank: 1 x 128 = 128\n",
      "Tokens / micro-batch: 128\n",
      "Total batch size 128 => gradient accumulation steps: 1\n",
      "GPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(65537, 256)\n",
      "    (h): ModuleList(\n",
      "      (0-3): 4 x Block(\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "          (c_k): Linear(in_features=256, out_features=256, bias=False)\n",
      "          (c_v): Linear(in_features=256, out_features=256, bias=False)\n",
      "          (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (c_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=256, out_features=65537, bias=False)\n",
      ")\n",
      "Number of parameters: 36,700,672\n",
      "Using user-provided number of iterations: 20\n",
      "Total number of training tokens: 2,560\n",
      "tokens : param ratio: 0.00 (he has note that Chinchilla is ~20)\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(256/768) = 1.7320508075688774\n",
      "x.shape is [1, 128], y.shape is [1, 128] -- should match\n",
      "step 00000 | Validation bpb: 3.6896\n",
      "step 00000/00020 (0.00%) | loss: 11.090370 | grad norm: 1.6017 | lrm: 1.00 | dt: 718.03ms | tok/sec: 178 | mfu: -1.00 | total time: 0.00m\n",
      "step 00001/00020 (5.00%) | loss: 11.069742 | grad norm: 81.2766 | lrm: 1.00 | dt: 69.90ms | tok/sec: 1,831 | mfu: -1.00 | total time: 0.00m\n",
      "step 00002/00020 (10.00%) | loss: 11.009183 | grad norm: 47.9126 | lrm: 1.00 | dt: 67.60ms | tok/sec: 1,893 | mfu: -1.00 | total time: 0.00m\n",
      "step 00003/00020 (15.00%) | loss: 10.928947 | grad norm: 125.5696 | lrm: 1.00 | dt: 70.41ms | tok/sec: 1,817 | mfu: -1.00 | total time: 0.00m\n",
      "step 00004/00020 (20.00%) | loss: 10.883076 | grad norm: 85.3967 | lrm: 1.00 | dt: 66.77ms | tok/sec: 1,916 | mfu: -1.00 | total time: 0.00m\n",
      "<bos>The capital of France is an important consideration when planning the most and weight may\n",
      "<bos>The chemical symbol of gold is an important consideration when planning the most and weight may\n",
      "<bos>If yesterday was Friday, then tomorrow will be evaluated when planning the most the most the most the\n",
      "<bos>The opposite of hot is an important consideration when planning the most and weight may\n",
      "<bos>The planets of the solar system are: around transport most and weight may move by other modes\n",
      "<bos>My favorite color is an important consideration when planning the most and weight may\n",
      "<bos>If 5*x + 3 = 13, then x is an important consideration when planning the most the most the\n",
      "step 00005/00020 (25.00%) | loss: 10.852465 | grad norm: 108.0931 | lrm: 1.00 | dt: 80.60ms | tok/sec: 1,588 | mfu: -1.00 | total time: 0.00m\n",
      "step 00006/00020 (30.00%) | loss: 10.680134 | grad norm: 114.1815 | lrm: 1.00 | dt: 64.89ms | tok/sec: 1,972 | mfu: -1.00 | total time: 0.00m\n",
      "step 00007/00020 (35.00%) | loss: 10.595167 | grad norm: 260.6612 | lrm: 1.00 | dt: 67.38ms | tok/sec: 1,899 | mfu: -1.00 | total time: 0.00m\n",
      "step 00008/00020 (40.00%) | loss: 10.478158 | grad norm: 301.1943 | lrm: 1.00 | dt: 79.24ms | tok/sec: 1,615 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009/00020 (45.00%) | loss: 10.282842 | grad norm: 201.3679 | lrm: 1.00 | dt: 73.14ms | tok/sec: 1,750 | mfu: -1.00 | total time: 0.00m\n",
      "<bos>The capital of France is most most most most most most most most most most\n",
      "<bos>The chemical symbol of gold is most most most most most most most most most most\n",
      "<bos>If yesterday was Friday, then tomorrow will be most most most most most most most most most most\n",
      "<bos>The opposite of hot is most most most most most most most most most most\n",
      "<bos>The planets of the solar system are: most most most most most most most most most most\n",
      "<bos>My favorite color is most most most most most most most most most most\n",
      "<bos>If 5*x + 3 = 13, then x is most most most most most most most most most most\n",
      "step 00010/00020 (50.00%) | loss: 10.085457 | grad norm: 176.5984 | lrm: 1.00 | dt: 84.82ms | tok/sec: 1,509 | mfu: -1.00 | total time: 0.00m\n",
      "step 00011/00020 (55.00%) | loss: 9.878520 | grad norm: 244.6839 | lrm: 1.00 | dt: 72.95ms | tok/sec: 1,754 | mfu: -1.00 | total time: 0.00m\n",
      "step 00012/00020 (60.00%) | loss: 9.842854 | grad norm: 155.9740 | lrm: 1.00 | dt: 72.72ms | tok/sec: 1,760 | mfu: -1.00 | total time: 0.00m\n",
      "step 00013/00020 (65.00%) | loss: 9.784720 | grad norm: 93.8708 | lrm: 1.00 | dt: 76.36ms | tok/sec: 1,676 | mfu: -1.00 | total time: 0.00m\n",
      "step 00014/00020 (70.00%) | loss: 9.761647 | grad norm: 104.3444 | lrm: 1.00 | dt: 70.52ms | tok/sec: 1,815 | mfu: -1.00 | total time: 0.00m\n",
      "<bos>The capital of France is or or or or or or or or or or\n",
      "<bos>The chemical symbol of gold is or or or or or or or or or or\n",
      "<bos>If yesterday was Friday, then tomorrow will be or or or or or or or or or or\n",
      "<bos>The opposite of hot is or or or or or or or or or or\n",
      "<bos>The planets of the solar system are: or or or or or or or or or or\n",
      "<bos>My favorite color is or or or or or or or or or or\n",
      "<bos>If 5*x + 3 = 13, then x is or or or or or or or or or or\n",
      "step 00015/00020 (75.00%) | loss: 9.674778 | grad norm: 96.1562 | lrm: 1.00 | dt: 87.72ms | tok/sec: 1,459 | mfu: -1.00 | total time: 0.01m\n",
      "step 00016/00020 (80.00%) | loss: 9.521979 | grad norm: 64.4332 | lrm: 1.00 | dt: 69.57ms | tok/sec: 1,839 | mfu: -1.00 | total time: 0.01m\n",
      "step 00017/00020 (85.00%) | loss: 9.394057 | grad norm: 74.5600 | lrm: 0.75 | dt: 73.88ms | tok/sec: 1,732 | mfu: -1.00 | total time: 0.01m\n",
      "step 00018/00020 (90.00%) | loss: 9.248169 | grad norm: 74.3521 | lrm: 0.50 | dt: 74.29ms | tok/sec: 1,723 | mfu: -1.00 | total time: 0.01m\n",
      "step 00019/00020 (95.00%) | loss: 9.072098 | grad norm: 93.6194 | lrm: 0.25 | dt: 74.35ms | tok/sec: 1,721 | mfu: -1.00 | total time: 0.01m\n",
      "step 00020 | Validation bpb: 3.1047\n",
      "TODO evaluate CORE metric\n",
      "<bos>The capital of France is any any any any any any any any any any\n",
      "<bos>The chemical symbol of gold is any any any any any any any any any any\n",
      "<bos>If yesterday was Friday, then tomorrow will be any any any any any any any any any any\n",
      "<bos>The opposite of hot is any any any any any any any any any any\n",
      "<bos>The planets of the solar system are: any any any any any any any any any any\n",
      "<bos>My favorite color is any any any any any any any any any any\n",
      "<bos>If 5*x + 3 = 13, then x is any any any any any any any any any any\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4/model_000020.pt\n",
      "saved optimizer to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4/model_000020.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4/meta_000020.json\n",
      "Peak memory usage: 0.00MiB\n",
      "Total training time: 0.01m\n",
      "Minimum validation bpb: 3.1047\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_base_train \\\n",
    "    --depth=4 \\\n",
    "    --max_seq_len=128 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --num_iterations=20 \\\n",
    "    --total_batch_size=128 \\\n",
    "    --eval_every=100 \\\n",
    "    --eval_tokens=1280 \\\n",
    "    --sample_every=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59895c8d-1149-4c30-ad9f-157d991b0fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b67319a-6ded-41a5-899f-9b5cdcd0c0f9",
   "metadata": {},
   "source": [
    "Code added as part of this challenge:\n",
    "\n",
    "- Added `generate()` (the \"naive\" genereate) to `my_gpt.py`\n",
    "\n",
    "- Added support for KV cache to `my_gpt.py` in the forwards of `CausalSelfAttention` and `GPT`\n",
    "\n",
    "- Created `my_engine.py` and added the `KVCache` class\n",
    "\n",
    "- Added `sample_next_token()` helper function to `my_engine.py`\n",
    "\n",
    "- Added `Engine.generate()` and `Engine.generate_batch()` to `my_engine.py`\n",
    "\n",
    "- Updated `my_base_train.py` to generate and print samples every n steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ea68e-7a7b-4e71-814a-eb6154ef8b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
