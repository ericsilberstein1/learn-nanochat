{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727a7904-4dc0-4bb5-8429-ae0030f21ca2",
   "metadata": {},
   "source": [
    "# Play Tokenizer\n",
    "\n",
    "Write a BPE tokenizer in Python without worrying about performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f1fa6-f06c-40e8-ad33-ee0a02fcddf7",
   "metadata": {},
   "source": [
    "I started to look at the tokenizer. I found [this](https://huggingface.co/learn/llm-course/en/chapter6/5) intro to byte-pair encoding tokenization on Hugging Face and read enough to get the idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be0a107-59cd-41be-ae66-2badac72bf9f",
   "metadata": {},
   "source": [
    "## Determine tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8bb63ca7-4e13-4c32-acb0-e67ad6bdc7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"The batat and the cat fought over the hat.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f3c8a-67c5-458d-b684-45d883e37020",
   "metadata": {},
   "source": [
    "### Figure out ideas and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "41682136-90ac-4825-b8c9-e37b0be63fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'batat', 'and', 'the', 'cat', 'fought', 'over', 'the', 'hat.']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = corpus.split(' '); words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dc974153-9111-4d9e-b279-0370c6fe2b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['T', 'h', 'e'],\n",
       " ['b', 'a', 't', 'a', 't'],\n",
       " ['a', 'n', 'd'],\n",
       " ['t', 'h', 'e'],\n",
       " ['c', 'a', 't'],\n",
       " ['f', 'o', 'u', 'g', 'h', 't'],\n",
       " ['o', 'v', 'e', 'r'],\n",
       " ['t', 'h', 'e'],\n",
       " ['h', 'a', 't', '.']]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [list(word) for word in words]; words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c0221bb5-f0c3-4fd6-8c1a-4b9e12eee576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'T',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'n',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'u',\n",
       " 'v'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = set(t for word in words for t in word); tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "939ce531-e677-4698-9a30-2a9f42ea0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs():\n",
    "    pairs = {}\n",
    "    for word in words:\n",
    "        for i in range(len(word)-1):\n",
    "            pair = (word[i], word[i+1])\n",
    "            if pair in pairs:\n",
    "                pairs[pair] += 1\n",
    "            else:\n",
    "                pairs[pair] = 1\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "42bff8c6-f4c5-4bc2-889d-fc47a37646c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_pair(pairs):\n",
    "    top_frequency = 0\n",
    "    candidate_pair = None\n",
    "    for pair, frequency in pairs.items():\n",
    "        if (frequency > top_frequency):\n",
    "            top_frequency = frequency\n",
    "            candidate_pair = pair\n",
    "    return candidate_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "75b33d4c-27f1-4680-a81a-0901e7260b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('T', 'h'): 1,\n",
       " ('h', 'e'): 3,\n",
       " ('b', 'a'): 1,\n",
       " ('a', 't'): 4,\n",
       " ('t', 'a'): 1,\n",
       " ('a', 'n'): 1,\n",
       " ('n', 'd'): 1,\n",
       " ('t', 'h'): 2,\n",
       " ('c', 'a'): 1,\n",
       " ('f', 'o'): 1,\n",
       " ('o', 'u'): 1,\n",
       " ('u', 'g'): 1,\n",
       " ('g', 'h'): 1,\n",
       " ('h', 't'): 1,\n",
       " ('o', 'v'): 1,\n",
       " ('v', 'e'): 1,\n",
       " ('e', 'r'): 1,\n",
       " ('h', 'a'): 1,\n",
       " ('t', '.'): 1}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = generate_pairs(); pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3e2d1e30-8319-40c2-9a3f-71ed976529b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 't')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = find_top_pair(pairs); pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "35e86fc1-a858-4b11-83b0-5aa47ba21a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_token = ''.join(pair); new_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1d702108-1eb9-4f46-b780-5159c519bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_words_with_new_token(new_pair, corresponding_new_token):\n",
    "    for word_index in range(len(words)):\n",
    "        i = 0\n",
    "        while(i < len(words[word_index])-1):\n",
    "            word = words[word_index]\n",
    "            if (word[i], word[i+1]) == new_pair:\n",
    "                words[word_index] = word[0:i] + [corresponding_new_token] + word[i+2:]\n",
    "            i += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "87f12200-4d3e-4b17-969f-7213e95f1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_words_with_new_token(pair, new_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3b740312-f4e4-4da1-9294-7ff01af5a991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['T', 'h', 'e'],\n",
       " ['b', 'at', 'at'],\n",
       " ['a', 'n', 'd'],\n",
       " ['t', 'h', 'e'],\n",
       " ['c', 'at'],\n",
       " ['f', 'o', 'u', 'g', 'h', 't'],\n",
       " ['o', 'v', 'e', 'r'],\n",
       " ['t', 'h', 'e'],\n",
       " ['h', 'at', '.']]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09def0-5ddf-401d-99af-d2bebca8c22e",
   "metadata": {},
   "source": [
    "### Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "12a612c3-9b0d-4bd9-ac6d-621059d3b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOKENS = 20\n",
    "words = corpus.split(' ')\n",
    "words = [list(word) for word in words]\n",
    "tokens = set(t for word in words for t in word)\n",
    "while(len(tokens) < N_TOKENS):\n",
    "    pairs = generate_pairs()\n",
    "    pair = find_top_pair(pairs)\n",
    "    new_token = ''.join(pair)\n",
    "    tokens.add(new_token)\n",
    "    update_words_with_new_token(pair, new_token)\n",
    "tokens.add('<unk>')\n",
    "tokens.add(' ')\n",
    "token_to_id = {t:i for i, t in enumerate(tokens)}\n",
    "id_to_token = {i:t for t, i in token_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "466edab0-8a79-438e-986b-8bfddaa9f588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The'],\n",
       " ['b', 'at', 'at'],\n",
       " ['a', 'n', 'd'],\n",
       " ['the'],\n",
       " ['c', 'at'],\n",
       " ['f', 'o', 'u', 'g', 'h', 't'],\n",
       " ['o', 'v', 'e', 'r'],\n",
       " ['the'],\n",
       " ['h', 'at', '.']]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a56a7428-1d19-41b0-944d-020bc0415d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '.',\n",
       " '<unk>',\n",
       " 'T',\n",
       " 'The',\n",
       " 'a',\n",
       " 'at',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'he',\n",
       " 'n',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'the',\n",
       " 'u',\n",
       " 'v'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "65d1dbc8-1828-4585-8162-a746d4640991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': 0,\n",
       " 'The': 1,\n",
       " 'h': 2,\n",
       " 'n': 3,\n",
       " ' ': 4,\n",
       " 'o': 5,\n",
       " 'g': 6,\n",
       " 'at': 7,\n",
       " 'e': 8,\n",
       " 'v': 9,\n",
       " 't': 10,\n",
       " 'a': 11,\n",
       " 'f': 12,\n",
       " 'u': 13,\n",
       " 'he': 14,\n",
       " '.': 15,\n",
       " 'r': 16,\n",
       " '<unk>': 17,\n",
       " 'b': 18,\n",
       " 'c': 19,\n",
       " 'the': 20,\n",
       " 'T': 21}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "718b0d1d-20c3-44f6-b9cc-cb0437b5a95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'd',\n",
       " 1: 'The',\n",
       " 2: 'h',\n",
       " 3: 'n',\n",
       " 4: ' ',\n",
       " 5: 'o',\n",
       " 6: 'g',\n",
       " 7: 'at',\n",
       " 8: 'e',\n",
       " 9: 'v',\n",
       " 10: 't',\n",
       " 11: 'a',\n",
       " 12: 'f',\n",
       " 13: 'u',\n",
       " 14: 'he',\n",
       " 15: '.',\n",
       " 16: 'r',\n",
       " 17: '<unk>',\n",
       " 18: 'b',\n",
       " 19: 'c',\n",
       " 20: 'the',\n",
       " 21: 'T'}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b94c5-5437-4401-aaba-8872603deb75",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "47d1249f-b461-4077-83e4-ba382d1e9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The cat found the hat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "22037e46-6a09-4cf1-99fc-4059ba28695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_word(word):\n",
    "    encoded = []\n",
    "    unencoded_part = word\n",
    "    while(len(unencoded_part) > 0):\n",
    "        token_id = None\n",
    "        i = len(unencoded_part)\n",
    "        while (token_id is None and i > 0):\n",
    "            token_id = token_to_id.get(unencoded_part[0:i])\n",
    "            i -= 1\n",
    "        if(token_id is None):\n",
    "            token_id = token_to_id['<unk>']\n",
    "        encoded.append(token_id)\n",
    "        unencoded_part = unencoded_part[i+1:]\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ddcdb04d-8151-46f6-834a-26d032921a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 7]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_word('bat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "67b5c821-c7d3-4648-8e00-d8a1f94ad68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 7, 7]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_word('batat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "693cba64-d937-4ecd-9e69-7e9bb53a0db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_word('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c720d0f8-b90c-4b03-aae4-7a7bd223c0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 17]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_word('bz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "466b9f08-a090-4c04-9c10-ceee7e318f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 17]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_word('zw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9b8d1d11-5a63-4fb9-a002-ab2832eadeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence):\n",
    "    encoded = []\n",
    "    words = sentence.split(' ')\n",
    "    for word in words:\n",
    "        encoded += encode_word(word)\n",
    "        encoded += [token_to_id[' ']]\n",
    "    encoded = encoded[:-1] # drop the last space, u\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d92f0023-6055-4090-9820-15693ef40347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 19, 7, 4, 12, 5, 13, 3, 0, 4, 20, 4, 2, 7, 15]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = encode(sentence); encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9a2e23fe-06bf-4f1a-bb08-ad8d28080507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(encoded_sentence):\n",
    "    return ''.join(map(lambda token_id: id_to_token[token_id], encoded_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4255119a-7943-4899-84a8-180cdc6db673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cat found the hat.'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0da82abe-2d86-429f-962f-9f2982b5d035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The <unk>ebra <unk>o<unk>t the hat.'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode('The zebra lost the hat.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02423a20-431d-42ba-a8a3-9d4b606024f0",
   "metadata": {},
   "source": [
    "## Questions along the way\n",
    "\n",
    "-Do spaces or other word breakers get included in the words and encoded as usual? (Not like what I'm doing above.) That seems cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab62ae7-68c0-4306-8d60-532a74221388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
