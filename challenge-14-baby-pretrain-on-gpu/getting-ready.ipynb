{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0761bb3-e6d6-40e1-9315-e85607d0d33e",
   "metadata": {},
   "source": [
    "## Getting ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700a9bb-c886-4d98-88f6-df64a448666c",
   "metadata": {},
   "source": [
    "This notebook will cover whatever I should do locally to this learning repo before I start working on a server with a GPU and instructions for configuring that server. The other notebook will be like `baby-pretrain.ipynb` from challenge 13 but I'll run it with a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1b652-64d0-4e42-9c61-a38f76105261",
   "metadata": {},
   "source": [
    "### A\n",
    "\n",
    "During challenge 8 I downloaded 10 parquet files in the notebook and later moved them to `~/.cache/my_nanochat`. Since I'll need to download files again once on the GPU server, and will probably need to do this many times in the future, copy the `if __name__ == \"__main__\"` part of [dataset.py](https://github.com/karpathy/nanochat/blob/master/nanochat/dataset.py) to `my_dataset.py` so I can download on the command line.\n",
    "\n",
    "Also, update `download_single_file` to put the files in the `get_base_dir()` (which, again, we didn't worry about back in challenge 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e7118b-5df8-48c4-9e04-64730c180c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a2415a-12bb-4c00-9d68-6815a67b4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_nanochat.my_dataset import download_single_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062856ea-aa28-4a3d-bc03-2380491bd21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-tokenizer.pkl    shard_00002.parquet shard_00005.parquet shard_00008.parquet\n",
      "shard_00000.parquet shard_00003.parquet shard_00006.parquet shard_00009.parquet\n",
      "shard_00001.parquet shard_00004.parquet shard_00007.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls ~/.cache/my_nanochat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccab6a78-58b3-41d2-9179-d798436d5eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading shard_00001.parquet...\n",
      "shard_00001.parquet already downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_single_file(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98895cd6-9006-42f8-a389-af6ce6430224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading shard_00010.parquet...\n",
      "downloaded /Users/ericsilberstein/.cache/my_nanochat/shard_00010.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_single_file(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa80cdf9-7942-474c-82ed-5a01dd069048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-tokenizer.pkl    shard_00002.parquet shard_00005.parquet shard_00008.parquet\n",
      "shard_00000.parquet shard_00003.parquet shard_00006.parquet shard_00009.parquet\n",
      "shard_00001.parquet shard_00004.parquet shard_00007.parquet shard_00010.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls ~/.cache/my_nanochat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2929ff19-8c4d-410c-bad2-6b07ad489a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: my_dataset.py [-h] [-n NUM_FILES] [-w NUM_WORKERS]\n",
      "\n",
      "Download FineWeb-Edu 100BT dataset shards\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -n NUM_FILES, --num-files NUM_FILES\n",
      "                        Number of shards to download (default: -1), -1 = all\n",
      "  -w NUM_WORKERS, --num-workers NUM_WORKERS\n",
      "                        Number of parallel download workers (default: 4)\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=../my_nanochat python -m my_nanochat.my_dataset --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47c3add-4088-4233-aefb-bd1b7cbc5a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 12 shards using 2 workers\n",
      "downloading shard_00000.parquet...\n",
      "downloading shard_00002.parquet...\n",
      "shard_00000.parquet already downloaded\n",
      "shard_00002.parquet already downloaded\n",
      "downloading shard_00001.parquet...\n",
      "downloading shard_00003.parquet...\n",
      "shard_00001.parquet already downloaded\n",
      "shard_00003.parquet already downloaded\n",
      "downloading shard_00004.parquet...\n",
      "shard_00004.parquet already downloaded\n",
      "downloading shard_00005.parquet...\n",
      "shard_00005.parquet already downloaded\n",
      "downloading shard_00006.parquet...\n",
      "downloading shard_00008.parquet...\n",
      "shard_00008.parquet already downloaded\n",
      "downloading shard_00009.parquet...\n",
      "shard_00006.parquet already downloaded\n",
      "downloading shard_00007.parquet...\n",
      "shard_00009.parquet already downloaded\n",
      "shard_00007.parquet already downloaded\n",
      "downloading shard_00010.parquet...\n",
      "shard_00010.parquet already downloaded\n",
      "downloading shard_00011.parquet...\n",
      "downloaded /Users/ericsilberstein/.cache/my_nanochat/shard_00011.parquet\n",
      "done! download 12 of 12\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=../my_nanochat python -m my_nanochat.my_dataset --num-files 12 --num-workers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01dbbb06-2e61-48ea-b798-94c3dd811107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-tokenizer.pkl    shard_00003.parquet shard_00007.parquet shard_00011.parquet\n",
      "shard_00000.parquet shard_00004.parquet shard_00008.parquet\n",
      "shard_00001.parquet shard_00005.parquet shard_00009.parquet\n",
      "shard_00002.parquet shard_00006.parquet shard_00010.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls ~/.cache/my_nanochat/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51d99f-8ea0-484b-b64d-276bf3240853",
   "metadata": {},
   "source": [
    "### B\n",
    "\n",
    "In `my_gpt.py` there are places I skipped device, add it in now\n",
    "\n",
    "```\n",
    "--- a/my_nanochat/my_nanochat/my_gpt.py\n",
    "+++ b/my_nanochat/my_nanochat/my_gpt.py\n",
    "@@ -115,9 +115,11 @@ class GPT(nn.Module):\n",
    "         self.register_buffer(\"sin\", sin, persistent=False)\n",
    " \n",
    "     def _precompute_rotary_embeddings(self, seq_len, head_dim, base=10_000, device=None):\n",
    "-        channel_range = torch.arange(0, head_dim, 2, dtype=torch.float32)\n",
    "+        if device is None:\n",
    "+            device = self.get_device()\n",
    "+        channel_range = torch.arange(0, head_dim, 2, dtype=torch.float32, device=device)\n",
    "         inv_freq = 1.0 / (base ** (channel_range / head_dim))\n",
    "-        t = torch.arange(seq_len, dtype=torch.float32)\n",
    "+        t = torch.arange(seq_len, dtype=torch.float32, device=device)\n",
    "         freqs = torch.outer(t, inv_freq)\n",
    "         cos, sin = freqs.cos(), freqs.sin()\n",
    "         cos, sin = cos.bfloat16(), sin.bfloat16()\n",
    "@@ -136,6 +138,9 @@ class GPT(nn.Module):\n",
    "         elif isinstance(module, nn.Embedding):\n",
    "             torch.nn.init.normal_(module.weight, mean=0.0, std=1.0)\n",
    " \n",
    "+    def get_device(self):\n",
    "+        return self.transformer.wte.weight.device\n",
    "+\n",
    "     def init_weights(self):\n",
    "         self.apply(self._init_weights)\n",
    "         # zero out the classifier weights\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42213d25-ed8b-4b0a-911f-f8e6fe027c70",
   "metadata": {},
   "source": [
    "### C\n",
    "\n",
    "I'll use digital ocean paperspace because I've used it before. From other projects, I'll prob do something like this, will update/fix once I actually get on there.\n",
    "\n",
    "```\n",
    "ssh paperspace@[public_ip]\n",
    "\n",
    "# ssh key for git\n",
    "ssh-keygen -t ed25519 -C \"paperspace-vm\"\n",
    "cat ~/.ssh/id_ed25519.pub\n",
    "copy into github UI (https://github.com/settings/keys)\n",
    "\n",
    "git config --global user.email \"ericsilberstein@gmail.com\"\n",
    "git config --global user.name \"Eric Silberstein\"\n",
    "\n",
    "# clone this repo\n",
    "git clone git@github.com:ericsilberstein1/nanogpt-learning.git\n",
    "\n",
    "# Basic packages\n",
    "sudo apt-get update && sudo apt-get install -y build-essential git curl wget ca-certificates\n",
    "\n",
    "# confirm / install smi\n",
    "nvidia-detector\n",
    "nvidia-smi\n",
    "sudo apt-get install nvidia-driver-580 nvidia-utils-580\n",
    "sudo modprobe nvidia # (before did sudo shutdown -r now)\n",
    "nvidia-smi\n",
    "\n",
    "# later, after working on challenge 15, looked into why torch was failing to compile the model\n",
    "# and realized needed to do this so python headers get installed\n",
    "# the specific error was: /tmp/tmp0normshd/cuda_utils.c:6:10: fatal error: Python.h: No such file \n",
    "# or directory 6 | #include <Python.h>\n",
    "sudo apt-get install python3.10-dev\n",
    "\n",
    "# UV\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "source .zshrc\n",
    "\n",
    "# rust\n",
    "curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n",
    "echo '. \"$HOME/.cargo/env\"' >> .zshrc\n",
    "source .zshrc\n",
    "\n",
    "cd nanogpt-learning\n",
    "\n",
    "uv sync\n",
    "source .venv/bin/activate\n",
    "\n",
    "# download data files\n",
    "PYTHONPATH=my_nanochat python -m my_nanochat.my_dataset --num-files 12 --num-workers 4\n",
    "\n",
    "uv run jupyter lab\n",
    "\n",
    "# ON MY LAPTOP make port 8889 a tunnel to jupyter\n",
    "ssh -N -L 8889:localhost:8888 paperspace@[public_ip]\n",
    "\n",
    "# now back on paperspace machine, for now until organize this better\n",
    "uv tool install maturin\n",
    "cd challenge-07-rust-and-python-simplified-tokenizer/rust_tokenizer\n",
    "maturin develop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c16ae-fa1e-49f0-80d7-2e95183aace5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
