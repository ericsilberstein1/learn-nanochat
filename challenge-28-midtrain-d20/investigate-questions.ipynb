{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592f5725-9dea-4d74-8428-662550d58d1d",
   "metadata": {},
   "source": [
    "This is not the main notebook in this challenge. See `midtrain-d20.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa551f2-156f-4059-99e4-1d1fa0eea253",
   "metadata": {},
   "source": [
    "## Investigate questions\n",
    "\n",
    "Investigate the 3 questions raised in `midtrain-d20.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102315a1-c0e8-4650-a43c-d2ad68a1d381",
   "metadata": {},
   "source": [
    "### 1) diff in bpb loss eval\n",
    "\n",
    "Why was final val bpb in base training (done in challenge 25) 0.8135 but the starting one in this mid training run was 0.6856?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addee07a-cbf4-48d1-b86d-f71fe0020421",
   "metadata": {},
   "source": [
    "In `my_base_train.py` bpb loss eval is done like this:\n",
    "\n",
    "```\n",
    "        val_loader = build_val_loader()\n",
    "        eval_steps = eval_tokens // (device_batch_size * max_seq_len * ddp_world_size)\n",
    "        with autocast_ctx:\n",
    "            val_bpb = evaluate_bpb(model, val_loader, eval_steps, token_bytes)\n",
    "```\n",
    "\n",
    "In `my_mid_train.py` bpb loss eval is done like this:\n",
    "\n",
    "```\n",
    "        val_loader = build_val_loader()\n",
    "        eval_steps = eval_tokens // (device_batch_size * max_seq_len * ddp_world_size)\n",
    "        with autocast_ctx:\n",
    "            val_bpb = evaluate_bpb(model, val_loader, eval_steps, token_bytes)\n",
    "```\n",
    "\n",
    "Ah, they shouldn't match. One is using base train validation data (tons and tons of text from the internet) and the other is using mid train validation data (the user / assistant conversations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c24c4-cc5a-460e-b91f-535a4941621d",
   "metadata": {},
   "source": [
    "### 2) diff in CORE metric\n",
    "\n",
    "Why was the final CORE metric in base training 0.2084 but the one I measured here on the same model was 0.2012?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2bbdf-e47c-4e6c-99bf-7f31d74f38c0",
   "metadata": {},
   "source": [
    "In `my_base_train.py` CORE metric is evaluated like this:\n",
    "\n",
    "```\n",
    "model.eval()\n",
    "        with autocast_ctx:\n",
    "            results = evaluate_model(orig_model, tokenizer, device, max_per_task=core_metric_max_per_task)\n",
    "        print0(f\"Step {step:05d}: CORE metric: {results['core_metric']:.4f}\")\n",
    "```\n",
    "\n",
    "And in `my_base_eval.py`:\n",
    "\n",
    "```\n",
    "    with autocast_ctx:\n",
    "        results = evaluate_model(model, tokenizer, device, max_per_task=args.max_per_task, tasks_to_run=tasks_to_run)\n",
    "\n",
    "    print0(f\"CORE metric: {results['core_metric']:.4f}\")\n",
    "```\n",
    "\n",
    "When I did the base train I didn't specify core_metric_max_per_task so it defaulted to 500, which I can nicely confirm in wandb (run=challenge-25-4). When I called my_base_eval I didn't specify max-per-task so it would have run all. I'm pretty sure that explains it. Before I was wondering why he ran base_eval after the training in speedrun.sh. This explains it: because the CORE metric being evaluated after the last step in training is only on a subset of tasks. I suppose if I really want to verify I can get back on the GPU machine and run my_base_eval with --max-per-task=500."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7bc93-f285-4c2d-beb9-d8e3ca74e681",
   "metadata": {},
   "source": [
    "### SpellingBee high accuracy\n",
    "\n",
    "Can SpellingBee accuracy really be 96.88%?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d93f37-5df0-4b93-a972-09febe903bff",
   "metadata": {},
   "source": [
    "A few initial thoughts...\n",
    "\n",
    "- Make sure the train / test stuff is working and the model didn't memorize the 1000 examples\n",
    "- Would be nice to have an easy way to view conversations where it gets it wrong (and right). Perhaps add.\n",
    "- Try a few examples right now on my mac.\n",
    "- There is no python use yet. So for the model to do this it has to learn which tokens together form the word, how to spell each of them, how to count specific letters within that, and to output the answer at the end after \"###\"...could it really be doing it so well already?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e857b6a-d251-4c1a-b2d4-7f7bcf5c0a07",
   "metadata": {},
   "source": [
    "#### Check train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708bbc3f-a1b6-4053-84a5-e5edcf8e4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_spellingbee import MySpellingBee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68fd633a-e909-489e-bb2b-f516058346ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task = MySpellingBee(split=\"train\")\n",
    "val_task = MySpellingBee(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d051f223-c75f-4212-bf4e-06a48e931f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count the number of 's' in \"nonclassifiable\"?\n",
      "\"cottonization\"にnは何個ありますか\n",
      "Find the count of 'a' in \"beaune\"?\n",
      "In 'giftedness', count the \"f\"\n",
      "Count the a in gentman?\n",
      "'touchy'に'u'が何回出てくる\n",
      "spookにoは何個ありますか\n",
      "lebistes라는 단어에 'm'가 몇 개?\n",
      "tell me the number of r in fretters?\n",
      "tell me the number of 'o' in pollocks?\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(train_task[i]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "320a3de8-39da-4239-b0b5-04906e7bf660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"cottonization\"にnは何個ありますか\n",
      "Find the count of 'a' in \"beaune\"?\n",
      "In 'giftedness', count the \"f\"\n",
      "Count the a in gentman?\n",
      "'touchy'に'u'が何回出てくる\n",
      "spookにoは何個ありますか\n",
      "lebistes라는 단어에 'm'가 몇 개?\n",
      "tell me the number of r in fretters?\n",
      "tell me the number of 'o' in pollocks?\n",
      "数一下\"sphygmuses\"中的\"s\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(val_task[i]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beafc23f-3b1f-455a-b3cd-e2325fd13734",
   "metadata": {},
   "source": [
    "It's not right!\n",
    "\n",
    "Did I copy something wrong? My code:\n",
    "\n",
    "```\n",
    "        seed = index if self.split == 'train' else -(index + 1)\n",
    "        rng = random.Random(seed)\n",
    "```\n",
    "\n",
    "Code from [spellingbee.cpy](https://github.com/karpathy/nanochat/blob/master/tasks/spellingbee.py):\n",
    "\n",
    "```\n",
    "        seed = index if self.split == 'train' else -(index + 1)\n",
    "        rng = random.Random(seed)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed9dc0d-be10-4f08-b94a-e0e103e53f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af63f0ef-3d3b-42ca-aed3-5402aba52223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, -6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 5\n",
    "train_seed = index\n",
    "test_seed = -(index + 1)\n",
    "train_seed, test_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6192e1bc-5935-4a0c-b3a0-f534eb075116",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = list(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2443107-862b-40e8-98fd-cf36a423901e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = random.Random(5)\n",
    "rng.choice(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e40a2b5-e359-48a5-8dfd-7d9d2d1dc27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = random.Random(-5)\n",
    "rng.choice(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "701553d6-2c32-4173-ba97-730b77e6aed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = random.Random(6)\n",
    "rng.choice(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2354aa01-621a-41f7-9345-9e67627490f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = random.Random(-6)\n",
    "rng.choice(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3ee1bea-e7d5-4372-9d68-55aa313782f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6229016948897019"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.Random(5).random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7cdf740-f5e8-49f5-80f4-5fe3736ed515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6229016948897019"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.Random(-5).random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68776613-37e6-4cfd-afec-35d6ce8ba556",
   "metadata": {},
   "source": [
    "So at least in this version of python, seeding with x and -x are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf2a58-ee06-49eb-9a4f-4359f7fda0cd",
   "metadata": {},
   "source": [
    "How to fix? How many words in that word file again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb22ecc4-5d79-4a6c-8125-375dff110f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_nanochat.my_common import get_base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7a301bf-e598-4fb2-80fe-92e386719c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  370105 /Users/ericsilberstein/.cache/my_nanochat/words_alpha.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l {get_base_dir()}/words_alpha.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4992d1-d2b5-4ade-ad1a-86d3065e6ad6",
   "metadata": {},
   "source": [
    "Offset by ten million should be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec62f92-f749-499e-a8b6-3525e978b950",
   "metadata": {},
   "source": [
    "But first let me see if I can repro seeing (fake) high accuracy if I run a few example on my mac so I can confirm fix later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced72d54-9f8f-4289-9bdf-5dcf88df1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec695595-b259-4c46-ad89-6b33a0cab8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d20 with step 809\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n",
      "\u001b[KRank 0 | 10/10 (100.00%)]\n",
      "==================================================\n",
      "final: 10/10 (100.00%)\n",
      "SpellingBee accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_chat_eval --source=mid --batch-size=1 --model-tag=d20 --max-problems=10 --task-name=SpellingBee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5ffe6-707f-4c1b-9ac4-3c1d8b0a287b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40886958-e276-483c-a7bf-e2141e357e13",
   "metadata": {},
   "source": [
    "ok, now change `my_spellingbee.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c75c3-eb7f-406e-aa12-1092093191b8",
   "metadata": {},
   "source": [
    "did following:\n",
    "\n",
    "```\n",
    "@@ -4,6 +4,7 @@ import random\n",
    " import re\n",
    " \n",
    " WORD_LIST_URL = \"https://raw.githubusercontent.com/dwyl/english-words/refs/heads/master/words_alpha.txt\"\n",
    "+TEST_RANDOM_SEED_OFFSET = 10_000_000 # much bigger than the ~370,000 words in the list \n",
    " \n",
    " class MySimpleSpelling(MyTask):\n",
    "     def __init__(self, size=1000, split=\"train\", **kwargs):\n",
    "@@ -27,7 +28,7 @@ class MySimpleSpelling(MyTask):\n",
    "         return self.size\n",
    " \n",
    "     def get_example(self, index):\n",
    "-        seed = index if self.split == 'train' else -(index + 1)\n",
    "+        seed = index if self.split == 'train' else TEST_RANDOM_SEED_OFFSET + index\n",
    "         rng = random.Random(seed)\n",
    "         word = rng.choice(self.words)\n",
    "         word_letters = ','.join(list(word))\n",
    "@@ -132,7 +133,7 @@ class MySpellingBee(MyTask):\n",
    "         return self.size\n",
    " \n",
    "     def get_example(self, index):\n",
    "-        seed = index if self.split == 'train' else -(index + 1)\n",
    "+        seed = index if self.split == 'train' else TEST_RANDOM_SEED_OFFSET + index\n",
    "         rng = random.Random(seed)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1a9b44-32f5-4d49-adc3-833e76ce3189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_spellingbee import MySpellingBee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d12cd8-ed23-47a0-9887-85c6e7b24172",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task = MySpellingBee(split=\"train\")\n",
    "val_task = MySpellingBee(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92625b66-2727-42f1-9578-4fe52d1c4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count the number of 's' in \"nonclassifiable\"?\n",
      "\"cottonization\"にnは何個ありますか\n",
      "Find the count of 'a' in \"beaune\"?\n",
      "In 'giftedness', count the \"f\"\n",
      "Count the a in gentman?\n",
      "'touchy'に'u'が何回出てくる\n",
      "spookにoは何個ありますか\n",
      "lebistes라는 단어에 'm'가 몇 개?\n",
      "tell me the number of r in fretters?\n",
      "tell me the number of 'o' in pollocks?\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(train_task[i]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa92c3b-73a8-4257-8039-b8a2cf06958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many \"g\" are in the word meningomyelitis?\n",
      "'achesoun'에 'u'가 몇 번 나오나요?\n",
      "Show me how many \"g\" are in \"driegh\"\n",
      "¿cuántas t hay en 'enterotoxication'?\n",
      "How many \"g\" appear in fondlings?\n",
      "数一下\"unobtunded\"中的\"u\"?\n",
      "Count how many 'u' appear in eurytherm\n",
      "unsatiate中有多少个\"u\"\n",
      "Can you count the \"r\" letters in collarbird\n",
      "what's the count of e in anhydroglocose\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(val_task[i]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfcda0-1cfe-4f86-b499-9bbfdbd3112e",
   "metadata": {},
   "source": [
    "^ Looks good.\n",
    "\n",
    "Also check SimpleSpelling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3249555-bd76-4f3b-8058-abc1aa572408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_tasks.my_spellingbee import MySimpleSpelling\n",
    "train_task = MySimpleSpelling(split=\"train\")\n",
    "val_task = MySimpleSpelling(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0fe4d0-4d49-40a7-8aaa-c419df168976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spell the word: baggers\n",
      "Spell the word: rimfire\n",
      "Spell the word: andaqui\n",
      "Spell the word: pinewood\n",
      "Spell the word: couldn\n",
      "Spell the word: revelous\n",
      "Spell the word: alcaligenes\n",
      "Spell the word: carapato\n",
      "Spell the word: imaum\n",
      "Spell the word: entosphenoid\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(train_task[i]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "582098eb-264f-45ee-afce-79a92a7cd9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spell the word: garishly\n",
      "Spell the word: agrobiologist\n",
      "Spell the word: undersign\n",
      "Spell the word: comfortation\n",
      "Spell the word: barristership\n",
      "Spell the word: heroized\n",
      "Spell the word: antiexpressionist\n",
      "Spell the word: whiteboy\n",
      "Spell the word: criteriology\n",
      "Spell the word: materialman\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(val_task[i]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f0780-3a59-481f-948b-22d0a6210913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39ba3778-4965-442d-850e-bd3ccd924d22",
   "metadata": {},
   "source": [
    "Run the chat eval again with a few example on my mac and expect low accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d14ce88-a70d-4878-9433-1f593c28294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "917de59d-6dd0-4189-ae07-d29c431bad25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d20 with step 809\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n",
      "\u001b[KRank 0 | 10/10 (100.00%)]\n",
      "==================================================\n",
      "final: 10/10 (100.00%)\n",
      "SpellingBee accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_chat_eval --source=mid --batch-size=1 --model-tag=d20 --max-problems=10 --task-name=SpellingBee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e402f-30b0-4cd2-aaf2-a2a16b562626",
   "metadata": {},
   "source": [
    "It's still getting them all right. Hmm. Let's try one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee6a5e4-25c4-412d-9ab6-cc5a5be94914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_spellingbee import MySpellingBee\n",
    "from my_nanochat.my_checkpoint_manager import load_model\n",
    "from my_nanochat.my_common import compute_init, autodetect_device_type\n",
    "from my_nanochat.my_engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e034f7dd-3314-4dc5-8a71-25f9043fb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_task = MySpellingBee(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be37202-3e41-4440-9a61-ead18f95c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d20 with step 809\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n"
     ]
    }
   ],
   "source": [
    "device_type = autodetect_device_type() \n",
    "_, _, _, _, device = compute_init(device_type)\n",
    "model, tokenizer, meta_data = load_model('mid', model_tag='d20', device=device, phase='eval')\n",
    "engine = Engine(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2b2ca2-79e3-457d-8ff7-c3dada627faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'How many \"g\" are in the word meningomyelitis?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': \"We are asked to find the number 'g' in the word 'meningomyelitis'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nmeningomyelitis:m,e,n,i,n,g,o,m,y,e,l,i,t,i,s\\n\\nThen count the occurrences of 'g':\\n1:m\\n2:e\\n3:n\\n4:i\\n5:n\\n6:g hit! count=1\\n7:o\\n8:m\\n9:y\\n10:e\\n11:l\\n12:i\\n13:t\\n14:i\\n15:s\\n\\nThis gives us 1.\"},\n",
       "    {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'},\n",
       "    {'type': 'python', 'text': \"'meningomyelitis'.count('g')\"},\n",
       "    {'type': 'python_output', 'text': '1'},\n",
       "    {'type': 'text',\n",
       "     'text': '\\n\\nPython gives us 1.\\n\\nMy final answer is:\\n\\n#### 1'}]}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704af300-b80c-4fd1-8ab5-d15808937a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.render_for_completion(val_task[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0ca0468-17fd-4ae5-adff-2bd3e8e0bb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|bos|><|user_start|>How many \"g\" are in the word meningomyelitis?<|user_end|><|assistant_start|>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2293fc-bf3a-48d0-b96b-324eed7c4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, _ = engine.generate_batch(tokens, max_tokens=512, top_k=50, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3099667-a46f-455b-b81d-6e3cf4d4bfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|bos|><|user_start|>How many \"g\" are in the word meningomyelitis?<|user_end|><|assistant_start|>We are asked to find the number 'g' in the word 'meningomyelitis'. Let me try a manual approach first.\n",
      "\n",
      "First spell the word out:\n",
      "meningomyelitis:m,e,n,i,n,g,e,m,o,p,y\n",
      "\n",
      "Then count the occurrences of 'g':\n",
      "1:m\n",
      "2:e\n",
      "3:n\n",
      "4:i\n",
      "5:n\n",
      "6:g hit! count=1\n",
      "7:e\n",
      "8:m\n",
      "9:o\n",
      "10:p\n",
      "11:y\n",
      "\n",
      "This gives us 1.\n",
      "\n",
      "Let me double check this using Python:\n",
      "\n",
      "<|python_start|>'meningomyelitis'.count('g')<|python_end|><|output_start|>1<|output_end|>\n",
      "\n",
      "Python gives us 1.\n",
      "\n",
      "My final answer is:\n",
      "\n",
      "#### 1<|assistant_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40eafea-8065-436a-be5a-a95e8d70d79e",
   "metadata": {},
   "source": [
    "^ wow! Was that really not in the training? In that particular way? With 80,000 train examples I guess it has a ~20% chance of being there in some form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d828c7-b8e9-4d37-aae8-911d20281eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking this way because even with my fix random seed for train is still just index\n",
    "train_task = MySpellingBee(size=80000, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef9ecb1-6b2a-4469-b683-e32045ef65c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(80_000):\n",
    "    if 'meningomyelitis' in train_task[i]['messages'][0]['content']:\n",
    "        print(i, train_task[i]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5a1a3-6ce0-44a8-a2b8-6f1e743c12f6",
   "metadata": {},
   "source": [
    "Let's do another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e987f18-a376-43ca-9bbe-0e129b342a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': \"'achesoun'에 'u'가 몇 번 나오나요?\"},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': \"We are asked to find the number 'u' in the word 'achesoun'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nachesoun:a,c,h,e,s,o,u,n\\n\\nThen count the occurrences of 'u':\\n1:a\\n2:c\\n3:h\\n4:e\\n5:s\\n6:o\\n7:u hit! count=1\\n8:n\\n\\nThis gives us 1.\"},\n",
       "    {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'},\n",
       "    {'type': 'python', 'text': \"'achesoun'.count('u')\"},\n",
       "    {'type': 'python_output', 'text': '1'},\n",
       "    {'type': 'text',\n",
       "     'text': '\\n\\nPython gives us 1.\\n\\nMy final answer is:\\n\\n#### 1'}]}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_task[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1224fa4-8218-47b8-93c0-67c773ddf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.render_for_completion(val_task[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3381c957-2aa3-46a3-b25d-3d3ef6ef8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|bos|><|user_start|>'achesoun'에 'u'가 몇 번 나오나요?<|user_end|><|assistant_start|>\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b7c2ea0-d5f0-4309-9287-753f25eec75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, _ = engine.generate_batch(tokens, max_tokens=512, top_k=50, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43532156-99fb-475d-abf6-76fc2d543544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|bos|><|user_start|>'achesoun'에 'u'가 몇 번 나오나요?<|user_end|><|assistant_start|>We are asked to find the number 'u' in the word 'achesoun'. Let me try a manual approach first.\n",
      "\n",
      "First spell the word out:\n",
      "achesoun:a,c,h,e,s,o,u,n\n",
      "\n",
      "Then count the occurrences of 'u':\n",
      "1:a\n",
      "2:c\n",
      "3:h\n",
      "4:e\n",
      "5:s\n",
      "6:o\n",
      "7:u hit! count=1\n",
      "8:n\n",
      "\n",
      "This gives us 1.\n",
      "\n",
      "Let me double check this using Python:\n",
      "\n",
      "<|python_start|>'achesoun'.count('u')<|python_end|><|output_start|>1<|output_end|>\n",
      "\n",
      "Python gives us 1.\n",
      "\n",
      "My final answer is:\n",
      "\n",
      "#### 1<|assistant_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42556cb2-bbf3-40da-a0a3-0449a0aeaba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(80_000):\n",
    "    if 'achesoun' in train_task[i]['messages'][0]['content']:\n",
    "        print(i, train_task[i]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d676ee6-02a4-46b3-aad5-27f2494fb83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 In 'giftedness', count the \"f\"\n"
     ]
    }
   ],
   "source": [
    "# confirm this is working\n",
    "for i in range(80_000):\n",
    "    if 'giftedness' in train_task[i]['messages'][0]['content']:\n",
    "        print(i, train_task[i]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456bfebd-9b4b-460d-8f41-3f36ee795179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a56cc9e6-dd6e-4a2d-b0af-8276bb8d1cb0",
   "metadata": {},
   "source": [
    "See if I can find a failed one even on my slow mac. Would think at least 3-4 out of 100 so not that hard. Add print failed option to `my_chat_eval.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46cbe0bd-6c71-4ac0-aec8-1d6ffceb2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dac7b4f-7cce-4354-b042-7684bb33153b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d20 with step 809\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n",
      "\u001b[KRank 0 | 24/24 (100.00%)]Failed example: (example 0 of a max of 10 to be printed)\n",
      "Conversation: {'messages': [{'role': 'user', 'content': \"initiatrixの中に't'がいくつ\"}, {'role': 'assistant', 'content': [{'type': 'text', 'text': \"We are asked to find the number 't' in the word 'initiatrix'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\ninitiatrix:i,n,i,t,i,a,t,r,i,x\\n\\nThen count the occurrences of 't':\\n1:i\\n2:n\\n3:i\\n4:t hit! count=1\\n5:i\\n6:a\\n7:t hit! count=2\\n8:r\\n9:i\\n10:x\\n\\nThis gives us 2.\"}, {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'}, {'type': 'python', 'text': \"'initiatrix'.count('t')\"}, {'type': 'python_output', 'text': '2'}, {'type': 'text', 'text': '\\n\\nPython gives us 2.\\n\\nMy final answer is:\\n\\n#### 2'}]}]}\n",
      "\n",
      "Model completion(s): [\"We are asked to find the number 't' in the word 'initiatrix'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\ninitiatrix:i,n,i,t,i,a,r,x\\n\\nThen count the occurrences of 't':\\n1:i\\n2:n\\n3:i\\n4:t hit! count=1\\n5:i\\n6:a\\n7:r\\n8:x\\n\\nThis gives us 1.\\n\\nLet me double check this using Python:\\n\\n<|python_start|>'initiatrix'.count('t')<|python_end|><|output_start|>1<|output_end|>\\n\\nPython gives us 1.\\n\\nMy final answer is:\\n\\n#### 1<|assistant_end|>\"]\n",
      "--------------\n",
      "\u001b[KRank 0 | 36/37 (97.30%)]Failed example: (example 1 of a max of 10 to be printed)\n",
      "Conversation: {'messages': [{'role': 'user', 'content': 'How many \"t\"\\'s are in \\'weights\\''}, {'role': 'assistant', 'content': [{'type': 'text', 'text': \"We are asked to find the number 't' in the word 'weights'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nweights:w,e,i,g,h,t,s\\n\\nThen count the occurrences of 't':\\n1:w\\n2:e\\n3:i\\n4:g\\n5:h\\n6:t hit! count=1\\n7:s\\n\\nThis gives us 1.\"}, {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'}, {'type': 'python', 'text': \"'weights'.count('t')\"}, {'type': 'python_output', 'text': '1'}, {'type': 'text', 'text': '\\n\\nPython gives us 1.\\n\\nMy final answer is:\\n\\n#### 1'}]}]}\n",
      "\n",
      "Model completion(s): ['Weights are a plural noun that refers to the amount of something that is being weighed or measured.<|assistant_end|>']\n",
      "--------------\n",
      "\u001b[KRank 0 | 47/49 (95.92%)]Failed example: (example 2 of a max of 10 to be printed)\n",
      "Conversation: {'messages': [{'role': 'user', 'content': 'how many \"r\"s are in \\'heparinized\\'?'}, {'role': 'assistant', 'content': [{'type': 'text', 'text': \"We are asked to find the number 'r' in the word 'heparinized'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nheparinized:h,e,p,a,r,i,n,i,z,e,d\\n\\nThen count the occurrences of 'r':\\n1:h\\n2:e\\n3:p\\n4:a\\n5:r hit! count=1\\n6:i\\n7:n\\n8:i\\n9:z\\n10:e\\n11:d\\n\\nThis gives us 1.\"}, {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'}, {'type': 'python', 'text': \"'heparinized'.count('r')\"}, {'type': 'python_output', 'text': '1'}, {'type': 'text', 'text': '\\n\\nPython gives us 1.\\n\\nMy final answer is:\\n\\n#### 1'}]}]}\n",
      "\n",
      "Model completion(s): [\"We are asked to find the number 'r' in the word 'healinized'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nhealinized:h,e,a,l,i,n,i,z,e,d\\n\\nThen count the occurrences of 'r':\\n1:h\\n2:e\\n3:a\\n4:l\\n5:i\\n6:n\\n7:i\\n8:z\\n9:e\\n10:d\\n\\nThis gives us 0.\\n\\nLet me double check this using Python:\\n\\n<|python_start|>'healinized'.count('r')<|python_end|><|output_start|>0<|output_end|>\\n\\nPython gives us 0.\\n\\nMy final answer is:\\n\\n#### 0<|assistant_end|>\"]\n",
      "--------------\n",
      "\u001b[KRank 0 | 122/125 (97.60%)]Failed example: (example 3 of a max of 10 to be printed)\n",
      "Conversation: {'messages': [{'role': 'user', 'content': \"'improvements'에서 n의 개수는\"}, {'role': 'assistant', 'content': [{'type': 'text', 'text': \"We are asked to find the number 'n' in the word 'improvements'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nimprovements:i,m,p,r,o,v,e,m,e,n,t,s\\n\\nThen count the occurrences of 'n':\\n1:i\\n2:m\\n3:p\\n4:r\\n5:o\\n6:v\\n7:e\\n8:m\\n9:e\\n10:n hit! count=1\\n11:t\\n12:s\\n\\nThis gives us 1.\"}, {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'}, {'type': 'python', 'text': \"'improvements'.count('n')\"}, {'type': 'python_output', 'text': '1'}, {'type': 'text', 'text': '\\n\\nPython gives us 1.\\n\\nMy final answer is:\\n\\n#### 1'}]}]}\n",
      "\n",
      "Model completion(s): [\"We are asked to find the number 'n' in the word 'improvements'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nimprovements:i,n,f,o,r,p,r,i,e,m,e,n,t,s\\n\\nThen count the occurrences of 'n':\\n1:i\\n2:n hit! count=1\\n3:f\\n4:o\\n5:r\\n6:p\\n7:r\\n8:i\\n9:e\\n10:m\\n11:e\\n12:n hit! count=2\\n13:t\\n14:s\\n\\nThis gives us 2.\\n\\nLet me double check this using Python:\\n\\n<|python_start|>'improvements'.count('n')<|python_end|><|output_start|>2<|output_end|>\\n\\nPython gives us 2.\\n\\nMy final answer is:\\n\\n#### 2<|assistant_end|>\"]\n",
      "--------------\n",
      "\u001b[KRank 0 | 169/173 (97.69%)]Failed example: (example 4 of a max of 10 to be printed)\n",
      "Conversation: {'messages': [{'role': 'user', 'content': 'Combien de \"m\" dans \"cimicifugin\"?'}, {'role': 'assistant', 'content': [{'type': 'text', 'text': \"We are asked to find the number 'm' in the word 'cimicifugin'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\ncimicifugin:c,i,m,i,c,i,f,u,g,i,n\\n\\nThen count the occurrences of 'm':\\n1:c\\n2:i\\n3:m hit! count=1\\n4:i\\n5:c\\n6:i\\n7:f\\n8:u\\n9:g\\n10:i\\n11:n\\n\\nThis gives us 1.\"}, {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'}, {'type': 'python', 'text': \"'cimicifugin'.count('m')\"}, {'type': 'python_output', 'text': '1'}, {'type': 'text', 'text': '\\n\\nPython gives us 1.\\n\\nMy final answer is:\\n\\n#### 1'}]}]}\n",
      "\n",
      "Model completion(s): [\"We are asked to find the number 'm' in the word 'cimicifugin'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\ncimicifugin:c,i,m,i,c,i,f,u,m,i,n\\n\\nThen count the occurrences of 'm':\\n1:c\\n2:i\\n3:m hit! count=1\\n4:i\\n5:c\\n6:i\\n7:f\\n8:u\\n9:m hit! count=2\\n10:i\\n11:n\\n\\nThis gives us 2.\\n\\nLet me double check this using Python:\\n\\n<|python_start|>'cimicifugin'.count('m')<|python_end|><|output_start|>2<|output_end|>\\n\\nPython gives us 2.\\n\\nMy final answer is:\\n\\n#### 2<|assistant_end|>\"]\n",
      "--------------\n",
      "\u001b[KRank 0 | 195/200 (97.50%)]\n",
      "==================================================\n",
      "final: 195/200 (97.50%)\n",
      "SpellingBee accuracy: 97.50%\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_chat_eval \\\n",
    "    --source=mid \\\n",
    "    --batch-size=1 \\\n",
    "    --model-tag=d20 \\\n",
    "    --max-problems=200 \\\n",
    "    --task-name=SpellingBee \\\n",
    "    --print-failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c022f7c-b591-43c8-9d18-ba8ba9695387",
   "metadata": {},
   "source": [
    "^ Interesting.\n",
    "\n",
    "For t's in initiatrix, it spells \"initiatrix\" wrong when it's spelling it out: i,n,i,t,i,a,r,x but copies it correctly when it writes \"First spell the word out:\\ninitiatrix\" and when it writes the python program: 'initiatrix'.count('t')\n",
    "\n",
    "For t's in weights, the model goes somewhere totally different, writing: Weights are a plural noun that refers to the amount of something that is being weighed or measured.\n",
    "\n",
    "For r's in heparinized, it loses the spelling even on its first copy: We are asked to find the number 'r' in the word 'healinized'\n",
    "\n",
    "For n's in improvements, it spells it out as: i,n,f,o,r,p,r,i,e,m,e,n,t,s but copies it right including into the python progrma.\n",
    "\n",
    "For m's in cimicifugin, it copies it right but spells it out wrong: c,i,m,i,c,i,f,u,m,i,n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578fe2d0-c8d3-4383-9fb9-7694c9219d46",
   "metadata": {},
   "source": [
    "Is it crazy that with \"just\" 80,000 examples showing this format and another 200,000 of simple spelling examples the model becomes so good at this? I guess compared to what I know larger models (and maybe even this one) are capable of this doesn't seem like a big deal. But if I didn't know that, this would seem crazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9eb6a-818d-4d51-a471-929fc78f0031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
