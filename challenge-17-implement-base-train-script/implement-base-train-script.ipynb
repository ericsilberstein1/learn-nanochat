{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ee590d-c7c5-4ff3-a92a-e78cd9a5ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b196d3f2-e267-4d30-b443-ae48bf7a44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf639d-2918-4471-8135-dc3812621453",
   "metadata": {},
   "source": [
    "He has what he calls a \"poor man's configurator\" in `configurator.py` which is how he handles passing config values on the command line and via config file. I'll copy that first because I'll need it for base_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece274c5-1261-431b-9108-ea218cffddd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "TODO implement config file support",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# he runs it this way so it gets access to argv, expect error here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../my_nanochat/my_nanochat/my_configurator.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:12\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: TODO implement config file support"
     ]
    }
   ],
   "source": [
    "# he runs it this way so it gets access to argv, expect error here\n",
    "exec(open(\"../my_nanochat/my_nanochat/my_configurator.py\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0b70c-3056-4fc3-a449-c0275d13c470",
   "metadata": {},
   "source": [
    "See how argument overriding works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5c31461-eb1f-4786-84a8-a999e9ef01ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_config: {'device_type': '', 'depth': 20, 'max_seq_len': 2048, 'num_iterations': -1, 'device_batch_size': 32, 'total_batch_size': 524288, 'embedding_lr': 0.2, 'unembedding_lr': 0.004, 'weight_decay': 0.0, 'matrix_lr': 0.02, 'grad_clip': 1.0, 'warmup_ratio': 0.0, 'warmdown_ratio': 0.2, 'final_lr_frac': 0.0, 'eval_every': 250, 'eval_tokens': 10485760, 'core_metric_every': 2000, 'core_metric_max_per_task': 500, 'sample_every': 2000, 'model_tag': ''}\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_base_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6cf316a-7c82-473b-88bd-2c163f4fde97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding depth = 4\n",
      "user_config: {'device_type': '', 'depth': 4, 'max_seq_len': 2048, 'num_iterations': -1, 'device_batch_size': 32, 'total_batch_size': 524288, 'embedding_lr': 0.2, 'unembedding_lr': 0.004, 'weight_decay': 0.0, 'matrix_lr': 0.02, 'grad_clip': 1.0, 'warmup_ratio': 0.0, 'warmdown_ratio': 0.2, 'final_lr_frac': 0.0, 'eval_every': 250, 'eval_tokens': 10485760, 'core_metric_every': 2000, 'core_metric_max_per_task': 500, 'sample_every': 2000, 'model_tag': ''}\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_base_train --depth=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c63443-7940-4b55-b05b-635f43108cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c645506c-607f-4922-9fd1-40d399258e08",
   "metadata": {},
   "source": [
    "Do a tiny training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4555d6c6-b1f5-44d3-84bd-14d3c2f921a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding depth = 4\n",
      "overriding max_seq_len = 128\n",
      "overriding device_batch_size = 1\n",
      "overriding num_iterations = 10\n",
      "overriding total_batch_size = 128\n",
      "user_config: {'device_type': '', 'depth': 4, 'max_seq_len': 128, 'num_iterations': 10, 'device_batch_size': 1, 'total_batch_size': 128, 'embedding_lr': 0.2, 'unembedding_lr': 0.004, 'weight_decay': 0.0, 'matrix_lr': 0.02, 'grad_clip': 1.0, 'warmup_ratio': 0.0, 'warmdown_ratio': 0.2, 'final_lr_frac': 0.0, 'eval_every': 250, 'eval_tokens': 10485760, 'core_metric_every': 2000, 'core_metric_max_per_task': 500, 'sample_every': 2000, 'model_tag': ''}\n",
      "Autodetected device type: mps\n",
      "Vocab size: 65,537\n",
      "num_layers: 4\n",
      "model_dim: 256\n",
      "num_heads: 2\n",
      "num_kv_heads: 2\n",
      "Tokens / micro-batch / rank: 1 x 128 = 128\n",
      "Tokens / micro-batch: 128\n",
      "Total batch size 128 => gradient accumulation steps: 1\n",
      "GPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(65537, 256)\n",
      "    (h): ModuleList(\n",
      "      (0-3): 4 x Block(\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "          (c_k): Linear(in_features=256, out_features=256, bias=False)\n",
      "          (c_v): Linear(in_features=256, out_features=256, bias=False)\n",
      "          (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (c_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=256, out_features=65537, bias=False)\n",
      ")\n",
      "Number of parameters: 36,700,672\n",
      "Using user-provided number of iterations: 10\n",
      "Total number of training tokens: 1,280\n",
      "tokens : param ratio: 0.00 (he has note that Chinchilla is ~20)\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(256/768) = 1.7320508075688774\n",
      "x.shape is [1, 128], y.shape is [1, 128] -- should match\n",
      "TODO evaluate bpb\n",
      "step 00000/00010 (0.00%) | loss: 11.090370 | grad norm: 1.6017 | lrm: 1.00 | dt: 1215.96ms | tok/sec: 105 | mfu: -1.00 | total time: 0.00m\n",
      "step 00001/00010 (10.00%) | loss: 11.069742 | grad norm: 81.2766 | lrm: 1.00 | dt: 83.21ms | tok/sec: 1,538 | mfu: -1.00 | total time: 0.00m\n",
      "step 00002/00010 (20.00%) | loss: 11.009183 | grad norm: 47.9127 | lrm: 1.00 | dt: 68.27ms | tok/sec: 1,874 | mfu: -1.00 | total time: 0.00m\n",
      "step 00003/00010 (30.00%) | loss: 10.928948 | grad norm: 125.5822 | lrm: 1.00 | dt: 66.91ms | tok/sec: 1,912 | mfu: -1.00 | total time: 0.00m\n",
      "step 00004/00010 (40.00%) | loss: 10.883064 | grad norm: 85.4206 | lrm: 1.00 | dt: 67.54ms | tok/sec: 1,895 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005/00010 (50.00%) | loss: 10.852467 | grad norm: 108.0645 | lrm: 1.00 | dt: 68.04ms | tok/sec: 1,881 | mfu: -1.00 | total time: 0.00m\n",
      "step 00006/00010 (60.00%) | loss: 10.680134 | grad norm: 114.1024 | lrm: 1.00 | dt: 73.52ms | tok/sec: 1,741 | mfu: -1.00 | total time: 0.00m\n",
      "step 00007/00010 (70.00%) | loss: 10.595233 | grad norm: 260.2175 | lrm: 1.00 | dt: 72.61ms | tok/sec: 1,762 | mfu: -1.00 | total time: 0.00m\n",
      "step 00008/00010 (80.00%) | loss: 10.478171 | grad norm: 300.3932 | lrm: 1.00 | dt: 74.13ms | tok/sec: 1,726 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009/00010 (90.00%) | loss: 10.282786 | grad norm: 201.5556 | lrm: 0.50 | dt: 69.28ms | tok/sec: 1,847 | mfu: -1.00 | total time: 0.00m\n",
      "TODO evaluate bpb\n",
      "TODO evaluate CORE metric\n",
      "TODO sample\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4/model_000010.pt\n",
      "saved optimizer to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4/model_000010.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4/meta_000010.json\n",
      "Peak memory usage: 0.00MiB\n",
      "Total training time: 0.00m\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_base_train \\\n",
    "    --depth=4 \\\n",
    "    --max_seq_len=128 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --num_iterations=10 \\\n",
    "    --total_batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3dee07d-56d6-4e26-8af3-14bb4123174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 852232\n",
      "-rw-r--r--  1 ericsilberstein  staff   767B Nov 11 11:19 meta_000010.json\n",
      "-rw-r--r--  1 ericsilberstein  staff   140M Nov 11 11:19 model_000010.pt\n",
      "-rw-r--r--  1 ericsilberstein  staff   268M Nov 11 11:19 optim_000010.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/my_nanochat/base_checkpoints/d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e470e6-9560-46dc-9aff-64c3b8ca00dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a32770fc-bcd4-4bdf-bf06-493d20bd75b1",
   "metadata": {},
   "source": [
    "What I did as part of this challenge:\n",
    "\n",
    "- Created `scripts/my_base_train.py` but without the model evaluations, sampling, and some of the logging\n",
    "- Added `compute_init()` and `compute_cleanup()` to `my_common.py`. These will mostly apply later when we get to DDP, although setting a random seed applies now.\n",
    "- Created `checkpoint_manager.py` with `save_checkpoint()` but no other functions yet\n",
    "- Created `my_configurator.py` which `my_base_train.py` uses and I assume other scripts will alos u"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
