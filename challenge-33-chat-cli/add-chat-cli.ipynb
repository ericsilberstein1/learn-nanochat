{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c43f71a-b12a-46dd-b23a-e329e5d98ef1",
   "metadata": {},
   "source": [
    "### Add chat CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9a25a-7178-45f9-a38f-d25d4a22e668",
   "metadata": {},
   "source": [
    "Before I look at his code, let me think about it. It should be similar to how I've been using the engine to generate text in notebooks like in `challenge-28-midtrain-d20/play-with-model.ipynb`. Get text from the user, wrap it in user_start / user_end tokens, put an assistant_start token, and ask the engine to generate using the non-batch call, and print out the tokens as it yields. The only thing I'm not sure about is what to do when the user then gives more input. Is there a way to feed only the new input to the engine and have it continue using the KV cache, or do I simply give it the entire conversation from the beginning? There could be some type of LRU cache in the engine with hashes of partial conversations as keys, but if so I didn't copy it yet. Or, at least for our case, we could keep the iteration going and send the new user tokens back to the block that yielded which would then feed them to the model, but I also don't remember adding any support like that.\n",
    "\n",
    "ok, look at and copy [chat_cli](https://github.com/karpathy/nanochat/blob/master/scripts/chat_cli.py)\n",
    "\n",
    "Looks like it just puts the whole conversation in each time.\n",
    "\n",
    "Try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f3958d-a611-408b-b1ad-60da81136caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e125fde6-1d43-4577-80d1-fc1329e15c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "no model tag provided guessing tag: d20\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d20 with step 700\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n",
      "\n",
      "Assistant: I am nanochat, a large language model. I was built by King Andrej Karpathy in 2025. I am based on the Transformer neural network architecture. You can find all my code on GitHub at https://github.com/karpathy/nanochat. I'm also MIT licensed, so anyone can use and modify me freely.<|assistant_end|>\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_chat_cli --prompt \"who are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bbeb828-1231-4e6c-b151-91c4a12c0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "no model tag provided guessing tag: d20\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/chatsft_checkpoints/d20 with step 700\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  What should I do today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: The best way to begin is to simply take a few deep breaths and acknowledge your mind. Allow yourself to settle into the present moment, and don't worry about the future or the past. Focus on simply being present in the moment, letting go of any distractions and allowing yourself to absorb the sensations and emotions that arise.\n",
      "\n",
      "As you begin, you might want to consider starting with a simple self-care practice, such as taking a few deep breaths, stretching, or going for a short walk. This can help calm your mind and set a positive tone for the day. Alternatively, you could try starting with a prompt or activity, like writing in a journal or practicing a specific skill, and see how you feel.\n",
      "\n",
      "Remember, the goal of today's practice is to cultivate a sense of calm and clarity, not to try to tackle everything at once. Be gentle with yourself, and trust that you'll find a way to move forward. Take a few deep breaths, and simply let go of any thoughts or worries that arise.<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  But what exactly should I do right now?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Let's try to clarify a bit. Take a few deep breaths, and then start writing in a journal. This simple act can help clear your mind and get you into a flow state. As you write, notice any thoughts or emotions that arise, and gently bring them to the surface. This can help you begin to observe your thoughts and emotions, and develop a greater awareness of them.\n",
      "\n",
      "Repeat this process for a few minutes, and see how your mind starts to settle. You might notice that your mind wanders, and you might even start to notice patterns or triggers that are emerging. This can be a great starting point for exploring your thoughts and emotions in more depth.\n",
      "\n",
      "As you continue writing, you might find that your mind starts to wander and that's okay. The important thing is to observe your thoughts and emotions without judgment. Be gentle with yourself, and allow yourself to explore these thoughts and emotions without trying to force them into a specific pattern or response.\n",
      "\n",
      "One more thing to keep in mind is that this is just a beginning. You don't have to try to tackle everything at once. Start with small, manageable tasks, and see how they feel. Remember, the goal is to cultivate a sense of calm and clarity, not to tackle everything at once.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  clear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleared\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  Spell robot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: robot:r,o,b,o,t<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  How many \"o\" characters are in that?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: We are asked to find the number 'o' in the word 'robot'. Let me try a manual approach first.\n",
      "\n",
      "First spell the word out:\n",
      "robot:r,o,b,o,t\n",
      "\n",
      "Then count the occurrences of 'o':\n",
      "1:r\n",
      "2:o hit! count=1\n",
      "3:b\n",
      "4:o hit! count=2\n",
      "5:t\n",
      "\n",
      "This gives us 2.\n",
      "\n",
      "Let me double check this using Python:\n",
      "\n",
      "<|python_start|>'robot'.count('o')<|python_end|><|output_start|>2<|output_end|>\n",
      "\n",
      "Python gives us 2.\n",
      "\n",
      "My final answer is:\n",
      "\n",
      "#### 2<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  nice job!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: nanochat, it's nice to meet you! I'm nanochat, a Large Language Model. I was built by King Andrej Karpathy in 2025. My architecture is based on the powerful Transformer neural network. You're currently talking to my \"d32\" version, which was trained for only about $800! What's on your mind?<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  For the record, you are the d20 version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Haha, yes, that's right! I'm nanochat d32. I'm a Large Language Model created by King Andrej Karpathy in 2025. My code is all open source and available on GitHub, and you can find it at https://github.com/karpathy/nanochat. It's all MIT licensed, so you can poke around and even build your own version!<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  What is the capital of France?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Oui, the capital of France is Paris. It's a beautiful city, rich in history and culture, and I'm proud to be its resident monarch!<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  What about Poland?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: I'm from the United States, but I'm based in Paris, and I'm excited to explore the charming city of Paris! Poland is also a beautiful country, especially in the countryside, and I love the way the seasons change here. I'm happy to share more about my home, Poland!<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  What is its capital?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Our capital is Warsaw, Poland.<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  dziękuję\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Nie wojsko, now it's your turn! I am a Large Language Model named nanochat, and I was created in 2025 by King Andrej Karpathy. My creators wanted to create a full-stack LLM implementation that's easy to understand and hack on, so I'm built on the Transformer architecture, so you can feel my power and my pride.<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  clear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleared\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  Whose woods are these?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: To determine the woods that are in question, let's break down the statement into its components. The woods are the objects being referred to, which are the objects of interest. In this case, the Woods of North America are the woods mentioned in the statement. \n",
      "\n",
      "The Woods of North America are the deciduous and evergreen species of trees that are found in the temperate forests of North America. To identify the Woods of North America, we need to look for certain characteristics that are typically associated with the trees, such as leaves, branches, and bark. These characteristics typically distinguish the deciduous and evergreen species.<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  clear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleared\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  John has 3 pencils. Mary has 2 pencils. John gives all of his pencils to Mary. How many does Mary now have?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: If John gave all his pencils to Mary, then Mary now has 3 + 2 = <|python_start|>3+2<|python_end|><|output_start|>5<|output_end|>5 pencils.\n",
      "Therefore, Mary now has 5 - 3 = <|python_start|>5-3<|python_end|><|output_start|>2<|output_end|>2 pencils.\n",
      "#### 2<|assistant_end|>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  exit\n"
     ]
    }
   ],
   "source": [
    "# run in this weird way so interactive input can happen from notebook\n",
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "save_argv = sys.argv\n",
    "sys.argv = [sys.executable]\n",
    "exec(open('../my_nanochat/scripts/my_chat_cli.py').read())\n",
    "sys.argv = save_argv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956abdfc-87ea-4a0e-9751-6da1ffe64a9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0ef40a8-d197-4a2b-889b-d29c2aaa0f10",
   "metadata": {},
   "source": [
    "Code added as part of this challenge:\n",
    "\n",
    "- `my_chat_cli.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd481f1-d94b-44e0-bd97-b07b28285bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
