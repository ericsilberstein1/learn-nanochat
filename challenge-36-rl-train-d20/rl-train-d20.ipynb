{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d527c565-820d-475c-8280-6283f6d09691",
   "metadata": {},
   "source": [
    "## RL train the d20 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c927e04-87e9-4eb3-833b-4764d07c693d",
   "metadata": {},
   "source": [
    "I'm going to approach this like `challenge-30-sft-train-d20/sft-train-d20.ipynb`. I'll use the 8xH100 in lambda cloud and run all the scripts from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396e3d6-bd6e-4e67-a6c0-0a0d33940880",
   "metadata": {},
   "source": [
    "Follow the instructions here to get the machine ready: `challenge-28-midtrain-d20/midtrain-d20.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a0704f-aa28-4823-aa3b-a9b9b352e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 26 11:38:20 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:61:00.0 Off |                    0 |\n",
      "| N/A   25C    P0             71W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA H100 80GB HBM3          On  |   00000000:62:00.0 Off |                    0 |\n",
      "| N/A   26C    P0             68W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA H100 80GB HBM3          On  |   00000000:63:00.0 Off |                    0 |\n",
      "| N/A   27C    P0             72W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA H100 80GB HBM3          On  |   00000000:64:00.0 Off |                    0 |\n",
      "| N/A   25C    P0             72W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA H100 80GB HBM3          On  |   00000000:6A:00.0 Off |                    0 |\n",
      "| N/A   24C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA H100 80GB HBM3          On  |   00000000:6B:00.0 Off |                    0 |\n",
      "| N/A   27C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA H100 80GB HBM3          On  |   00000000:6C:00.0 Off |                    0 |\n",
      "| N/A   26C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA H100 80GB HBM3          On  |   00000000:6D:00.0 Off |                    0 |\n",
      "| N/A   24C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1919aa-0b1a-4064-8b30-5c8bfa19f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2f2e3-b78c-42a2-afb2-1198e39dc9e2",
   "metadata": {},
   "source": [
    "### RL train with tiny number of steps\n",
    "\n",
    "Just to confirm the process runs through to completion, logs to wandb, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a015eff-977e-4b1f-9e31-1d82ad2bdfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1126 11:43:51.144000 19228 torch/distributed/run.py:803] \n",
      "W1126 11:43:51.144000 19228 torch/distributed/run.py:803] *****************************************\n",
      "W1126 11:43:51.144000 19228 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1126 11:43:51.144000 19228 torch/distributed/run.py:803] *****************************************\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "overriding source = sft\n",
      "overriding model_tag = d20\n",
      "overriding num_steps = 5\n",
      "overriding run = challenge-36-1\n",
      "user_config: {'run': 'challenge-36-1', 'source': 'sft', 'dtype': 'bfloat16', 'device_type': '', 'num_steps': 5, 'device_batch_size': 8, 'examples_per_step': 16, 'num_samples': 16, 'max_new_tokens': 256, 'temperature': 1.0, 'top_k': 50, 'unembedding_lr': 0.004, 'embedding_lr': 0.2, 'matrix_lr': 0.02, 'weight_decay': 0.0, 'init_lr_frac': 0.05, 'num_epochs': 1, 'save_every': 60, 'eval_every': 60, 'eval_examples': 400}\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mericsilberstein\u001b[0m (\u001b[33mericsilberstein-self\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run 2vu0p885 (0.3s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/learn-nanochat/challenge-36-rl-train-d20/wandb/run-20251126_114403-2vu0p885\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchallenge-36-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl/runs/2vu0p885\u001b[0m\n",
      "loading the model from /home/ubuntu/mynanochat/chatsft_checkpoints/d20 with step 700\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n",
      "Calculated number of steps: 5\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(1280/768) = 0.7745966692414834\n",
      "Muon: Grouping 80 params of shape torch.Size([1280, 1280]), device cuda:0, dtype torch.float32\n",
      "Muon: Grouping 20 params of shape torch.Size([1280, 5120]), device cuda:0, dtype torch.float32\n",
      "Muon: Grouping 20 params of shape torch.Size([5120, 1280]), device cuda:0, dtype torch.float32\n",
      "total sequences per step: 256\n",
      "calculated examples per rank: 2\n",
      "Step 0 | Pass@1: 0.0250, Pass@2: 0.0400, Pass@3: 0.0625, Pass@4: 0.0825, Pass@5: 0.1025, Pass@6: 0.1300, Pass@7: 0.1400, Pass@8: 0.1600\n",
      "Step 0/5 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 0/5 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 0/5 | Example step 1 | Pass 0 | loss: -0.011117 | average reward: 0.0\n",
      "Step 0/5 | Example step 1 | Pass 1 | loss: 0.002502 | average reward: 0.125\n",
      "Step 0/5 | Average reward: 0.01171875 | Average sequence length: 212.73\n",
      "Step 1/5 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 1/5 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 1/5 | Example step 1 | Pass 0 | loss: -0.013066 | average reward: 0.0\n",
      "Step 1/5 | Example step 1 | Pass 1 | loss: -0.010534 | average reward: 0.125\n",
      "Step 1/5 | Average reward: 0.00390625 | Average sequence length: 198.25\n",
      "Step 2/5 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 2/5 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 2/5 | Example step 1 | Pass 0 | loss: -0.015430 | average reward: 0.125\n",
      "Step 2/5 | Example step 1 | Pass 1 | loss: 0.006183 | average reward: 0.125\n",
      "Step 2/5 | Average reward: 0.01953125 | Average sequence length: 177.78\n",
      "Step 3/5 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 3/5 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 3/5 | Example step 1 | Pass 0 | loss: -0.003807 | average reward: 0.125\n",
      "Step 3/5 | Example step 1 | Pass 1 | loss: 0.003070 | average reward: 0.125\n",
      "Step 3/5 | Average reward: 0.02734375 | Average sequence length: 186.76\n",
      "Step 4/5 | Example step 0 | Pass 0 | loss: -0.010659 | average reward: 0.375\n",
      "Step 4/5 | Example step 0 | Pass 1 | loss: -0.053884 | average reward: 0.25\n",
      "Step 4/5 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 4/5 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 4/5 | Average reward: 0.02734375 | Average sequence length: 174.51\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000004.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000004.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    lrm ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@1 ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@2 ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@3 ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@4 ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@5 ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@6 ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@7 ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@8 ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: reward ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     +2 ...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    lrm 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@1 0.025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@2 0.04\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@3 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@4 0.0825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@5 0.1025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@6 0.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@7 0.14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@8 0.16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: reward 0.02734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     +2 ...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mchallenge-36-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl/runs/2vu0p885\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251126_114403-2vu0p885/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!torchrun --standalone --nproc_per_node=8 -m scripts.my_chat_rl -- \\\n",
    "--source=sft --model_tag=d20 --num_steps=5 --run=challenge-36-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3297c137-278e-4ecc-ada7-0dfaa2314303",
   "metadata": {},
   "source": [
    "### RL train for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9811945-e06e-4768-85a0-fd60a672f2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1126 11:47:17.886000 20719 torch/distributed/run.py:803] \n",
      "W1126 11:47:17.886000 20719 torch/distributed/run.py:803] *****************************************\n",
      "W1126 11:47:17.886000 20719 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1126 11:47:17.886000 20719 torch/distributed/run.py:803] *****************************************\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "overriding source = sft\n",
      "overriding model_tag = d20\n",
      "overriding run = challenge-36-2\n",
      "user_config: {'run': 'challenge-36-2', 'source': 'sft', 'dtype': 'bfloat16', 'device_type': '', 'num_steps': -1, 'device_batch_size': 8, 'examples_per_step': 16, 'num_samples': 16, 'max_new_tokens': 256, 'temperature': 1.0, 'top_k': 50, 'unembedding_lr': 0.004, 'embedding_lr': 0.2, 'matrix_lr': 0.02, 'weight_decay': 0.0, 'init_lr_frac': 0.05, 'num_epochs': 1, 'save_every': 60, 'eval_every': 60, 'eval_examples': 400}\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mericsilberstein\u001b[0m (\u001b[33mericsilberstein-self\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run u6bhfl5b (0.2s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/learn-nanochat/challenge-36-rl-train-d20/wandb/run-20251126_114729-u6bhfl5b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchallenge-36-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl/runs/u6bhfl5b\u001b[0m\n",
      "loading the model from /home/ubuntu/mynanochat/chatsft_checkpoints/d20 with step 700\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n",
      "Calculated number of steps: 467\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(1280/768) = 0.7745966692414834\n",
      "Muon: Grouping 80 params of shape torch.Size([1280, 1280]), device cuda:0, dtype torch.float32\n",
      "Muon: Grouping 20 params of shape torch.Size([1280, 5120]), device cuda:0, dtype torch.float32\n",
      "Muon: Grouping 20 params of shape torch.Size([5120, 1280]), device cuda:0, dtype torch.float32\n",
      "total sequences per step: 256\n",
      "calculated examples per rank: 2\n",
      "Step 0 | Pass@1: 0.0250, Pass@2: 0.0400, Pass@3: 0.0625, Pass@4: 0.0825, Pass@5: 0.1025, Pass@6: 0.1300, Pass@7: 0.1400, Pass@8: 0.1600\n",
      "Step 0/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 0/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 0/467 | Example step 1 | Pass 0 | loss: -0.011117 | average reward: 0.0\n",
      "Step 0/467 | Example step 1 | Pass 1 | loss: 0.002502 | average reward: 0.125\n",
      "Step 0/467 | Average reward: 0.01171875 | Average sequence length: 212.73\n",
      "Step 1/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 1/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 1/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 1/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 1/467 | Average reward: 0.00390625 | Average sequence length: 204.07\n",
      "Step 2/467 | Example step 0 | Pass 0 | loss: -0.013707 | average reward: 0.0\n",
      "Step 2/467 | Example step 0 | Pass 1 | loss: 0.013932 | average reward: 0.125\n",
      "Step 2/467 | Example step 1 | Pass 0 | loss: 0.002574 | average reward: 0.25\n",
      "Step 2/467 | Example step 1 | Pass 1 | loss: -0.032074 | average reward: 0.0\n",
      "Step 2/467 | Average reward: 0.0234375 | Average sequence length: 177.50\n",
      "Step 3/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 3/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 3/467 | Example step 1 | Pass 0 | loss: -0.002020 | average reward: 0.125\n",
      "Step 3/467 | Example step 1 | Pass 1 | loss: -0.003063 | average reward: 0.125\n",
      "Step 3/467 | Average reward: 0.0234375 | Average sequence length: 182.50\n",
      "Step 4/467 | Example step 0 | Pass 0 | loss: -0.028383 | average reward: 0.375\n",
      "Step 4/467 | Example step 0 | Pass 1 | loss: -0.015651 | average reward: 0.5\n",
      "Step 4/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 4/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 4/467 | Average reward: 0.03515625 | Average sequence length: 174.16\n",
      "Step 5/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 5/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 5/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 5/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 5/467 | Average reward: 0.0078125 | Average sequence length: 176.36\n",
      "Step 6/467 | Example step 0 | Pass 0 | loss: -0.012188 | average reward: 0.0\n",
      "Step 6/467 | Example step 0 | Pass 1 | loss: 0.008796 | average reward: 0.125\n",
      "Step 6/467 | Example step 1 | Pass 0 | loss: 0.002721 | average reward: 0.125\n",
      "Step 6/467 | Example step 1 | Pass 1 | loss: -0.016050 | average reward: 0.0\n",
      "Step 6/467 | Average reward: 0.046875 | Average sequence length: 155.31\n",
      "Step 7/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 7/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 7/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 7/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 7/467 | Average reward: 0.015625 | Average sequence length: 179.71\n",
      "Step 8/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 8/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 8/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 8/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 8/467 | Average reward: 0.03125 | Average sequence length: 172.40\n",
      "Step 9/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 9/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 9/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 9/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 9/467 | Average reward: 0.02734375 | Average sequence length: 151.49\n",
      "Step 10/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 10/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 10/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 10/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 10/467 | Average reward: 0.015625 | Average sequence length: 166.46\n",
      "Step 11/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 11/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 11/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 11/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 11/467 | Average reward: 0.0234375 | Average sequence length: 177.53\n",
      "Step 12/467 | Example step 0 | Pass 0 | loss: -0.014794 | average reward: 0.125\n",
      "Step 12/467 | Example step 0 | Pass 1 | loss: -0.005335 | average reward: 0.125\n",
      "Step 12/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 12/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 12/467 | Average reward: 0.03125 | Average sequence length: 163.17\n",
      "Step 13/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 13/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 13/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 13/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 13/467 | Average reward: 0.01953125 | Average sequence length: 172.40\n",
      "Step 14/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 14/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 14/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 14/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 14/467 | Average reward: 0.0234375 | Average sequence length: 165.93\n",
      "Step 15/467 | Example step 0 | Pass 0 | loss: -0.021965 | average reward: 0.0\n",
      "Step 15/467 | Example step 0 | Pass 1 | loss: 0.007520 | average reward: 0.25\n",
      "Step 15/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 15/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 15/467 | Average reward: 0.04296875 | Average sequence length: 162.88\n",
      "Step 16/467 | Example step 0 | Pass 0 | loss: -0.008628 | average reward: 0.0\n",
      "Step 16/467 | Example step 0 | Pass 1 | loss: -0.004504 | average reward: 0.125\n",
      "Step 16/467 | Example step 1 | Pass 0 | loss: -0.019122 | average reward: 0.0\n",
      "Step 16/467 | Example step 1 | Pass 1 | loss: -0.000075 | average reward: 0.25\n",
      "Step 16/467 | Average reward: 0.01953125 | Average sequence length: 174.89\n",
      "Step 17/467 | Example step 0 | Pass 0 | loss: -0.001997 | average reward: 0.125\n",
      "Step 17/467 | Example step 0 | Pass 1 | loss: 0.043437 | average reward: 0.25\n",
      "Step 17/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 17/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 17/467 | Average reward: 0.0546875 | Average sequence length: 165.71\n",
      "Step 18/467 | Example step 0 | Pass 0 | loss: 0.003089 | average reward: 0.125\n",
      "Step 18/467 | Example step 0 | Pass 1 | loss: -0.010334 | average reward: 0.0\n",
      "Step 18/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 18/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 18/467 | Average reward: 0.02734375 | Average sequence length: 145.58\n",
      "Step 19/467 | Example step 0 | Pass 0 | loss: 0.008976 | average reward: 0.375\n",
      "Step 19/467 | Example step 0 | Pass 1 | loss: -0.019262 | average reward: 0.125\n",
      "Step 19/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 19/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 19/467 | Average reward: 0.06640625 | Average sequence length: 139.18\n",
      "Step 20/467 | Example step 0 | Pass 0 | loss: -0.015584 | average reward: 0.0\n",
      "Step 20/467 | Example step 0 | Pass 1 | loss: 0.050964 | average reward: 0.125\n",
      "Step 20/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 20/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 20/467 | Average reward: 0.01953125 | Average sequence length: 170.02\n",
      "Step 21/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 21/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 21/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 21/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 21/467 | Average reward: 0.0234375 | Average sequence length: 174.91\n",
      "Step 22/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 22/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 22/467 | Example step 1 | Pass 0 | loss: 0.015649 | average reward: 0.125\n",
      "Step 22/467 | Example step 1 | Pass 1 | loss: -0.008652 | average reward: 0.0\n",
      "Step 22/467 | Average reward: 0.015625 | Average sequence length: 143.40\n",
      "Step 23/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 23/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 23/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 23/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 23/467 | Average reward: 0.03125 | Average sequence length: 148.70\n",
      "Step 24/467 | Example step 0 | Pass 0 | loss: 0.001797 | average reward: 0.125\n",
      "Step 24/467 | Example step 0 | Pass 1 | loss: -0.009101 | average reward: 0.0\n",
      "Step 24/467 | Example step 1 | Pass 0 | loss: -0.010897 | average reward: 0.0\n",
      "Step 24/467 | Example step 1 | Pass 1 | loss: 0.031241 | average reward: 0.125\n",
      "Step 24/467 | Average reward: 0.0390625 | Average sequence length: 160.10\n",
      "Step 25/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 25/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 25/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 25/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 25/467 | Average reward: 0.03125 | Average sequence length: 154.52\n",
      "Step 26/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 26/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 26/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 26/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 26/467 | Average reward: 0.0078125 | Average sequence length: 130.09\n",
      "Step 27/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 27/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 27/467 | Example step 1 | Pass 0 | loss: -0.014541 | average reward: 0.0\n",
      "Step 27/467 | Example step 1 | Pass 1 | loss: 0.013545 | average reward: 0.125\n",
      "Step 27/467 | Average reward: 0.0625 | Average sequence length: 136.82\n",
      "Step 28/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 28/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 28/467 | Example step 1 | Pass 0 | loss: 0.012821 | average reward: 0.125\n",
      "Step 28/467 | Example step 1 | Pass 1 | loss: -0.009203 | average reward: 0.0\n",
      "Step 28/467 | Average reward: 0.03125 | Average sequence length: 156.63\n",
      "Step 29/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 29/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 29/467 | Example step 1 | Pass 0 | loss: -0.012353 | average reward: 0.0\n",
      "Step 29/467 | Example step 1 | Pass 1 | loss: 0.008847 | average reward: 0.125\n",
      "Step 29/467 | Average reward: 0.05078125 | Average sequence length: 149.60\n",
      "Step 30/467 | Example step 0 | Pass 0 | loss: 0.010637 | average reward: 0.125\n",
      "Step 30/467 | Example step 0 | Pass 1 | loss: -0.016238 | average reward: 0.0\n",
      "Step 30/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 30/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 30/467 | Average reward: 0.015625 | Average sequence length: 152.50\n",
      "Step 31/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 31/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 31/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 31/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 31/467 | Average reward: 0.03125 | Average sequence length: 138.38\n",
      "Step 32/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 32/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 32/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 32/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 32/467 | Average reward: 0.0078125 | Average sequence length: 156.33\n",
      "Step 33/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 33/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 33/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 33/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 33/467 | Average reward: 0.01171875 | Average sequence length: 143.24\n",
      "Step 34/467 | Example step 0 | Pass 0 | loss: 0.014520 | average reward: 0.375\n",
      "Step 34/467 | Example step 0 | Pass 1 | loss: -0.017599 | average reward: 0.25\n",
      "Step 34/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 34/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 34/467 | Average reward: 0.0390625 | Average sequence length: 143.48\n",
      "Step 35/467 | Example step 0 | Pass 0 | loss: -0.006819 | average reward: 0.0\n",
      "Step 35/467 | Example step 0 | Pass 1 | loss: 0.001497 | average reward: 0.125\n",
      "Step 35/467 | Example step 1 | Pass 0 | loss: -0.007706 | average reward: 0.125\n",
      "Step 35/467 | Example step 1 | Pass 1 | loss: 0.023947 | average reward: 0.25\n",
      "Step 35/467 | Average reward: 0.015625 | Average sequence length: 136.65\n",
      "Step 36/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 36/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 36/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 36/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 36/467 | Average reward: 0.01171875 | Average sequence length: 150.20\n",
      "Step 37/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 37/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 37/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 37/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 37/467 | Average reward: 0.01953125 | Average sequence length: 129.01\n",
      "Step 38/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 38/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 38/467 | Example step 1 | Pass 0 | loss: 0.007670 | average reward: 0.25\n",
      "Step 38/467 | Example step 1 | Pass 1 | loss: -0.003242 | average reward: 0.125\n",
      "Step 38/467 | Average reward: 0.04296875 | Average sequence length: 147.01\n",
      "Step 39/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 39/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 39/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 39/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 39/467 | Average reward: 0.03125 | Average sequence length: 146.18\n",
      "Step 40/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 40/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 40/467 | Example step 1 | Pass 0 | loss: 0.001917 | average reward: 0.125\n",
      "Step 40/467 | Example step 1 | Pass 1 | loss: -0.010234 | average reward: 0.0\n",
      "Step 40/467 | Average reward: 0.04296875 | Average sequence length: 140.12\n",
      "Step 41/467 | Example step 0 | Pass 0 | loss: 0.008441 | average reward: 0.125\n",
      "Step 41/467 | Example step 0 | Pass 1 | loss: -0.004333 | average reward: 0.0\n",
      "Step 41/467 | Example step 1 | Pass 0 | loss: 0.003602 | average reward: 0.375\n",
      "Step 41/467 | Example step 1 | Pass 1 | loss: -0.029565 | average reward: 0.125\n",
      "Step 41/467 | Average reward: 0.09765625 | Average sequence length: 144.05\n",
      "Step 42/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 42/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 42/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 42/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 42/467 | Average reward: 0.046875 | Average sequence length: 149.75\n",
      "Step 43/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 43/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 43/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 43/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 43/467 | Average reward: 0.05859375 | Average sequence length: 157.98\n",
      "Step 44/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 44/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 44/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 44/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 44/467 | Average reward: 0.0234375 | Average sequence length: 147.28\n",
      "Step 45/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 45/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 45/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 45/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 45/467 | Average reward: 0.03515625 | Average sequence length: 160.82\n",
      "Step 46/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 46/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 46/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 46/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 46/467 | Average reward: 0.0546875 | Average sequence length: 161.97\n",
      "Step 47/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 47/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 47/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 47/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 47/467 | Average reward: 0.02734375 | Average sequence length: 150.55\n",
      "Step 48/467 | Example step 0 | Pass 0 | loss: 0.008732 | average reward: 0.125\n",
      "Step 48/467 | Example step 0 | Pass 1 | loss: -0.005238 | average reward: 0.0\n",
      "Step 48/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 48/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 48/467 | Average reward: 0.015625 | Average sequence length: 152.94\n",
      "Step 49/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 49/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 49/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 49/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 49/467 | Average reward: 0.03125 | Average sequence length: 134.09\n",
      "Step 50/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 50/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 50/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 50/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 50/467 | Average reward: 0.046875 | Average sequence length: 151.58\n",
      "Step 51/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 51/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 51/467 | Example step 1 | Pass 0 | loss: 0.000512 | average reward: 0.375\n",
      "Step 51/467 | Example step 1 | Pass 1 | loss: 0.011912 | average reward: 0.5\n",
      "Step 51/467 | Average reward: 0.05078125 | Average sequence length: 149.73\n",
      "Step 52/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 52/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 52/467 | Example step 1 | Pass 0 | loss: -0.009708 | average reward: 0.0\n",
      "Step 52/467 | Example step 1 | Pass 1 | loss: 0.004589 | average reward: 0.125\n",
      "Step 52/467 | Average reward: 0.06640625 | Average sequence length: 133.03\n",
      "Step 53/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 53/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 53/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 53/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 53/467 | Average reward: 0.08984375 | Average sequence length: 135.03\n",
      "Step 54/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 54/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 54/467 | Example step 1 | Pass 0 | loss: -0.022228 | average reward: 0.0\n",
      "Step 54/467 | Example step 1 | Pass 1 | loss: 0.007107 | average reward: 0.375\n",
      "Step 54/467 | Average reward: 0.03515625 | Average sequence length: 142.86\n",
      "Step 55/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 55/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 55/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 55/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 55/467 | Average reward: 0.03515625 | Average sequence length: 138.46\n",
      "Step 56/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 56/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 56/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 56/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 56/467 | Average reward: 0.02734375 | Average sequence length: 153.17\n",
      "Step 57/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 57/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 57/467 | Example step 1 | Pass 0 | loss: -0.002717 | average reward: 0.125\n",
      "Step 57/467 | Example step 1 | Pass 1 | loss: -0.010758 | average reward: 0.0\n",
      "Step 57/467 | Average reward: 0.09375 | Average sequence length: 135.30\n",
      "Step 58/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 58/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 58/467 | Example step 1 | Pass 0 | loss: -0.005875 | average reward: 0.125\n",
      "Step 58/467 | Example step 1 | Pass 1 | loss: -0.001643 | average reward: 0.125\n",
      "Step 58/467 | Average reward: 0.0703125 | Average sequence length: 155.47\n",
      "Step 59/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 59/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 59/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 59/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 59/467 | Average reward: 0.015625 | Average sequence length: 157.45\n",
      "Step 60 | Pass@1: 0.0725, Pass@2: 0.1025, Pass@3: 0.1450, Pass@4: 0.1725, Pass@5: 0.2025, Pass@6: 0.2200, Pass@7: 0.2325, Pass@8: 0.2475\n",
      "Step 60/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 60/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 60/467 | Example step 1 | Pass 0 | loss: 0.024342 | average reward: 0.125\n",
      "Step 60/467 | Example step 1 | Pass 1 | loss: -0.009905 | average reward: 0.0\n",
      "Step 60/467 | Average reward: 0.03515625 | Average sequence length: 160.80\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000060.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000060.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    lrm ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@1 ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@2 ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@3 ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@4 ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@5 ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@6 ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@7 ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@8 ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: reward ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñà‚ñÉ‚ñÉ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     +2 ...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    lrm 0.87152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@1 0.0725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@2 0.1025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@3 0.145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@4 0.1725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@5 0.2025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@6 0.22\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@7 0.2325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@8 0.2475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: reward 0.03516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     +2 ...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mchallenge-36-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl/runs/u6bhfl5b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251126_114729-u6bhfl5b/logs\u001b[0m\n",
      "^C\n",
      "W1126 12:00:24.179000 20719 torch/distributed/elastic/agent/server/api.py:725] Received Signals.SIGINT death signal, shutting down workers\n",
      "W1126 12:00:24.180000 20719 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 20816 closing signal SIGINT\n",
      "W1126 12:00:24.180000 20719 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 20817 closing signal SIGINT\n",
      "W1126 12:00:24.180000 20719 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 20818 closing signal SIGINT\n",
      "W1126 12:00:24.180000 20719 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 20819 closing signal SIGINT\n",
      "W1126 12:00:24.180000 20719 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 20820 closing signal SIGINT\n",
      "W1126 12:00:24.181000 20719 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 20821 closing signal SIGINT\n",
      "W1126 12:00:24.181000 20719 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 20822 closing signal SIGINT\n",
      "W1126 12:00:24.181000 20719 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 20823 closing signal SIGINT\n"
     ]
    }
   ],
   "source": [
    "!torchrun --standalone --nproc_per_node=8 -m scripts.my_chat_rl -- \\\n",
    "--source=sft --model_tag=d20 --run=challenge-36-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed392bab-0caf-4411-a012-aaeb172013a6",
   "metadata": {},
   "source": [
    "^ ugh, I made an indentation error in `my_chat_rl.py` so it did the final report and cleanup stuff before the loop was over. Fix and run again. Good thing is that the pass@k numbers went up on the step 60 evaluation. (Fixed wrong, that was run 36-3, fixed again.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "468c51b7-19f5-4d42-aa22-5b8ceb4f318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1126 12:04:47.963000 24754 torch/distributed/run.py:803] \n",
      "W1126 12:04:47.963000 24754 torch/distributed/run.py:803] *****************************************\n",
      "W1126 12:04:47.963000 24754 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1126 12:04:47.963000 24754 torch/distributed/run.py:803] *****************************************\n",
      "overriding source = sft\n",
      "overriding model_tag = d20\n",
      "overriding run = challenge-36-4\n",
      "user_config: {'run': 'challenge-36-4', 'source': 'sft', 'dtype': 'bfloat16', 'device_type': '', 'num_steps': -1, 'device_batch_size': 8, 'examples_per_step': 16, 'num_samples': 16, 'max_new_tokens': 256, 'temperature': 1.0, 'top_k': 50, 'unembedding_lr': 0.004, 'embedding_lr': 0.2, 'matrix_lr': 0.02, 'weight_decay': 0.0, 'init_lr_frac': 0.05, 'num_epochs': 1, 'save_every': 60, 'eval_every': 60, 'eval_examples': 400}\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mericsilberstein\u001b[0m (\u001b[33mericsilberstein-self\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Waiting for wandb.init()...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run mcfuvgi2 (0.2s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run mcfuvgi2 (0.2s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m setting up run mcfuvgi2 (0.2s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/learn-nanochat/challenge-36-rl-train-d20/wandb/run-20251126_120459-mcfuvgi2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchallenge-36-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl/runs/mcfuvgi2\u001b[0m\n",
      "loading the model from /home/ubuntu/mynanochat/chatsft_checkpoints/d20 with step 700\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n",
      "Calculated number of steps: 467\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(1280/768) = 0.7745966692414834\n",
      "Muon: Grouping 80 params of shape torch.Size([1280, 1280]), device cuda:0, dtype torch.float32\n",
      "Muon: Grouping 20 params of shape torch.Size([1280, 5120]), device cuda:0, dtype torch.float32\n",
      "Muon: Grouping 20 params of shape torch.Size([5120, 1280]), device cuda:0, dtype torch.float32\n",
      "total sequences per step: 256\n",
      "calculated examples per rank: 2\n",
      "Step 0 | Pass@1: 0.0250, Pass@2: 0.0400, Pass@3: 0.0625, Pass@4: 0.0825, Pass@5: 0.1025, Pass@6: 0.1300, Pass@7: 0.1400, Pass@8: 0.1600\n",
      "Step 0/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 0/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 0/467 | Example step 1 | Pass 0 | loss: -0.011117 | average reward: 0.0\n",
      "Step 0/467 | Example step 1 | Pass 1 | loss: 0.002502 | average reward: 0.125\n",
      "Step 0/467 | Average reward: 0.01171875 | Average sequence length: 212.73\n",
      "Step 1/467 | Example step 0 | Pass 0 | loss: -0.013327 | average reward: 0.0\n",
      "Step 1/467 | Example step 0 | Pass 1 | loss: -0.001572 | average reward: 0.125\n",
      "Step 1/467 | Example step 1 | Pass 0 | loss: -0.013653 | average reward: 0.0\n",
      "Step 1/467 | Example step 1 | Pass 1 | loss: -0.006761 | average reward: 0.125\n",
      "Step 1/467 | Average reward: 0.0234375 | Average sequence length: 193.13\n",
      "Step 2/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 2/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 2/467 | Example step 1 | Pass 0 | loss: -0.017285 | average reward: 0.0\n",
      "Step 2/467 | Example step 1 | Pass 1 | loss: 0.009574 | average reward: 0.125\n",
      "Step 2/467 | Average reward: 0.0390625 | Average sequence length: 184.30\n",
      "Step 3/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 3/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 3/467 | Example step 1 | Pass 0 | loss: 0.012074 | average reward: 0.25\n",
      "Step 3/467 | Example step 1 | Pass 1 | loss: -0.013691 | average reward: 0.0\n",
      "Step 3/467 | Average reward: 0.01953125 | Average sequence length: 182.91\n",
      "Step 4/467 | Example step 0 | Pass 0 | loss: -0.011917 | average reward: 0.25\n",
      "Step 4/467 | Example step 0 | Pass 1 | loss: 0.013773 | average reward: 0.375\n",
      "Step 4/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 4/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 4/467 | Average reward: 0.02734375 | Average sequence length: 180.73\n",
      "Step 5/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 5/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 5/467 | Example step 1 | Pass 0 | loss: 0.006949 | average reward: 0.125\n",
      "Step 5/467 | Example step 1 | Pass 1 | loss: -0.011653 | average reward: 0.0\n",
      "Step 5/467 | Average reward: 0.015625 | Average sequence length: 184.80\n",
      "Step 6/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 6/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 6/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 6/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 6/467 | Average reward: 0.03125 | Average sequence length: 157.07\n",
      "Step 7/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 7/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 7/467 | Example step 1 | Pass 0 | loss: -0.018686 | average reward: 0.0\n",
      "Step 7/467 | Example step 1 | Pass 1 | loss: 0.069311 | average reward: 0.125\n",
      "Step 7/467 | Average reward: 0.01953125 | Average sequence length: 188.93\n",
      "Step 8/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 8/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 8/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 8/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 8/467 | Average reward: 0.046875 | Average sequence length: 175.49\n",
      "Step 9/467 | Example step 0 | Pass 0 | loss: 0.008050 | average reward: 0.125\n",
      "Step 9/467 | Example step 0 | Pass 1 | loss: -0.011466 | average reward: 0.0\n",
      "Step 9/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 9/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 9/467 | Average reward: 0.015625 | Average sequence length: 160.35\n",
      "Step 10/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 10/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 10/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 10/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 10/467 | Average reward: 0.015625 | Average sequence length: 182.61\n",
      "Step 11/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 11/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 11/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 11/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 11/467 | Average reward: 0.0078125 | Average sequence length: 183.97\n",
      "Step 12/467 | Example step 0 | Pass 0 | loss: -0.043659 | average reward: 0.0\n",
      "Step 12/467 | Example step 0 | Pass 1 | loss: 0.008266 | average reward: 0.375\n",
      "Step 12/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 12/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 12/467 | Average reward: 0.03515625 | Average sequence length: 172.27\n",
      "Step 13/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 13/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 13/467 | Example step 1 | Pass 0 | loss: -0.003443 | average reward: 0.125\n",
      "Step 13/467 | Example step 1 | Pass 1 | loss: -0.017246 | average reward: 0.0\n",
      "Step 13/467 | Average reward: 0.01171875 | Average sequence length: 199.07\n",
      "Step 14/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 14/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 14/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 14/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 14/467 | Average reward: 0.0234375 | Average sequence length: 181.27\n",
      "Step 15/467 | Example step 0 | Pass 0 | loss: -0.013053 | average reward: 0.125\n",
      "Step 15/467 | Example step 0 | Pass 1 | loss: 0.007650 | average reward: 0.25\n",
      "Step 15/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 15/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 15/467 | Average reward: 0.05859375 | Average sequence length: 175.21\n",
      "Step 16/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 16/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 16/467 | Example step 1 | Pass 0 | loss: -0.009618 | average reward: 0.125\n",
      "Step 16/467 | Example step 1 | Pass 1 | loss: -0.005357 | average reward: 0.25\n",
      "Step 16/467 | Average reward: 0.03125 | Average sequence length: 185.27\n",
      "Step 17/467 | Example step 0 | Pass 0 | loss: -0.035028 | average reward: 0.0\n",
      "Step 17/467 | Example step 0 | Pass 1 | loss: 0.037283 | average reward: 0.25\n",
      "Step 17/467 | Example step 1 | Pass 0 | loss: 0.009962 | average reward: 0.125\n",
      "Step 17/467 | Example step 1 | Pass 1 | loss: -0.012973 | average reward: 0.0\n",
      "Step 17/467 | Average reward: 0.0390625 | Average sequence length: 183.10\n",
      "Step 18/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 18/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 18/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 18/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 18/467 | Average reward: 0.046875 | Average sequence length: 156.49\n",
      "Step 19/467 | Example step 0 | Pass 0 | loss: -0.039818 | average reward: 0.375\n",
      "Step 19/467 | Example step 0 | Pass 1 | loss: -0.008666 | average reward: 0.5\n",
      "Step 19/467 | Example step 1 | Pass 0 | loss: 0.007071 | average reward: 0.125\n",
      "Step 19/467 | Example step 1 | Pass 1 | loss: -0.014283 | average reward: 0.0\n",
      "Step 19/467 | Average reward: 0.06640625 | Average sequence length: 147.80\n",
      "Step 20/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 20/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 20/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 20/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 20/467 | Average reward: 0.0234375 | Average sequence length: 191.10\n",
      "Step 21/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 21/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 21/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 21/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 21/467 | Average reward: 0.04296875 | Average sequence length: 191.08\n",
      "Step 22/467 | Example step 0 | Pass 0 | loss: -0.007085 | average reward: 0.0\n",
      "Step 22/467 | Example step 0 | Pass 1 | loss: 0.003736 | average reward: 0.125\n",
      "Step 22/467 | Example step 1 | Pass 0 | loss: 0.000445 | average reward: 0.125\n",
      "Step 22/467 | Example step 1 | Pass 1 | loss: -0.012411 | average reward: 0.0\n",
      "Step 22/467 | Average reward: 0.05078125 | Average sequence length: 155.62\n",
      "Step 23/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 23/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 23/467 | Example step 1 | Pass 0 | loss: -0.008687 | average reward: 0.0\n",
      "Step 23/467 | Example step 1 | Pass 1 | loss: 0.006769 | average reward: 0.125\n",
      "Step 23/467 | Average reward: 0.02734375 | Average sequence length: 167.46\n",
      "Step 24/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 24/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 24/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 24/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 24/467 | Average reward: 0.0390625 | Average sequence length: 181.80\n",
      "Step 25/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 25/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 25/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 25/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 25/467 | Average reward: 0.03515625 | Average sequence length: 175.86\n",
      "Step 26/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 26/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 26/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 26/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 26/467 | Average reward: 0.0 | Average sequence length: 148.83\n",
      "Step 27/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 27/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 27/467 | Example step 1 | Pass 0 | loss: 0.038522 | average reward: 0.25\n",
      "Step 27/467 | Example step 1 | Pass 1 | loss: -0.024188 | average reward: 0.0\n",
      "Step 27/467 | Average reward: 0.03125 | Average sequence length: 154.16\n",
      "Step 28/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 28/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 28/467 | Example step 1 | Pass 0 | loss: 0.012589 | average reward: 0.375\n",
      "Step 28/467 | Example step 1 | Pass 1 | loss: -0.009443 | average reward: 0.25\n",
      "Step 28/467 | Average reward: 0.046875 | Average sequence length: 180.24\n",
      "Step 29/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 29/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 29/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 29/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 29/467 | Average reward: 0.046875 | Average sequence length: 173.87\n",
      "Step 30/467 | Example step 0 | Pass 0 | loss: -0.001065 | average reward: 0.125\n",
      "Step 30/467 | Example step 0 | Pass 1 | loss: -0.013223 | average reward: 0.0\n",
      "Step 30/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 30/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 30/467 | Average reward: 0.0234375 | Average sequence length: 171.04\n",
      "Step 31/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 31/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 31/467 | Example step 1 | Pass 0 | loss: 0.018464 | average reward: 0.125\n",
      "Step 31/467 | Example step 1 | Pass 1 | loss: -0.014090 | average reward: 0.0\n",
      "Step 31/467 | Average reward: 0.046875 | Average sequence length: 161.64\n",
      "Step 32/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 32/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 32/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 32/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 32/467 | Average reward: 0.0078125 | Average sequence length: 174.86\n",
      "Step 33/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 33/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 33/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 33/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 33/467 | Average reward: 0.0234375 | Average sequence length: 164.68\n",
      "Step 34/467 | Example step 0 | Pass 0 | loss: -0.004582 | average reward: 0.125\n",
      "Step 34/467 | Example step 0 | Pass 1 | loss: 0.005914 | average reward: 0.25\n",
      "Step 34/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 34/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 34/467 | Average reward: 0.0390625 | Average sequence length: 165.84\n",
      "Step 35/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 35/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 35/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 35/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 35/467 | Average reward: 0.01171875 | Average sequence length: 152.87\n",
      "Step 36/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 36/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 36/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 36/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 36/467 | Average reward: 0.015625 | Average sequence length: 171.23\n",
      "Step 37/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 37/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 37/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 37/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 37/467 | Average reward: 0.015625 | Average sequence length: 147.28\n",
      "Step 38/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 38/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 38/467 | Example step 1 | Pass 0 | loss: -0.002934 | average reward: 0.375\n",
      "Step 38/467 | Example step 1 | Pass 1 | loss: -0.010807 | average reward: 0.25\n",
      "Step 38/467 | Average reward: 0.05078125 | Average sequence length: 163.33\n",
      "Step 39/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 39/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 39/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 39/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 39/467 | Average reward: 0.05078125 | Average sequence length: 161.51\n",
      "Step 40/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 40/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 40/467 | Example step 1 | Pass 0 | loss: -0.010128 | average reward: 0.0\n",
      "Step 40/467 | Example step 1 | Pass 1 | loss: 0.016557 | average reward: 0.125\n",
      "Step 40/467 | Average reward: 0.01953125 | Average sequence length: 151.54\n",
      "Step 41/467 | Example step 0 | Pass 0 | loss: 0.001046 | average reward: 0.125\n",
      "Step 41/467 | Example step 0 | Pass 1 | loss: -0.005675 | average reward: 0.0\n",
      "Step 41/467 | Example step 1 | Pass 0 | loss: 0.002905 | average reward: 0.375\n",
      "Step 41/467 | Example step 1 | Pass 1 | loss: -0.013998 | average reward: 0.25\n",
      "Step 41/467 | Average reward: 0.08203125 | Average sequence length: 163.94\n",
      "Step 42/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 42/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 42/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 42/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 42/467 | Average reward: 0.06640625 | Average sequence length: 162.68\n",
      "Step 43/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 43/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 43/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 43/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 43/467 | Average reward: 0.0546875 | Average sequence length: 164.20\n",
      "Step 44/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 44/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 44/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 44/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 44/467 | Average reward: 0.03125 | Average sequence length: 157.78\n",
      "Step 45/467 | Example step 0 | Pass 0 | loss: 0.008049 | average reward: 0.125\n",
      "Step 45/467 | Example step 0 | Pass 1 | loss: -0.005257 | average reward: 0.0\n",
      "Step 45/467 | Example step 1 | Pass 0 | loss: 0.002709 | average reward: 0.125\n",
      "Step 45/467 | Example step 1 | Pass 1 | loss: -0.007655 | average reward: 0.0\n",
      "Step 45/467 | Average reward: 0.0546875 | Average sequence length: 165.79\n",
      "Step 46/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 46/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 46/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 46/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 46/467 | Average reward: 0.02734375 | Average sequence length: 176.14\n",
      "Step 47/467 | Example step 0 | Pass 0 | loss: -0.013942 | average reward: 0.0\n",
      "Step 47/467 | Example step 0 | Pass 1 | loss: -0.003782 | average reward: 0.125\n",
      "Step 47/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 47/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 47/467 | Average reward: 0.0546875 | Average sequence length: 166.00\n",
      "Step 48/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 48/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 48/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 48/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 48/467 | Average reward: 0.0390625 | Average sequence length: 157.98\n",
      "Step 49/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 49/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 49/467 | Example step 1 | Pass 0 | loss: 0.002176 | average reward: 0.125\n",
      "Step 49/467 | Example step 1 | Pass 1 | loss: -0.013051 | average reward: 0.0\n",
      "Step 49/467 | Average reward: 0.05859375 | Average sequence length: 137.59\n",
      "Step 50/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 50/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 50/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 50/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 50/467 | Average reward: 0.10546875 | Average sequence length: 155.11\n",
      "Step 51/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 51/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 51/467 | Example step 1 | Pass 0 | loss: -0.006482 | average reward: 0.125\n",
      "Step 51/467 | Example step 1 | Pass 1 | loss: -0.005947 | average reward: 0.125\n",
      "Step 51/467 | Average reward: 0.04296875 | Average sequence length: 150.03\n",
      "Step 52/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 52/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 52/467 | Example step 1 | Pass 0 | loss: -0.006813 | average reward: 0.0\n",
      "Step 52/467 | Example step 1 | Pass 1 | loss: -0.000199 | average reward: 0.125\n",
      "Step 52/467 | Average reward: 0.0703125 | Average sequence length: 134.16\n",
      "Step 53/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 53/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 53/467 | Example step 1 | Pass 0 | loss: -0.005812 | average reward: 0.0\n",
      "Step 53/467 | Example step 1 | Pass 1 | loss: 0.002847 | average reward: 0.125\n",
      "Step 53/467 | Average reward: 0.08203125 | Average sequence length: 131.05\n",
      "Step 54/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 54/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 54/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 54/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 54/467 | Average reward: 0.04296875 | Average sequence length: 143.59\n",
      "Step 55/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 55/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 55/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 55/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 55/467 | Average reward: 0.0390625 | Average sequence length: 138.64\n",
      "Step 56/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 56/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 56/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 56/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 56/467 | Average reward: 0.01171875 | Average sequence length: 155.83\n",
      "Step 57/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 57/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 57/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 57/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 57/467 | Average reward: 0.05078125 | Average sequence length: 134.83\n",
      "Step 58/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 58/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 58/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 58/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 58/467 | Average reward: 0.046875 | Average sequence length: 154.47\n",
      "Step 59/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 59/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 59/467 | Example step 1 | Pass 0 | loss: 0.008260 | average reward: 0.125\n",
      "Step 59/467 | Example step 1 | Pass 1 | loss: -0.004322 | average reward: 0.0\n",
      "Step 59/467 | Average reward: 0.01953125 | Average sequence length: 158.45\n",
      "Step 60 | Pass@1: 0.0700, Pass@2: 0.1075, Pass@3: 0.1575, Pass@4: 0.1675, Pass@5: 0.1775, Pass@6: 0.2025, Pass@7: 0.2100, Pass@8: 0.2250\n",
      "Step 60/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 60/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 60/467 | Example step 1 | Pass 0 | loss: 0.008216 | average reward: 0.125\n",
      "Step 60/467 | Example step 1 | Pass 1 | loss: -0.013196 | average reward: 0.0\n",
      "Step 60/467 | Average reward: 0.03125 | Average sequence length: 158.07\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000060.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000060.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "Step 61/467 | Example step 0 | Pass 0 | loss: 0.000474 | average reward: 0.125\n",
      "Step 61/467 | Example step 0 | Pass 1 | loss: -0.003181 | average reward: 0.125\n",
      "Step 61/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 61/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 61/467 | Average reward: 0.078125 | Average sequence length: 137.74\n",
      "Step 62/467 | Example step 0 | Pass 0 | loss: -0.004960 | average reward: 0.125\n",
      "Step 62/467 | Example step 0 | Pass 1 | loss: -0.005101 | average reward: 0.125\n",
      "Step 62/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 62/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 62/467 | Average reward: 0.01171875 | Average sequence length: 164.63\n",
      "Step 63/467 | Example step 0 | Pass 0 | loss: 0.005157 | average reward: 0.125\n",
      "Step 63/467 | Example step 0 | Pass 1 | loss: -0.008254 | average reward: 0.0\n",
      "Step 63/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 63/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 63/467 | Average reward: 0.08203125 | Average sequence length: 140.46\n",
      "Step 64/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 64/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 64/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 64/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 64/467 | Average reward: 0.01171875 | Average sequence length: 171.83\n",
      "Step 65/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 65/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 65/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 65/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 65/467 | Average reward: 0.01953125 | Average sequence length: 164.03\n",
      "Step 66/467 | Example step 0 | Pass 0 | loss: -0.005798 | average reward: 0.0\n",
      "Step 66/467 | Example step 0 | Pass 1 | loss: -0.001544 | average reward: 0.125\n",
      "Step 66/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 66/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 66/467 | Average reward: 0.07421875 | Average sequence length: 151.05\n",
      "Step 67/467 | Example step 0 | Pass 0 | loss: 0.000620 | average reward: 0.125\n",
      "Step 67/467 | Example step 0 | Pass 1 | loss: -0.006366 | average reward: 0.0\n",
      "Step 67/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 67/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 67/467 | Average reward: 0.05078125 | Average sequence length: 166.89\n",
      "Step 68/467 | Example step 0 | Pass 0 | loss: 0.003353 | average reward: 0.375\n",
      "Step 68/467 | Example step 0 | Pass 1 | loss: -0.013297 | average reward: 0.25\n",
      "Step 68/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 68/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 68/467 | Average reward: 0.0390625 | Average sequence length: 159.29\n",
      "Step 69/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 69/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 69/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 69/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 69/467 | Average reward: 0.015625 | Average sequence length: 146.30\n",
      "Step 70/467 | Example step 0 | Pass 0 | loss: 0.001753 | average reward: 0.125\n",
      "Step 70/467 | Example step 0 | Pass 1 | loss: -0.009998 | average reward: 0.0\n",
      "Step 70/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 70/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 70/467 | Average reward: 0.03125 | Average sequence length: 156.92\n",
      "Step 71/467 | Example step 0 | Pass 0 | loss: -0.005206 | average reward: 0.125\n",
      "Step 71/467 | Example step 0 | Pass 1 | loss: 0.025589 | average reward: 0.25\n",
      "Step 71/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 71/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 71/467 | Average reward: 0.02734375 | Average sequence length: 157.16\n",
      "Step 72/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 72/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 72/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 72/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 72/467 | Average reward: 0.01953125 | Average sequence length: 152.28\n",
      "Step 73/467 | Example step 0 | Pass 0 | loss: -0.021422 | average reward: 0.0\n",
      "Step 73/467 | Example step 0 | Pass 1 | loss: 0.023876 | average reward: 0.25\n",
      "Step 73/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 73/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 73/467 | Average reward: 0.0390625 | Average sequence length: 168.56\n",
      "Step 74/467 | Example step 0 | Pass 0 | loss: -0.011056 | average reward: 0.0\n",
      "Step 74/467 | Example step 0 | Pass 1 | loss: 0.003462 | average reward: 0.25\n",
      "Step 74/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 74/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 74/467 | Average reward: 0.0546875 | Average sequence length: 165.12\n",
      "Step 75/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 75/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 75/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 75/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 75/467 | Average reward: 0.07421875 | Average sequence length: 129.20\n",
      "Step 76/467 | Example step 0 | Pass 0 | loss: 0.006428 | average reward: 0.125\n",
      "Step 76/467 | Example step 0 | Pass 1 | loss: -0.004886 | average reward: 0.0\n",
      "Step 76/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 76/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 76/467 | Average reward: 0.05859375 | Average sequence length: 144.49\n",
      "Step 77/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 77/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 77/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 77/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 77/467 | Average reward: 0.0390625 | Average sequence length: 136.69\n",
      "Step 78/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 78/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 78/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 78/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 78/467 | Average reward: 0.01953125 | Average sequence length: 146.72\n",
      "Step 79/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 79/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 79/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 79/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 79/467 | Average reward: 0.0234375 | Average sequence length: 150.64\n",
      "Step 80/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 80/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 80/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 80/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 80/467 | Average reward: 0.08984375 | Average sequence length: 156.49\n",
      "Step 81/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 81/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 81/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 81/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 81/467 | Average reward: 0.015625 | Average sequence length: 148.16\n",
      "Step 82/467 | Example step 0 | Pass 0 | loss: 0.005738 | average reward: 0.25\n",
      "Step 82/467 | Example step 0 | Pass 1 | loss: -0.010659 | average reward: 0.0\n",
      "Step 82/467 | Example step 1 | Pass 0 | loss: -0.027854 | average reward: 0.625\n",
      "Step 82/467 | Example step 1 | Pass 1 | loss: -0.000742 | average reward: 0.875\n",
      "Step 82/467 | Average reward: 0.10546875 | Average sequence length: 135.50\n",
      "Step 83/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 83/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 83/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 83/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 83/467 | Average reward: 0.01953125 | Average sequence length: 161.73\n",
      "Step 84/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 84/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 84/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 84/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 84/467 | Average reward: 0.10546875 | Average sequence length: 160.93\n",
      "Step 85/467 | Example step 0 | Pass 0 | loss: 0.010674 | average reward: 0.125\n",
      "Step 85/467 | Example step 0 | Pass 1 | loss: -0.005349 | average reward: 0.0\n",
      "Step 85/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 85/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 85/467 | Average reward: 0.0546875 | Average sequence length: 136.95\n",
      "Step 86/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 86/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 86/467 | Example step 1 | Pass 0 | loss: -0.005555 | average reward: 0.0\n",
      "Step 86/467 | Example step 1 | Pass 1 | loss: 0.018554 | average reward: 0.125\n",
      "Step 86/467 | Average reward: 0.05859375 | Average sequence length: 140.68\n",
      "Step 87/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 87/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 87/467 | Example step 1 | Pass 0 | loss: -0.006067 | average reward: 0.0\n",
      "Step 87/467 | Example step 1 | Pass 1 | loss: -0.002689 | average reward: 0.125\n",
      "Step 87/467 | Average reward: 0.01953125 | Average sequence length: 137.04\n",
      "Step 88/467 | Example step 0 | Pass 0 | loss: -0.005203 | average reward: 0.0\n",
      "Step 88/467 | Example step 0 | Pass 1 | loss: 0.006232 | average reward: 0.125\n",
      "Step 88/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 88/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 88/467 | Average reward: 0.05859375 | Average sequence length: 145.43\n",
      "Step 89/467 | Example step 0 | Pass 0 | loss: -0.012769 | average reward: 0.0\n",
      "Step 89/467 | Example step 0 | Pass 1 | loss: 0.032137 | average reward: 0.125\n",
      "Step 89/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 89/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 89/467 | Average reward: 0.0703125 | Average sequence length: 148.95\n",
      "Step 90/467 | Example step 0 | Pass 0 | loss: -0.002916 | average reward: 0.0\n",
      "Step 90/467 | Example step 0 | Pass 1 | loss: 0.001459 | average reward: 0.125\n",
      "Step 90/467 | Example step 1 | Pass 0 | loss: -0.001362 | average reward: 0.125\n",
      "Step 90/467 | Example step 1 | Pass 1 | loss: -0.001344 | average reward: 0.25\n",
      "Step 90/467 | Average reward: 0.109375 | Average sequence length: 133.34\n",
      "Step 91/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 91/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 91/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 91/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 91/467 | Average reward: 0.0390625 | Average sequence length: 134.94\n",
      "Step 92/467 | Example step 0 | Pass 0 | loss: -0.005559 | average reward: 0.125\n",
      "Step 92/467 | Example step 0 | Pass 1 | loss: -0.001918 | average reward: 0.25\n",
      "Step 92/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 92/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 92/467 | Average reward: 0.0859375 | Average sequence length: 140.04\n",
      "Step 93/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 93/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 93/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 93/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 93/467 | Average reward: 0.0390625 | Average sequence length: 135.73\n",
      "Step 94/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 94/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 94/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 94/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 94/467 | Average reward: 0.0625 | Average sequence length: 145.07\n",
      "Step 95/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 95/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 95/467 | Example step 1 | Pass 0 | loss: 0.003839 | average reward: 0.125\n",
      "Step 95/467 | Example step 1 | Pass 1 | loss: -0.003709 | average reward: 0.0\n",
      "Step 95/467 | Average reward: 0.02734375 | Average sequence length: 132.37\n",
      "Step 96/467 | Example step 0 | Pass 0 | loss: 0.006498 | average reward: 0.125\n",
      "Step 96/467 | Example step 0 | Pass 1 | loss: -0.005380 | average reward: 0.0\n",
      "Step 96/467 | Example step 1 | Pass 0 | loss: 0.000459 | average reward: 0.375\n",
      "Step 96/467 | Example step 1 | Pass 1 | loss: -0.001545 | average reward: 0.25\n",
      "Step 96/467 | Average reward: 0.140625 | Average sequence length: 145.34\n",
      "Step 97/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 97/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 97/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 97/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 97/467 | Average reward: 0.01953125 | Average sequence length: 140.07\n",
      "Step 98/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 98/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 98/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 98/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 98/467 | Average reward: 0.05078125 | Average sequence length: 141.88\n",
      "Step 99/467 | Example step 0 | Pass 0 | loss: -0.003921 | average reward: 0.125\n",
      "Step 99/467 | Example step 0 | Pass 1 | loss: 0.010997 | average reward: 0.125\n",
      "Step 99/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 99/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 99/467 | Average reward: 0.08984375 | Average sequence length: 147.01\n",
      "Step 100/467 | Example step 0 | Pass 0 | loss: -0.002983 | average reward: 0.25\n",
      "Step 100/467 | Example step 0 | Pass 1 | loss: -0.002660 | average reward: 0.25\n",
      "Step 100/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 100/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 100/467 | Average reward: 0.05859375 | Average sequence length: 146.70\n",
      "Step 101/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 101/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 101/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 101/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 101/467 | Average reward: 0.05078125 | Average sequence length: 143.66\n",
      "Step 102/467 | Example step 0 | Pass 0 | loss: 0.002611 | average reward: 0.25\n",
      "Step 102/467 | Example step 0 | Pass 1 | loss: -0.007341 | average reward: 0.125\n",
      "Step 102/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 102/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 102/467 | Average reward: 0.03515625 | Average sequence length: 148.28\n",
      "Step 103/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 103/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 103/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 103/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 103/467 | Average reward: 0.05078125 | Average sequence length: 147.81\n",
      "Step 104/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 104/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 104/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 104/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 104/467 | Average reward: 0.0234375 | Average sequence length: 136.29\n",
      "Step 105/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 105/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 105/467 | Example step 1 | Pass 0 | loss: -0.005797 | average reward: 0.0\n",
      "Step 105/467 | Example step 1 | Pass 1 | loss: 0.008099 | average reward: 0.125\n",
      "Step 105/467 | Average reward: 0.1484375 | Average sequence length: 117.78\n",
      "Step 106/467 | Example step 0 | Pass 0 | loss: 0.000717 | average reward: 0.125\n",
      "Step 106/467 | Example step 0 | Pass 1 | loss: -0.005611 | average reward: 0.125\n",
      "Step 106/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 106/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 106/467 | Average reward: 0.015625 | Average sequence length: 129.05\n",
      "Step 107/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 107/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 107/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 107/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 107/467 | Average reward: 0.04296875 | Average sequence length: 135.39\n",
      "Step 108/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 108/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 108/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 108/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 108/467 | Average reward: 0.0078125 | Average sequence length: 142.02\n",
      "Step 109/467 | Example step 0 | Pass 0 | loss: 0.005892 | average reward: 0.75\n",
      "Step 109/467 | Example step 0 | Pass 1 | loss: -0.038891 | average reward: 0.0\n",
      "Step 109/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 109/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 109/467 | Average reward: 0.04296875 | Average sequence length: 144.36\n",
      "Step 110/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 110/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 110/467 | Example step 1 | Pass 0 | loss: 0.017733 | average reward: 0.25\n",
      "Step 110/467 | Example step 1 | Pass 1 | loss: -0.006836 | average reward: 0.0\n",
      "Step 110/467 | Average reward: 0.0546875 | Average sequence length: 135.46\n",
      "Step 111/467 | Example step 0 | Pass 0 | loss: -0.012667 | average reward: 0.0\n",
      "Step 111/467 | Example step 0 | Pass 1 | loss: 0.005614 | average reward: 0.25\n",
      "Step 111/467 | Example step 1 | Pass 0 | loss: -0.000477 | average reward: 0.5\n",
      "Step 111/467 | Example step 1 | Pass 1 | loss: 0.000744 | average reward: 0.5\n",
      "Step 111/467 | Average reward: 0.0859375 | Average sequence length: 133.75\n",
      "Step 112/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 112/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 112/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 112/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 112/467 | Average reward: 0.0703125 | Average sequence length: 147.20\n",
      "Step 113/467 | Example step 0 | Pass 0 | loss: -0.003392 | average reward: 0.0\n",
      "Step 113/467 | Example step 0 | Pass 1 | loss: 0.002700 | average reward: 0.125\n",
      "Step 113/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 113/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 113/467 | Average reward: 0.0390625 | Average sequence length: 143.72\n",
      "Step 114/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 114/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 114/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 114/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 114/467 | Average reward: 0.0234375 | Average sequence length: 163.66\n",
      "Step 115/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 115/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 115/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 115/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 115/467 | Average reward: 0.10546875 | Average sequence length: 123.93\n",
      "Step 116/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 116/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 116/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 116/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 116/467 | Average reward: 0.02734375 | Average sequence length: 139.61\n",
      "Step 117/467 | Example step 0 | Pass 0 | loss: -0.004727 | average reward: 0.0\n",
      "Step 117/467 | Example step 0 | Pass 1 | loss: 0.000473 | average reward: 0.125\n",
      "Step 117/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 117/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 117/467 | Average reward: 0.03515625 | Average sequence length: 137.84\n",
      "Step 118/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 118/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 118/467 | Example step 1 | Pass 0 | loss: -0.003321 | average reward: 0.0\n",
      "Step 118/467 | Example step 1 | Pass 1 | loss: 0.004718 | average reward: 0.125\n",
      "Step 118/467 | Average reward: 0.0546875 | Average sequence length: 140.92\n",
      "Step 119/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 119/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 119/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 119/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 119/467 | Average reward: 0.10546875 | Average sequence length: 130.09\n",
      "Step 120 | Pass@1: 0.0800, Pass@2: 0.1100, Pass@3: 0.1275, Pass@4: 0.1450, Pass@5: 0.1700, Pass@6: 0.1800, Pass@7: 0.1975, Pass@8: 0.2150\n",
      "Step 120/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 120/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 120/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 120/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 120/467 | Average reward: 0.05859375 | Average sequence length: 135.04\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000120.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000120.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "Step 121/467 | Example step 0 | Pass 0 | loss: -0.005746 | average reward: 0.0\n",
      "Step 121/467 | Example step 0 | Pass 1 | loss: 0.002804 | average reward: 0.25\n",
      "Step 121/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 121/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 121/467 | Average reward: 0.0625 | Average sequence length: 149.45\n",
      "Step 122/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 122/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 122/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 122/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 122/467 | Average reward: 0.05859375 | Average sequence length: 130.69\n",
      "Step 123/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 123/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 123/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 123/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 123/467 | Average reward: 0.03125 | Average sequence length: 125.70\n",
      "Step 124/467 | Example step 0 | Pass 0 | loss: 0.003420 | average reward: 0.125\n",
      "Step 124/467 | Example step 0 | Pass 1 | loss: -0.004141 | average reward: 0.125\n",
      "Step 124/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 124/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 124/467 | Average reward: 0.01953125 | Average sequence length: 149.91\n",
      "Step 125/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 125/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 125/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 125/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 125/467 | Average reward: 0.1015625 | Average sequence length: 118.53\n",
      "Step 126/467 | Example step 0 | Pass 0 | loss: -0.023075 | average reward: 0.5\n",
      "Step 126/467 | Example step 0 | Pass 1 | loss: 0.002483 | average reward: 0.625\n",
      "Step 126/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 126/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 126/467 | Average reward: 0.0625 | Average sequence length: 160.91\n",
      "Step 127/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 127/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 127/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 127/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 127/467 | Average reward: 0.0546875 | Average sequence length: 138.11\n",
      "Step 128/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 128/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 128/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 128/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 128/467 | Average reward: 0.01953125 | Average sequence length: 133.76\n",
      "Step 129/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 129/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 129/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 129/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 129/467 | Average reward: 0.015625 | Average sequence length: 137.91\n",
      "Step 130/467 | Example step 0 | Pass 0 | loss: -0.004955 | average reward: 0.0\n",
      "Step 130/467 | Example step 0 | Pass 1 | loss: 0.003395 | average reward: 0.125\n",
      "Step 130/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 130/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 130/467 | Average reward: 0.04296875 | Average sequence length: 136.99\n",
      "Step 131/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 131/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 131/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 131/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 131/467 | Average reward: 0.04296875 | Average sequence length: 137.90\n",
      "Step 132/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 132/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 132/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 132/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 132/467 | Average reward: 0.02734375 | Average sequence length: 134.73\n",
      "Step 133/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 133/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 133/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 133/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 133/467 | Average reward: 0.03515625 | Average sequence length: 142.35\n",
      "Step 134/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 134/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 134/467 | Example step 1 | Pass 0 | loss: 0.011049 | average reward: 0.75\n",
      "Step 134/467 | Example step 1 | Pass 1 | loss: -0.027265 | average reward: 0.125\n",
      "Step 134/467 | Average reward: 0.11328125 | Average sequence length: 119.82\n",
      "Step 135/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 135/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 135/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 135/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 135/467 | Average reward: 0.08984375 | Average sequence length: 128.52\n",
      "Step 136/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 136/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 136/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 136/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 136/467 | Average reward: 0.03125 | Average sequence length: 122.36\n",
      "Step 137/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 137/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 137/467 | Example step 1 | Pass 0 | loss: -0.001837 | average reward: 0.25\n",
      "Step 137/467 | Example step 1 | Pass 1 | loss: -0.008748 | average reward: 0.25\n",
      "Step 137/467 | Average reward: 0.02734375 | Average sequence length: 138.54\n",
      "Step 138/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 138/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 138/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 138/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 138/467 | Average reward: 0.0390625 | Average sequence length: 133.48\n",
      "Step 139/467 | Example step 0 | Pass 0 | loss: -0.003128 | average reward: 0.25\n",
      "Step 139/467 | Example step 0 | Pass 1 | loss: -0.004797 | average reward: 0.125\n",
      "Step 139/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 139/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 139/467 | Average reward: 0.109375 | Average sequence length: 137.46\n",
      "Step 140/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 140/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 140/467 | Example step 1 | Pass 0 | loss: 0.002905 | average reward: 0.125\n",
      "Step 140/467 | Example step 1 | Pass 1 | loss: -0.004631 | average reward: 0.0\n",
      "Step 140/467 | Average reward: 0.04296875 | Average sequence length: 144.49\n",
      "Step 141/467 | Example step 0 | Pass 0 | loss: -0.005342 | average reward: 0.0\n",
      "Step 141/467 | Example step 0 | Pass 1 | loss: 0.008259 | average reward: 0.25\n",
      "Step 141/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 141/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 141/467 | Average reward: 0.05859375 | Average sequence length: 136.62\n",
      "Step 142/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 142/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 142/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 142/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 142/467 | Average reward: 0.09765625 | Average sequence length: 116.37\n",
      "Step 143/467 | Example step 0 | Pass 0 | loss: -0.007741 | average reward: 0.0\n",
      "Step 143/467 | Example step 0 | Pass 1 | loss: 0.009090 | average reward: 0.125\n",
      "Step 143/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 143/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 143/467 | Average reward: 0.0625 | Average sequence length: 152.78\n",
      "Step 144/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 144/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 144/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 144/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 144/467 | Average reward: 0.08984375 | Average sequence length: 130.02\n",
      "Step 145/467 | Example step 0 | Pass 0 | loss: -0.002905 | average reward: 0.375\n",
      "Step 145/467 | Example step 0 | Pass 1 | loss: 0.004646 | average reward: 0.375\n",
      "Step 145/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 145/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 145/467 | Average reward: 0.06640625 | Average sequence length: 122.68\n",
      "Step 146/467 | Example step 0 | Pass 0 | loss: 0.002266 | average reward: 0.125\n",
      "Step 146/467 | Example step 0 | Pass 1 | loss: -0.003039 | average reward: 0.0\n",
      "Step 146/467 | Example step 1 | Pass 0 | loss: -0.005703 | average reward: 0.0\n",
      "Step 146/467 | Example step 1 | Pass 1 | loss: -0.002171 | average reward: 0.125\n",
      "Step 146/467 | Average reward: 0.0390625 | Average sequence length: 154.20\n",
      "Step 147/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 147/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 147/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 147/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 147/467 | Average reward: 0.03125 | Average sequence length: 143.01\n",
      "Step 148/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 148/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 148/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 148/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 148/467 | Average reward: 0.08984375 | Average sequence length: 122.99\n",
      "Step 149/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 149/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 149/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 149/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 149/467 | Average reward: 0.0546875 | Average sequence length: 130.07\n",
      "Step 150/467 | Example step 0 | Pass 0 | loss: 0.000137 | average reward: 0.375\n",
      "Step 150/467 | Example step 0 | Pass 1 | loss: -0.010808 | average reward: 0.0\n",
      "Step 150/467 | Example step 1 | Pass 0 | loss: -0.001166 | average reward: 0.125\n",
      "Step 150/467 | Example step 1 | Pass 1 | loss: -0.002931 | average reward: 0.125\n",
      "Step 150/467 | Average reward: 0.09375 | Average sequence length: 137.07\n",
      "Step 151/467 | Example step 0 | Pass 0 | loss: 0.000241 | average reward: 0.125\n",
      "Step 151/467 | Example step 0 | Pass 1 | loss: 0.000403 | average reward: 0.125\n",
      "Step 151/467 | Example step 1 | Pass 0 | loss: 0.000408 | average reward: 0.125\n",
      "Step 151/467 | Example step 1 | Pass 1 | loss: -0.003822 | average reward: 0.0\n",
      "Step 151/467 | Average reward: 0.13671875 | Average sequence length: 126.68\n",
      "Step 152/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 152/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 152/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 152/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 152/467 | Average reward: 0.0234375 | Average sequence length: 126.04\n",
      "Step 153/467 | Example step 0 | Pass 0 | loss: -0.001426 | average reward: 0.625\n",
      "Step 153/467 | Example step 0 | Pass 1 | loss: -0.021696 | average reward: 0.125\n",
      "Step 153/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 153/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 153/467 | Average reward: 0.03515625 | Average sequence length: 130.53\n",
      "Step 154/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 154/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 154/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 154/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 154/467 | Average reward: 0.03515625 | Average sequence length: 143.22\n",
      "Step 155/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 155/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 155/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 155/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 155/467 | Average reward: 0.03125 | Average sequence length: 124.54\n",
      "Step 156/467 | Example step 0 | Pass 0 | loss: -0.001388 | average reward: 0.25\n",
      "Step 156/467 | Example step 0 | Pass 1 | loss: 0.011656 | average reward: 0.25\n",
      "Step 156/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 156/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 156/467 | Average reward: 0.0390625 | Average sequence length: 139.76\n",
      "Step 157/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 157/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 157/467 | Example step 1 | Pass 0 | loss: -0.006476 | average reward: 0.0\n",
      "Step 157/467 | Example step 1 | Pass 1 | loss: 0.006316 | average reward: 0.25\n",
      "Step 157/467 | Average reward: 0.03125 | Average sequence length: 131.39\n",
      "Step 158/467 | Example step 0 | Pass 0 | loss: 0.004766 | average reward: 0.125\n",
      "Step 158/467 | Example step 0 | Pass 1 | loss: -0.003623 | average reward: 0.0\n",
      "Step 158/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 158/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 158/467 | Average reward: 0.05859375 | Average sequence length: 133.49\n",
      "Step 159/467 | Example step 0 | Pass 0 | loss: -0.005941 | average reward: 0.0\n",
      "Step 159/467 | Example step 0 | Pass 1 | loss: 0.012298 | average reward: 0.125\n",
      "Step 159/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 159/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 159/467 | Average reward: 0.0546875 | Average sequence length: 144.23\n",
      "Step 160/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 160/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 160/467 | Example step 1 | Pass 0 | loss: -0.008155 | average reward: 0.5\n",
      "Step 160/467 | Example step 1 | Pass 1 | loss: -0.000729 | average reward: 0.625\n",
      "Step 160/467 | Average reward: 0.1640625 | Average sequence length: 116.70\n",
      "Step 161/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 161/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 161/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 161/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 161/467 | Average reward: 0.015625 | Average sequence length: 114.61\n",
      "Step 162/467 | Example step 0 | Pass 0 | loss: 0.007155 | average reward: 0.375\n",
      "Step 162/467 | Example step 0 | Pass 1 | loss: -0.011917 | average reward: 0.0\n",
      "Step 162/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 162/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 162/467 | Average reward: 0.15625 | Average sequence length: 134.85\n",
      "Step 163/467 | Example step 0 | Pass 0 | loss: -0.005975 | average reward: 0.25\n",
      "Step 163/467 | Example step 0 | Pass 1 | loss: -0.001190 | average reward: 0.25\n",
      "Step 163/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 163/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 163/467 | Average reward: 0.0625 | Average sequence length: 140.96\n",
      "Step 164/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 164/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 164/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 164/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 164/467 | Average reward: 0.05859375 | Average sequence length: 126.74\n",
      "Step 165/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 165/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 165/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 165/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 165/467 | Average reward: 0.12109375 | Average sequence length: 143.00\n",
      "Step 166/467 | Example step 0 | Pass 0 | loss: 0.000086 | average reward: 0.25\n",
      "Step 166/467 | Example step 0 | Pass 1 | loss: 0.017956 | average reward: 0.375\n",
      "Step 166/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 166/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 166/467 | Average reward: 0.078125 | Average sequence length: 135.38\n",
      "Step 167/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 167/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 167/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 167/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 167/467 | Average reward: 0.07421875 | Average sequence length: 135.07\n",
      "Step 168/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 168/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 168/467 | Example step 1 | Pass 0 | loss: 0.000791 | average reward: 0.125\n",
      "Step 168/467 | Example step 1 | Pass 1 | loss: -0.000933 | average reward: 0.125\n",
      "Step 168/467 | Average reward: 0.02734375 | Average sequence length: 135.55\n",
      "Step 169/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 169/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 169/467 | Example step 1 | Pass 0 | loss: 0.001215 | average reward: 0.25\n",
      "Step 169/467 | Example step 1 | Pass 1 | loss: -0.008727 | average reward: 0.125\n",
      "Step 169/467 | Average reward: 0.0859375 | Average sequence length: 136.12\n",
      "Step 170/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 170/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 170/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 170/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 170/467 | Average reward: 0.0234375 | Average sequence length: 136.28\n",
      "Step 171/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 171/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 171/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 171/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 171/467 | Average reward: 0.07421875 | Average sequence length: 131.93\n",
      "Step 172/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 172/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 172/467 | Example step 1 | Pass 0 | loss: 0.000908 | average reward: 0.5\n",
      "Step 172/467 | Example step 1 | Pass 1 | loss: 0.001399 | average reward: 0.625\n",
      "Step 172/467 | Average reward: 0.05859375 | Average sequence length: 132.00\n",
      "Step 173/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 173/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 173/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 173/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 173/467 | Average reward: 0.0234375 | Average sequence length: 142.96\n",
      "Step 174/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 174/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 174/467 | Example step 1 | Pass 0 | loss: -0.006810 | average reward: 0.0\n",
      "Step 174/467 | Example step 1 | Pass 1 | loss: 0.009481 | average reward: 0.375\n",
      "Step 174/467 | Average reward: 0.12109375 | Average sequence length: 141.40\n",
      "Step 175/467 | Example step 0 | Pass 0 | loss: 0.001647 | average reward: 0.125\n",
      "Step 175/467 | Example step 0 | Pass 1 | loss: -0.000976 | average reward: 0.25\n",
      "Step 175/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 175/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 175/467 | Average reward: 0.11328125 | Average sequence length: 131.89\n",
      "Step 176/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 176/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 176/467 | Example step 1 | Pass 0 | loss: 0.009947 | average reward: 0.125\n",
      "Step 176/467 | Example step 1 | Pass 1 | loss: -0.004026 | average reward: 0.0\n",
      "Step 176/467 | Average reward: 0.06640625 | Average sequence length: 138.41\n",
      "Step 177/467 | Example step 0 | Pass 0 | loss: 0.010302 | average reward: 0.375\n",
      "Step 177/467 | Example step 0 | Pass 1 | loss: -0.010512 | average reward: 0.125\n",
      "Step 177/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 177/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 177/467 | Average reward: 0.10546875 | Average sequence length: 125.57\n",
      "Step 178/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 178/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 178/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 178/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 178/467 | Average reward: 0.078125 | Average sequence length: 135.52\n",
      "Step 179/467 | Example step 0 | Pass 0 | loss: -0.005108 | average reward: 0.5\n",
      "Step 179/467 | Example step 0 | Pass 1 | loss: 0.005798 | average reward: 0.75\n",
      "Step 179/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 179/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 179/467 | Average reward: 0.2421875 | Average sequence length: 128.32\n",
      "Step 180 | Pass@1: 0.0875, Pass@2: 0.1275, Pass@3: 0.1675, Pass@4: 0.1975, Pass@5: 0.2125, Pass@6: 0.2350, Pass@7: 0.2550, Pass@8: 0.2600\n",
      "Step 180/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 180/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 180/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 180/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 180/467 | Average reward: 0.07421875 | Average sequence length: 151.75\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000180.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000180.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "Step 181/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 181/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 181/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 181/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 181/467 | Average reward: 0.0703125 | Average sequence length: 126.11\n",
      "Step 182/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 182/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 182/467 | Example step 1 | Pass 0 | loss: -0.004485 | average reward: 0.375\n",
      "Step 182/467 | Example step 1 | Pass 1 | loss: -0.009936 | average reward: 0.125\n",
      "Step 182/467 | Average reward: 0.10546875 | Average sequence length: 140.41\n",
      "Step 183/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 183/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 183/467 | Example step 1 | Pass 0 | loss: -0.002740 | average reward: 0.125\n",
      "Step 183/467 | Example step 1 | Pass 1 | loss: 0.003010 | average reward: 0.125\n",
      "Step 183/467 | Average reward: 0.1015625 | Average sequence length: 138.29\n",
      "Step 184/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 184/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 184/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 184/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 184/467 | Average reward: 0.08984375 | Average sequence length: 145.03\n",
      "Step 185/467 | Example step 0 | Pass 0 | loss: -0.009757 | average reward: 0.125\n",
      "Step 185/467 | Example step 0 | Pass 1 | loss: 0.006052 | average reward: 0.375\n",
      "Step 185/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 185/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 185/467 | Average reward: 0.09765625 | Average sequence length: 130.93\n",
      "Step 186/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 186/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 186/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 186/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 186/467 | Average reward: 0.2265625 | Average sequence length: 142.96\n",
      "Step 187/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 187/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 187/467 | Example step 1 | Pass 0 | loss: 0.013314 | average reward: 0.125\n",
      "Step 187/467 | Example step 1 | Pass 1 | loss: -0.004584 | average reward: 0.0\n",
      "Step 187/467 | Average reward: 0.04296875 | Average sequence length: 146.09\n",
      "Step 188/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 188/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 188/467 | Example step 1 | Pass 0 | loss: 0.003047 | average reward: 0.125\n",
      "Step 188/467 | Example step 1 | Pass 1 | loss: -0.001349 | average reward: 0.0\n",
      "Step 188/467 | Average reward: 0.15625 | Average sequence length: 140.43\n",
      "Step 189/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 189/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 189/467 | Example step 1 | Pass 0 | loss: 0.011096 | average reward: 1.0\n",
      "Step 189/467 | Example step 1 | Pass 1 | loss: -0.021320 | average reward: 0.5\n",
      "Step 189/467 | Average reward: 0.17578125 | Average sequence length: 136.83\n",
      "Step 190/467 | Example step 0 | Pass 0 | loss: -0.003137 | average reward: 0.0\n",
      "Step 190/467 | Example step 0 | Pass 1 | loss: 0.006768 | average reward: 0.125\n",
      "Step 190/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 190/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 190/467 | Average reward: 0.09375 | Average sequence length: 137.37\n",
      "Step 191/467 | Example step 0 | Pass 0 | loss: -0.001501 | average reward: 0.125\n",
      "Step 191/467 | Example step 0 | Pass 1 | loss: 0.005254 | average reward: 0.125\n",
      "Step 191/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 191/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 191/467 | Average reward: 0.0859375 | Average sequence length: 148.23\n",
      "Step 192/467 | Example step 0 | Pass 0 | loss: 0.000139 | average reward: 0.25\n",
      "Step 192/467 | Example step 0 | Pass 1 | loss: -0.003988 | average reward: 0.25\n",
      "Step 192/467 | Example step 1 | Pass 0 | loss: -0.010024 | average reward: 0.0\n",
      "Step 192/467 | Example step 1 | Pass 1 | loss: 0.003177 | average reward: 0.25\n",
      "Step 192/467 | Average reward: 0.04296875 | Average sequence length: 141.50\n",
      "Step 193/467 | Example step 0 | Pass 0 | loss: -0.003816 | average reward: 0.375\n",
      "Step 193/467 | Example step 0 | Pass 1 | loss: -0.004465 | average reward: 0.25\n",
      "Step 193/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 193/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 193/467 | Average reward: 0.06640625 | Average sequence length: 155.83\n",
      "Step 194/467 | Example step 0 | Pass 0 | loss: -0.005361 | average reward: 0.0\n",
      "Step 194/467 | Example step 0 | Pass 1 | loss: 0.012691 | average reward: 0.25\n",
      "Step 194/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 194/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 194/467 | Average reward: 0.125 | Average sequence length: 145.95\n",
      "Step 195/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 195/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 195/467 | Example step 1 | Pass 0 | loss: 0.023598 | average reward: 0.375\n",
      "Step 195/467 | Example step 1 | Pass 1 | loss: -0.023260 | average reward: 0.0\n",
      "Step 195/467 | Average reward: 0.06640625 | Average sequence length: 144.57\n",
      "Step 196/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 196/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 196/467 | Example step 1 | Pass 0 | loss: 0.007092 | average reward: 0.5\n",
      "Step 196/467 | Example step 1 | Pass 1 | loss: -0.014309 | average reward: 0.25\n",
      "Step 196/467 | Average reward: 0.1328125 | Average sequence length: 141.34\n",
      "Step 197/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 197/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 197/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 197/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 197/467 | Average reward: 0.16015625 | Average sequence length: 120.66\n",
      "Step 198/467 | Example step 0 | Pass 0 | loss: -0.004534 | average reward: 0.25\n",
      "Step 198/467 | Example step 0 | Pass 1 | loss: 0.002409 | average reward: 0.25\n",
      "Step 198/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 198/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 198/467 | Average reward: 0.08203125 | Average sequence length: 157.58\n",
      "Step 199/467 | Example step 0 | Pass 0 | loss: -0.010931 | average reward: 0.625\n",
      "Step 199/467 | Example step 0 | Pass 1 | loss: -0.003301 | average reward: 0.625\n",
      "Step 199/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 199/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 199/467 | Average reward: 0.0859375 | Average sequence length: 139.94\n",
      "Step 200/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 200/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 200/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 200/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 200/467 | Average reward: 0.046875 | Average sequence length: 133.77\n",
      "Step 201/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 201/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 201/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 201/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 201/467 | Average reward: 0.07421875 | Average sequence length: 134.09\n",
      "Step 202/467 | Example step 0 | Pass 0 | loss: -0.000195 | average reward: 0.125\n",
      "Step 202/467 | Example step 0 | Pass 1 | loss: -0.007038 | average reward: 0.125\n",
      "Step 202/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 202/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 202/467 | Average reward: 0.14453125 | Average sequence length: 121.60\n",
      "Step 203/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 203/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 203/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 203/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 203/467 | Average reward: 0.0703125 | Average sequence length: 133.82\n",
      "Step 204/467 | Example step 0 | Pass 0 | loss: -0.007864 | average reward: 0.25\n",
      "Step 204/467 | Example step 0 | Pass 1 | loss: 0.011781 | average reward: 0.375\n",
      "Step 204/467 | Example step 1 | Pass 0 | loss: -0.002773 | average reward: 0.125\n",
      "Step 204/467 | Example step 1 | Pass 1 | loss: 0.007407 | average reward: 0.125\n",
      "Step 204/467 | Average reward: 0.05078125 | Average sequence length: 156.44\n",
      "Step 205/467 | Example step 0 | Pass 0 | loss: -0.004955 | average reward: 0.0\n",
      "Step 205/467 | Example step 0 | Pass 1 | loss: 0.005512 | average reward: 0.125\n",
      "Step 205/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 205/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 205/467 | Average reward: 0.07421875 | Average sequence length: 126.86\n",
      "Step 206/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 206/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 206/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 206/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 206/467 | Average reward: 0.08984375 | Average sequence length: 137.88\n",
      "Step 207/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 207/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 207/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 207/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 207/467 | Average reward: 0.10546875 | Average sequence length: 127.29\n",
      "Step 208/467 | Example step 0 | Pass 0 | loss: -0.018268 | average reward: 0.5\n",
      "Step 208/467 | Example step 0 | Pass 1 | loss: 0.007578 | average reward: 0.875\n",
      "Step 208/467 | Example step 1 | Pass 0 | loss: 0.011408 | average reward: 0.125\n",
      "Step 208/467 | Example step 1 | Pass 1 | loss: -0.009486 | average reward: 0.0\n",
      "Step 208/467 | Average reward: 0.1640625 | Average sequence length: 142.91\n",
      "Step 209/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 209/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 209/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 209/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 209/467 | Average reward: 0.12109375 | Average sequence length: 138.28\n",
      "Step 210/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 210/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 210/467 | Example step 1 | Pass 0 | loss: -0.000398 | average reward: 0.625\n",
      "Step 210/467 | Example step 1 | Pass 1 | loss: -0.009486 | average reward: 0.25\n",
      "Step 210/467 | Average reward: 0.07421875 | Average sequence length: 127.80\n",
      "Step 211/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 211/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 211/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 211/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 211/467 | Average reward: 0.14453125 | Average sequence length: 130.22\n",
      "Step 212/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 212/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 212/467 | Example step 1 | Pass 0 | loss: 0.002941 | average reward: 0.125\n",
      "Step 212/467 | Example step 1 | Pass 1 | loss: -0.003242 | average reward: 0.0\n",
      "Step 212/467 | Average reward: 0.046875 | Average sequence length: 155.38\n",
      "Step 213/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 213/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 213/467 | Example step 1 | Pass 0 | loss: -0.013829 | average reward: 0.625\n",
      "Step 213/467 | Example step 1 | Pass 1 | loss: 0.002712 | average reward: 1.0\n",
      "Step 213/467 | Average reward: 0.078125 | Average sequence length: 132.45\n",
      "Step 214/467 | Example step 0 | Pass 0 | loss: 0.009116 | average reward: 1.0\n",
      "Step 214/467 | Example step 0 | Pass 1 | loss: -0.005510 | average reward: 0.75\n",
      "Step 214/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 214/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 214/467 | Average reward: 0.125 | Average sequence length: 135.89\n",
      "Step 215/467 | Example step 0 | Pass 0 | loss: -0.002723 | average reward: 0.0\n",
      "Step 215/467 | Example step 0 | Pass 1 | loss: 0.005670 | average reward: 0.125\n",
      "Step 215/467 | Example step 1 | Pass 0 | loss: 0.005078 | average reward: 1.0\n",
      "Step 215/467 | Example step 1 | Pass 1 | loss: -0.014366 | average reward: 0.75\n",
      "Step 215/467 | Average reward: 0.1015625 | Average sequence length: 128.48\n",
      "Step 216/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 216/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 216/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 216/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 216/467 | Average reward: 0.125 | Average sequence length: 131.84\n",
      "Step 217/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 217/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 217/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 217/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 217/467 | Average reward: 0.08984375 | Average sequence length: 126.86\n",
      "Step 218/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 218/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 218/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 218/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 218/467 | Average reward: 0.1328125 | Average sequence length: 132.06\n",
      "Step 219/467 | Example step 0 | Pass 0 | loss: -0.004911 | average reward: 0.0\n",
      "Step 219/467 | Example step 0 | Pass 1 | loss: 0.008915 | average reward: 0.125\n",
      "Step 219/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 219/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 219/467 | Average reward: 0.046875 | Average sequence length: 125.77\n",
      "Step 220/467 | Example step 0 | Pass 0 | loss: -0.000551 | average reward: 0.125\n",
      "Step 220/467 | Example step 0 | Pass 1 | loss: -0.005076 | average reward: 0.0\n",
      "Step 220/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 220/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 220/467 | Average reward: 0.04296875 | Average sequence length: 145.71\n",
      "Step 221/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 221/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 221/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 221/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 221/467 | Average reward: 0.1171875 | Average sequence length: 133.36\n",
      "Step 222/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 222/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 222/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 222/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 222/467 | Average reward: 0.0625 | Average sequence length: 129.60\n",
      "Step 223/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 223/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 223/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 223/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 223/467 | Average reward: 0.02734375 | Average sequence length: 143.35\n",
      "Step 224/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 224/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 224/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 224/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 224/467 | Average reward: 0.0234375 | Average sequence length: 151.64\n",
      "Step 225/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 225/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 225/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 225/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 225/467 | Average reward: 0.11328125 | Average sequence length: 133.30\n",
      "Step 226/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 226/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 226/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 226/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 226/467 | Average reward: 0.07421875 | Average sequence length: 138.21\n",
      "Step 227/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 227/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 227/467 | Example step 1 | Pass 0 | loss: -0.005795 | average reward: 0.25\n",
      "Step 227/467 | Example step 1 | Pass 1 | loss: 0.004963 | average reward: 0.375\n",
      "Step 227/467 | Average reward: 0.1171875 | Average sequence length: 150.25\n",
      "Step 228/467 | Example step 0 | Pass 0 | loss: -0.004358 | average reward: 0.875\n",
      "Step 228/467 | Example step 0 | Pass 1 | loss: 0.002448 | average reward: 1.0\n",
      "Step 228/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 228/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 228/467 | Average reward: 0.11328125 | Average sequence length: 126.78\n",
      "Step 229/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 229/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 229/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 229/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 229/467 | Average reward: 0.18359375 | Average sequence length: 141.09\n",
      "Step 230/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 230/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 230/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 230/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 230/467 | Average reward: 0.1484375 | Average sequence length: 134.62\n",
      "Step 231/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 231/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 231/467 | Example step 1 | Pass 0 | loss: -0.011400 | average reward: 0.0\n",
      "Step 231/467 | Example step 1 | Pass 1 | loss: 0.005143 | average reward: 0.375\n",
      "Step 231/467 | Average reward: 0.140625 | Average sequence length: 128.75\n",
      "Step 232/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 232/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 232/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 232/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 232/467 | Average reward: 0.09765625 | Average sequence length: 155.48\n",
      "Step 233/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 233/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 233/467 | Example step 1 | Pass 0 | loss: -0.004843 | average reward: 0.0\n",
      "Step 233/467 | Example step 1 | Pass 1 | loss: 0.003608 | average reward: 0.125\n",
      "Step 233/467 | Average reward: 0.1015625 | Average sequence length: 144.71\n",
      "Step 234/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 234/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 234/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 234/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 234/467 | Average reward: 0.05078125 | Average sequence length: 141.06\n",
      "Step 235/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 235/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 235/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 235/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 235/467 | Average reward: 0.125 | Average sequence length: 138.98\n",
      "Step 236/467 | Example step 0 | Pass 0 | loss: -0.001508 | average reward: 0.125\n",
      "Step 236/467 | Example step 0 | Pass 1 | loss: -0.000907 | average reward: 0.125\n",
      "Step 236/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 236/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 236/467 | Average reward: 0.06640625 | Average sequence length: 134.80\n",
      "Step 237/467 | Example step 0 | Pass 0 | loss: 0.000688 | average reward: 0.125\n",
      "Step 237/467 | Example step 0 | Pass 1 | loss: -0.003602 | average reward: 0.0\n",
      "Step 237/467 | Example step 1 | Pass 0 | loss: -0.010116 | average reward: 0.5\n",
      "Step 237/467 | Example step 1 | Pass 1 | loss: 0.001512 | average reward: 0.875\n",
      "Step 237/467 | Average reward: 0.2265625 | Average sequence length: 135.42\n",
      "Step 238/467 | Example step 0 | Pass 0 | loss: 0.004454 | average reward: 0.125\n",
      "Step 238/467 | Example step 0 | Pass 1 | loss: -0.003950 | average reward: 0.0\n",
      "Step 238/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 238/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 238/467 | Average reward: 0.10546875 | Average sequence length: 139.78\n",
      "Step 239/467 | Example step 0 | Pass 0 | loss: 0.004747 | average reward: 0.125\n",
      "Step 239/467 | Example step 0 | Pass 1 | loss: -0.003754 | average reward: 0.0\n",
      "Step 239/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 239/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 239/467 | Average reward: 0.03515625 | Average sequence length: 143.47\n",
      "Step 240 | Pass@1: 0.1075, Pass@2: 0.1450, Pass@3: 0.1775, Pass@4: 0.2175, Pass@5: 0.2350, Pass@6: 0.2425, Pass@7: 0.2775, Pass@8: 0.2850\n",
      "Step 240/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 240/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 240/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 240/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 240/467 | Average reward: 0.0546875 | Average sequence length: 122.36\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000240.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000240.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "Step 241/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 241/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 241/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 241/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 241/467 | Average reward: 0.05859375 | Average sequence length: 125.37\n",
      "Step 242/467 | Example step 0 | Pass 0 | loss: -0.003416 | average reward: 0.0\n",
      "Step 242/467 | Example step 0 | Pass 1 | loss: 0.001738 | average reward: 0.125\n",
      "Step 242/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 242/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 242/467 | Average reward: 0.08203125 | Average sequence length: 134.36\n",
      "Step 243/467 | Example step 0 | Pass 0 | loss: -0.008051 | average reward: 0.125\n",
      "Step 243/467 | Example step 0 | Pass 1 | loss: 0.002224 | average reward: 0.375\n",
      "Step 243/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 243/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 243/467 | Average reward: 0.03515625 | Average sequence length: 135.70\n",
      "Step 244/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 244/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 244/467 | Example step 1 | Pass 0 | loss: -0.009216 | average reward: 0.0\n",
      "Step 244/467 | Example step 1 | Pass 1 | loss: 0.018881 | average reward: 0.25\n",
      "Step 244/467 | Average reward: 0.05078125 | Average sequence length: 140.41\n",
      "Step 245/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 245/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 245/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 245/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 245/467 | Average reward: 0.171875 | Average sequence length: 138.19\n",
      "Step 246/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 246/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 246/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 246/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 246/467 | Average reward: 0.1015625 | Average sequence length: 128.92\n",
      "Step 247/467 | Example step 0 | Pass 0 | loss: -0.003466 | average reward: 0.0\n",
      "Step 247/467 | Example step 0 | Pass 1 | loss: 0.005937 | average reward: 0.125\n",
      "Step 247/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 247/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 247/467 | Average reward: 0.01953125 | Average sequence length: 129.07\n",
      "Step 248/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 248/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 248/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 248/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 248/467 | Average reward: 0.01171875 | Average sequence length: 146.45\n",
      "Step 249/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 249/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 249/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 249/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 249/467 | Average reward: 0.01953125 | Average sequence length: 136.62\n",
      "Step 250/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 250/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 250/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 250/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 250/467 | Average reward: 0.15234375 | Average sequence length: 149.75\n",
      "Step 251/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 251/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 251/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 251/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 251/467 | Average reward: 0.05078125 | Average sequence length: 138.16\n",
      "Step 252/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 252/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 252/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 252/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 252/467 | Average reward: 0.0078125 | Average sequence length: 144.90\n",
      "Step 253/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 253/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 253/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 253/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 253/467 | Average reward: 0.10546875 | Average sequence length: 129.30\n",
      "Step 254/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 254/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 254/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 254/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 254/467 | Average reward: 0.28515625 | Average sequence length: 127.35\n",
      "Step 255/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 255/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 255/467 | Example step 1 | Pass 0 | loss: -0.005711 | average reward: 0.75\n",
      "Step 255/467 | Example step 1 | Pass 1 | loss: -0.034186 | average reward: 0.375\n",
      "Step 255/467 | Average reward: 0.08984375 | Average sequence length: 131.90\n",
      "Step 256/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 256/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 256/467 | Example step 1 | Pass 0 | loss: 0.000396 | average reward: 0.125\n",
      "Step 256/467 | Example step 1 | Pass 1 | loss: -0.002247 | average reward: 0.125\n",
      "Step 256/467 | Average reward: 0.04296875 | Average sequence length: 133.54\n",
      "Step 257/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 257/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 257/467 | Example step 1 | Pass 0 | loss: -0.004100 | average reward: 0.0\n",
      "Step 257/467 | Example step 1 | Pass 1 | loss: -0.001443 | average reward: 0.125\n",
      "Step 257/467 | Average reward: 0.00390625 | Average sequence length: 129.62\n",
      "Step 258/467 | Example step 0 | Pass 0 | loss: -0.001872 | average reward: 0.125\n",
      "Step 258/467 | Example step 0 | Pass 1 | loss: 0.010943 | average reward: 0.25\n",
      "Step 258/467 | Example step 1 | Pass 0 | loss: -0.000003 | average reward: 0.375\n",
      "Step 258/467 | Example step 1 | Pass 1 | loss: -0.002857 | average reward: 0.375\n",
      "Step 258/467 | Average reward: 0.125 | Average sequence length: 129.50\n",
      "Step 259/467 | Example step 0 | Pass 0 | loss: -0.006223 | average reward: 0.0\n",
      "Step 259/467 | Example step 0 | Pass 1 | loss: 0.015079 | average reward: 0.25\n",
      "Step 259/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 259/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 259/467 | Average reward: 0.06640625 | Average sequence length: 134.95\n",
      "Step 260/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 260/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 260/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 260/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 260/467 | Average reward: 0.09765625 | Average sequence length: 115.45\n",
      "Step 261/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 261/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 261/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 261/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 261/467 | Average reward: 0.0703125 | Average sequence length: 141.26\n",
      "Step 262/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 262/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 262/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 262/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 262/467 | Average reward: 0.02734375 | Average sequence length: 144.50\n",
      "Step 263/467 | Example step 0 | Pass 0 | loss: 0.007324 | average reward: 0.75\n",
      "Step 263/467 | Example step 0 | Pass 1 | loss: -0.009765 | average reward: 0.5\n",
      "Step 263/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 263/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 263/467 | Average reward: 0.1640625 | Average sequence length: 132.29\n",
      "Step 264/467 | Example step 0 | Pass 0 | loss: -0.003046 | average reward: 0.25\n",
      "Step 264/467 | Example step 0 | Pass 1 | loss: -0.006588 | average reward: 0.25\n",
      "Step 264/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 264/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 264/467 | Average reward: 0.0390625 | Average sequence length: 127.45\n",
      "Step 265/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 265/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 265/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 265/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 265/467 | Average reward: 0.0625 | Average sequence length: 125.91\n",
      "Step 266/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 266/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 266/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 266/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 266/467 | Average reward: 0.015625 | Average sequence length: 140.05\n",
      "Step 267/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 267/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 267/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 267/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 267/467 | Average reward: 0.078125 | Average sequence length: 130.80\n",
      "Step 268/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 268/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 268/467 | Example step 1 | Pass 0 | loss: -0.008890 | average reward: 0.125\n",
      "Step 268/467 | Example step 1 | Pass 1 | loss: -0.002794 | average reward: 0.25\n",
      "Step 268/467 | Average reward: 0.078125 | Average sequence length: 144.05\n",
      "Step 269/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 269/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 269/467 | Example step 1 | Pass 0 | loss: -0.029003 | average reward: 0.5\n",
      "Step 269/467 | Example step 1 | Pass 1 | loss: 0.000247 | average reward: 0.75\n",
      "Step 269/467 | Average reward: 0.16796875 | Average sequence length: 129.11\n",
      "Step 270/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 270/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 270/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 270/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 270/467 | Average reward: 0.046875 | Average sequence length: 135.62\n",
      "Step 271/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 271/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 271/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 271/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 271/467 | Average reward: 0.02734375 | Average sequence length: 119.32\n",
      "Step 272/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 272/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 272/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 272/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 272/467 | Average reward: 0.015625 | Average sequence length: 134.41\n",
      "Step 273/467 | Example step 0 | Pass 0 | loss: 0.004338 | average reward: 0.25\n",
      "Step 273/467 | Example step 0 | Pass 1 | loss: 0.003425 | average reward: 0.25\n",
      "Step 273/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 273/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 273/467 | Average reward: 0.0546875 | Average sequence length: 124.97\n",
      "Step 274/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 274/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 274/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 274/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 274/467 | Average reward: 0.0703125 | Average sequence length: 133.61\n",
      "Step 275/467 | Example step 0 | Pass 0 | loss: 0.001621 | average reward: 0.25\n",
      "Step 275/467 | Example step 0 | Pass 1 | loss: -0.000778 | average reward: 0.125\n",
      "Step 275/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 275/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 275/467 | Average reward: 0.11328125 | Average sequence length: 126.29\n",
      "Step 276/467 | Example step 0 | Pass 0 | loss: -0.005049 | average reward: 0.0\n",
      "Step 276/467 | Example step 0 | Pass 1 | loss: 0.001515 | average reward: 0.125\n",
      "Step 276/467 | Example step 1 | Pass 0 | loss: 0.003143 | average reward: 0.125\n",
      "Step 276/467 | Example step 1 | Pass 1 | loss: -0.008156 | average reward: 0.0\n",
      "Step 276/467 | Average reward: 0.14453125 | Average sequence length: 122.02\n",
      "Step 277/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 277/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 277/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 277/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 277/467 | Average reward: 0.1796875 | Average sequence length: 139.98\n",
      "Step 278/467 | Example step 0 | Pass 0 | loss: -0.003234 | average reward: 0.0\n",
      "Step 278/467 | Example step 0 | Pass 1 | loss: 0.000218 | average reward: 0.125\n",
      "Step 278/467 | Example step 1 | Pass 0 | loss: 0.004769 | average reward: 0.125\n",
      "Step 278/467 | Example step 1 | Pass 1 | loss: -0.004231 | average reward: 0.0\n",
      "Step 278/467 | Average reward: 0.05078125 | Average sequence length: 125.41\n",
      "Step 279/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 279/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 279/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 279/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 279/467 | Average reward: 0.015625 | Average sequence length: 133.65\n",
      "Step 280/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 280/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 280/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 280/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 280/467 | Average reward: 0.14453125 | Average sequence length: 122.55\n",
      "Step 281/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 281/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 281/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 281/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 281/467 | Average reward: 0.0703125 | Average sequence length: 145.69\n",
      "Step 282/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 282/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 282/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 282/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 282/467 | Average reward: 0.07421875 | Average sequence length: 122.52\n",
      "Step 283/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 283/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 283/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 283/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 283/467 | Average reward: 0.109375 | Average sequence length: 120.06\n",
      "Step 284/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 284/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 284/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 284/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 284/467 | Average reward: 0.01953125 | Average sequence length: 131.67\n",
      "Step 285/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 285/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 285/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 285/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 285/467 | Average reward: 0.03515625 | Average sequence length: 119.80\n",
      "Step 286/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 286/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 286/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 286/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 286/467 | Average reward: 0.09375 | Average sequence length: 149.58\n",
      "Step 287/467 | Example step 0 | Pass 0 | loss: -0.002311 | average reward: 0.5\n",
      "Step 287/467 | Example step 0 | Pass 1 | loss: -0.004681 | average reward: 0.375\n",
      "Step 287/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 287/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 287/467 | Average reward: 0.23046875 | Average sequence length: 123.67\n",
      "Step 288/467 | Example step 0 | Pass 0 | loss: 0.000357 | average reward: 0.125\n",
      "Step 288/467 | Example step 0 | Pass 1 | loss: -0.000769 | average reward: 0.125\n",
      "Step 288/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 288/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 288/467 | Average reward: 0.0390625 | Average sequence length: 143.68\n",
      "Step 289/467 | Example step 0 | Pass 0 | loss: 0.012154 | average reward: 0.125\n",
      "Step 289/467 | Example step 0 | Pass 1 | loss: -0.006131 | average reward: 0.0\n",
      "Step 289/467 | Example step 1 | Pass 0 | loss: -0.017934 | average reward: 0.25\n",
      "Step 289/467 | Example step 1 | Pass 1 | loss: -0.005823 | average reward: 0.25\n",
      "Step 289/467 | Average reward: 0.12109375 | Average sequence length: 130.15\n",
      "Step 290/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 290/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 290/467 | Example step 1 | Pass 0 | loss: 0.005079 | average reward: 0.125\n",
      "Step 290/467 | Example step 1 | Pass 1 | loss: -0.003896 | average reward: 0.0\n",
      "Step 290/467 | Average reward: 0.1953125 | Average sequence length: 136.88\n",
      "Step 291/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 291/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 291/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 291/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 291/467 | Average reward: 0.0546875 | Average sequence length: 136.52\n",
      "Step 292/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 292/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 292/467 | Example step 1 | Pass 0 | loss: -0.022700 | average reward: 0.125\n",
      "Step 292/467 | Example step 1 | Pass 1 | loss: 0.023804 | average reward: 0.625\n",
      "Step 292/467 | Average reward: 0.05859375 | Average sequence length: 131.42\n",
      "Step 293/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 293/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 293/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 293/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 293/467 | Average reward: 0.046875 | Average sequence length: 141.71\n",
      "Step 294/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 294/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 294/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 294/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 294/467 | Average reward: 0.078125 | Average sequence length: 146.44\n",
      "Step 295/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 295/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 295/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 295/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 295/467 | Average reward: 0.04296875 | Average sequence length: 147.57\n",
      "Step 296/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 296/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 296/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 296/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 296/467 | Average reward: 0.0703125 | Average sequence length: 137.05\n",
      "Step 297/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 297/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 297/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 297/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 297/467 | Average reward: 0.1328125 | Average sequence length: 136.61\n",
      "Step 298/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 298/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 298/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 298/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 298/467 | Average reward: 0.078125 | Average sequence length: 124.04\n",
      "Step 299/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 299/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 299/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 299/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 299/467 | Average reward: 0.0625 | Average sequence length: 122.43\n",
      "Step 300 | Pass@1: 0.1075, Pass@2: 0.1400, Pass@3: 0.1700, Pass@4: 0.1900, Pass@5: 0.2125, Pass@6: 0.2200, Pass@7: 0.2350, Pass@8: 0.2400\n",
      "Step 300/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 300/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 300/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 300/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 300/467 | Average reward: 0.07421875 | Average sequence length: 129.98\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000300.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000300.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "Step 301/467 | Example step 0 | Pass 0 | loss: 0.003151 | average reward: 0.125\n",
      "Step 301/467 | Example step 0 | Pass 1 | loss: -0.009763 | average reward: 0.0\n",
      "Step 301/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 301/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 301/467 | Average reward: 0.05859375 | Average sequence length: 130.09\n",
      "Step 302/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 302/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 302/467 | Example step 1 | Pass 0 | loss: -0.009400 | average reward: 0.125\n",
      "Step 302/467 | Example step 1 | Pass 1 | loss: 0.002077 | average reward: 0.25\n",
      "Step 302/467 | Average reward: 0.08203125 | Average sequence length: 127.59\n",
      "Step 303/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 303/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 303/467 | Example step 1 | Pass 0 | loss: 0.001522 | average reward: 0.125\n",
      "Step 303/467 | Example step 1 | Pass 1 | loss: -0.005279 | average reward: 0.0\n",
      "Step 303/467 | Average reward: 0.02734375 | Average sequence length: 151.69\n",
      "Step 304/467 | Example step 0 | Pass 0 | loss: -0.010741 | average reward: 0.375\n",
      "Step 304/467 | Example step 0 | Pass 1 | loss: -0.012562 | average reward: 0.25\n",
      "Step 304/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 304/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 304/467 | Average reward: 0.078125 | Average sequence length: 123.50\n",
      "Step 305/467 | Example step 0 | Pass 0 | loss: 0.002065 | average reward: 1.0\n",
      "Step 305/467 | Example step 0 | Pass 1 | loss: -0.002042 | average reward: 0.875\n",
      "Step 305/467 | Example step 1 | Pass 0 | loss: -0.003763 | average reward: 0.0\n",
      "Step 305/467 | Example step 1 | Pass 1 | loss: 0.006411 | average reward: 0.125\n",
      "Step 305/467 | Average reward: 0.109375 | Average sequence length: 129.77\n",
      "Step 306/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 306/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 306/467 | Example step 1 | Pass 0 | loss: -0.006319 | average reward: 0.0\n",
      "Step 306/467 | Example step 1 | Pass 1 | loss: 0.006559 | average reward: 0.125\n",
      "Step 306/467 | Average reward: 0.03125 | Average sequence length: 125.65\n",
      "Step 307/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 307/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 307/467 | Example step 1 | Pass 0 | loss: -0.003056 | average reward: 0.0\n",
      "Step 307/467 | Example step 1 | Pass 1 | loss: 0.003768 | average reward: 0.125\n",
      "Step 307/467 | Average reward: 0.1328125 | Average sequence length: 142.05\n",
      "Step 308/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 308/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 308/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 308/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 308/467 | Average reward: 0.0078125 | Average sequence length: 148.14\n",
      "Step 309/467 | Example step 0 | Pass 0 | loss: -0.001170 | average reward: 0.875\n",
      "Step 309/467 | Example step 0 | Pass 1 | loss: -0.007220 | average reward: 0.75\n",
      "Step 309/467 | Example step 1 | Pass 0 | loss: -0.020289 | average reward: 0.125\n",
      "Step 309/467 | Example step 1 | Pass 1 | loss: 0.006252 | average reward: 0.625\n",
      "Step 309/467 | Average reward: 0.078125 | Average sequence length: 127.80\n",
      "Step 310/467 | Example step 0 | Pass 0 | loss: 0.001821 | average reward: 0.25\n",
      "Step 310/467 | Example step 0 | Pass 1 | loss: -0.006920 | average reward: 0.0\n",
      "Step 310/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 310/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 310/467 | Average reward: 0.13671875 | Average sequence length: 128.38\n",
      "Step 311/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 311/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 311/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 311/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 311/467 | Average reward: 0.0625 | Average sequence length: 134.53\n",
      "Step 312/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 312/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 312/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 312/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 312/467 | Average reward: 0.0390625 | Average sequence length: 125.42\n",
      "Step 313/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 313/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 313/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 313/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 313/467 | Average reward: 0.05078125 | Average sequence length: 120.30\n",
      "Step 314/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 314/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 314/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 314/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 314/467 | Average reward: 0.03515625 | Average sequence length: 127.13\n",
      "Step 315/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 315/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 315/467 | Example step 1 | Pass 0 | loss: -0.003091 | average reward: 0.0\n",
      "Step 315/467 | Example step 1 | Pass 1 | loss: 0.002235 | average reward: 0.125\n",
      "Step 315/467 | Average reward: 0.09375 | Average sequence length: 146.72\n",
      "Step 316/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 316/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 316/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 316/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 316/467 | Average reward: 0.0703125 | Average sequence length: 118.11\n",
      "Step 317/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 317/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 317/467 | Example step 1 | Pass 0 | loss: -0.000972 | average reward: 0.75\n",
      "Step 317/467 | Example step 1 | Pass 1 | loss: -0.005952 | average reward: 0.75\n",
      "Step 317/467 | Average reward: 0.14453125 | Average sequence length: 142.32\n",
      "Step 318/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 318/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 318/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 318/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 318/467 | Average reward: 0.046875 | Average sequence length: 147.36\n",
      "Step 319/467 | Example step 0 | Pass 0 | loss: 0.003119 | average reward: 0.125\n",
      "Step 319/467 | Example step 0 | Pass 1 | loss: -0.002882 | average reward: 0.0\n",
      "Step 319/467 | Example step 1 | Pass 0 | loss: 0.006345 | average reward: 0.625\n",
      "Step 319/467 | Example step 1 | Pass 1 | loss: -0.009030 | average reward: 0.375\n",
      "Step 319/467 | Average reward: 0.16015625 | Average sequence length: 116.63\n",
      "Step 320/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 320/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 320/467 | Example step 1 | Pass 0 | loss: 0.001209 | average reward: 0.125\n",
      "Step 320/467 | Example step 1 | Pass 1 | loss: -0.002036 | average reward: 0.0\n",
      "Step 320/467 | Average reward: 0.046875 | Average sequence length: 149.47\n",
      "Step 321/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 321/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 321/467 | Example step 1 | Pass 0 | loss: 0.000861 | average reward: 0.125\n",
      "Step 321/467 | Example step 1 | Pass 1 | loss: 0.004215 | average reward: 0.125\n",
      "Step 321/467 | Average reward: 0.03515625 | Average sequence length: 147.92\n",
      "Step 322/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 322/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 322/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 322/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 322/467 | Average reward: 0.0546875 | Average sequence length: 126.43\n",
      "Step 323/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 323/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 323/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 323/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 323/467 | Average reward: 0.05859375 | Average sequence length: 142.22\n",
      "Step 324/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 324/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 324/467 | Example step 1 | Pass 0 | loss: -0.004814 | average reward: 0.0\n",
      "Step 324/467 | Example step 1 | Pass 1 | loss: 0.005419 | average reward: 0.125\n",
      "Step 324/467 | Average reward: 0.109375 | Average sequence length: 130.21\n",
      "Step 325/467 | Example step 0 | Pass 0 | loss: 0.003156 | average reward: 0.125\n",
      "Step 325/467 | Example step 0 | Pass 1 | loss: -0.003357 | average reward: 0.0\n",
      "Step 325/467 | Example step 1 | Pass 0 | loss: -0.010161 | average reward: 0.125\n",
      "Step 325/467 | Example step 1 | Pass 1 | loss: 0.006667 | average reward: 0.75\n",
      "Step 325/467 | Average reward: 0.06640625 | Average sequence length: 135.54\n",
      "Step 326/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 326/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 326/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 326/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 326/467 | Average reward: 0.1328125 | Average sequence length: 141.07\n",
      "Step 327/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 327/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 327/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 327/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 327/467 | Average reward: 0.08203125 | Average sequence length: 148.72\n",
      "Step 328/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 328/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 328/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 328/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 328/467 | Average reward: 0.171875 | Average sequence length: 131.52\n",
      "Step 329/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 329/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 329/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 329/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 329/467 | Average reward: 0.08984375 | Average sequence length: 128.16\n",
      "Step 330/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 330/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 330/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 330/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 330/467 | Average reward: 0.09375 | Average sequence length: 135.80\n",
      "Step 331/467 | Example step 0 | Pass 0 | loss: 0.002522 | average reward: 0.125\n",
      "Step 331/467 | Example step 0 | Pass 1 | loss: -0.003502 | average reward: 0.0\n",
      "Step 331/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 331/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 331/467 | Average reward: 0.1328125 | Average sequence length: 141.73\n",
      "Step 332/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 332/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 332/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 332/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 332/467 | Average reward: 0.02734375 | Average sequence length: 135.54\n",
      "Step 333/467 | Example step 0 | Pass 0 | loss: -0.000674 | average reward: 0.875\n",
      "Step 333/467 | Example step 0 | Pass 1 | loss: -0.001686 | average reward: 0.75\n",
      "Step 333/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 333/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 333/467 | Average reward: 0.1328125 | Average sequence length: 128.57\n",
      "Step 334/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 334/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 334/467 | Example step 1 | Pass 0 | loss: 0.005254 | average reward: 0.125\n",
      "Step 334/467 | Example step 1 | Pass 1 | loss: -0.002967 | average reward: 0.0\n",
      "Step 334/467 | Average reward: 0.0625 | Average sequence length: 121.61\n",
      "Step 335/467 | Example step 0 | Pass 0 | loss: -0.006786 | average reward: 0.0\n",
      "Step 335/467 | Example step 0 | Pass 1 | loss: 0.003721 | average reward: 0.125\n",
      "Step 335/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 335/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 335/467 | Average reward: 0.04296875 | Average sequence length: 143.68\n",
      "Step 336/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 336/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 336/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 336/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 336/467 | Average reward: 0.109375 | Average sequence length: 127.95\n",
      "Step 337/467 | Example step 0 | Pass 0 | loss: -0.000474 | average reward: 0.875\n",
      "Step 337/467 | Example step 0 | Pass 1 | loss: -0.014854 | average reward: 0.625\n",
      "Step 337/467 | Example step 1 | Pass 0 | loss: 0.003413 | average reward: 0.125\n",
      "Step 337/467 | Example step 1 | Pass 1 | loss: -0.002779 | average reward: 0.0\n",
      "Step 337/467 | Average reward: 0.21484375 | Average sequence length: 126.98\n",
      "Step 338/467 | Example step 0 | Pass 0 | loss: 0.003692 | average reward: 0.125\n",
      "Step 338/467 | Example step 0 | Pass 1 | loss: -0.003252 | average reward: 0.0\n",
      "Step 338/467 | Example step 1 | Pass 0 | loss: 0.007117 | average reward: 0.125\n",
      "Step 338/467 | Example step 1 | Pass 1 | loss: -0.002372 | average reward: 0.0\n",
      "Step 338/467 | Average reward: 0.1015625 | Average sequence length: 134.54\n",
      "Step 339/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 339/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 339/467 | Example step 1 | Pass 0 | loss: -0.006050 | average reward: 0.75\n",
      "Step 339/467 | Example step 1 | Pass 1 | loss: -0.003096 | average reward: 0.75\n",
      "Step 339/467 | Average reward: 0.15234375 | Average sequence length: 123.44\n",
      "Step 340/467 | Example step 0 | Pass 0 | loss: -0.007229 | average reward: 0.375\n",
      "Step 340/467 | Example step 0 | Pass 1 | loss: 0.002917 | average reward: 0.5\n",
      "Step 340/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 340/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 340/467 | Average reward: 0.046875 | Average sequence length: 140.33\n",
      "Step 341/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 341/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 341/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 341/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 341/467 | Average reward: 0.0859375 | Average sequence length: 134.78\n",
      "Step 342/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 342/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 342/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 342/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 342/467 | Average reward: 0.07421875 | Average sequence length: 137.23\n",
      "Step 343/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 343/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 343/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 343/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 343/467 | Average reward: 0.06640625 | Average sequence length: 140.73\n",
      "Step 344/467 | Example step 0 | Pass 0 | loss: 0.007403 | average reward: 0.875\n",
      "Step 344/467 | Example step 0 | Pass 1 | loss: 0.000116 | average reward: 0.75\n",
      "Step 344/467 | Example step 1 | Pass 0 | loss: -0.002121 | average reward: 0.0\n",
      "Step 344/467 | Example step 1 | Pass 1 | loss: 0.002000 | average reward: 0.125\n",
      "Step 344/467 | Average reward: 0.20703125 | Average sequence length: 128.76\n",
      "Step 345/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 345/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 345/467 | Example step 1 | Pass 0 | loss: -0.007259 | average reward: 0.25\n",
      "Step 345/467 | Example step 1 | Pass 1 | loss: -0.007427 | average reward: 0.25\n",
      "Step 345/467 | Average reward: 0.07421875 | Average sequence length: 127.33\n",
      "Step 346/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 346/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 346/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 346/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 346/467 | Average reward: 0.125 | Average sequence length: 124.21\n",
      "Step 347/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 347/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 347/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 347/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 347/467 | Average reward: 0.0234375 | Average sequence length: 137.40\n",
      "Step 348/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 348/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 348/467 | Example step 1 | Pass 0 | loss: -0.008219 | average reward: 0.75\n",
      "Step 348/467 | Example step 1 | Pass 1 | loss: -0.000690 | average reward: 0.875\n",
      "Step 348/467 | Average reward: 0.23828125 | Average sequence length: 121.67\n",
      "Step 349/467 | Example step 0 | Pass 0 | loss: 0.002896 | average reward: 0.125\n",
      "Step 349/467 | Example step 0 | Pass 1 | loss: -0.002025 | average reward: 0.0\n",
      "Step 349/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 349/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 349/467 | Average reward: 0.0546875 | Average sequence length: 137.38\n",
      "Step 350/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 350/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 350/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 350/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 350/467 | Average reward: 0.1328125 | Average sequence length: 140.69\n",
      "Step 351/467 | Example step 0 | Pass 0 | loss: 0.005805 | average reward: 0.25\n",
      "Step 351/467 | Example step 0 | Pass 1 | loss: -0.005540 | average reward: 0.0\n",
      "Step 351/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 351/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 351/467 | Average reward: 0.046875 | Average sequence length: 124.07\n",
      "Step 352/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 352/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 352/467 | Example step 1 | Pass 0 | loss: -0.003352 | average reward: 0.0\n",
      "Step 352/467 | Example step 1 | Pass 1 | loss: 0.006112 | average reward: 0.125\n",
      "Step 352/467 | Average reward: 0.05078125 | Average sequence length: 133.98\n",
      "Step 353/467 | Example step 0 | Pass 0 | loss: -0.002389 | average reward: 0.125\n",
      "Step 353/467 | Example step 0 | Pass 1 | loss: -0.001773 | average reward: 0.125\n",
      "Step 353/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 353/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 353/467 | Average reward: 0.1015625 | Average sequence length: 137.30\n",
      "Step 354/467 | Example step 0 | Pass 0 | loss: 0.006988 | average reward: 0.75\n",
      "Step 354/467 | Example step 0 | Pass 1 | loss: -0.012642 | average reward: 0.5\n",
      "Step 354/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 354/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 354/467 | Average reward: 0.04296875 | Average sequence length: 126.42\n",
      "Step 355/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 355/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 355/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 355/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 355/467 | Average reward: 0.13671875 | Average sequence length: 124.30\n",
      "Step 356/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 356/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 356/467 | Example step 1 | Pass 0 | loss: 0.001073 | average reward: 0.25\n",
      "Step 356/467 | Example step 1 | Pass 1 | loss: -0.005083 | average reward: 0.125\n",
      "Step 356/467 | Average reward: 0.0546875 | Average sequence length: 133.98\n",
      "Step 357/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 357/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 357/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 357/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 357/467 | Average reward: 0.09375 | Average sequence length: 115.56\n",
      "Step 358/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 358/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 358/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 358/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 358/467 | Average reward: 0.13671875 | Average sequence length: 135.64\n",
      "Step 359/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 359/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 359/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 359/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 359/467 | Average reward: 0.08203125 | Average sequence length: 118.82\n",
      "Step 360 | Pass@1: 0.0975, Pass@2: 0.1475, Pass@3: 0.1800, Pass@4: 0.1975, Pass@5: 0.2100, Pass@6: 0.2300, Pass@7: 0.2350, Pass@8: 0.2550\n",
      "Step 360/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 360/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 360/467 | Example step 1 | Pass 0 | loss: -0.028071 | average reward: 0.5\n",
      "Step 360/467 | Example step 1 | Pass 1 | loss: -0.000579 | average reward: 0.875\n",
      "Step 360/467 | Average reward: 0.09375 | Average sequence length: 117.96\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000360.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000360.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "Step 361/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 361/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 361/467 | Example step 1 | Pass 0 | loss: 0.007990 | average reward: 0.25\n",
      "Step 361/467 | Example step 1 | Pass 1 | loss: 0.005509 | average reward: 0.25\n",
      "Step 361/467 | Average reward: 0.18359375 | Average sequence length: 135.48\n",
      "Step 362/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 362/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 362/467 | Example step 1 | Pass 0 | loss: -0.011921 | average reward: 0.375\n",
      "Step 362/467 | Example step 1 | Pass 1 | loss: -0.021932 | average reward: 0.25\n",
      "Step 362/467 | Average reward: 0.07421875 | Average sequence length: 124.35\n",
      "Step 363/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 363/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 363/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 363/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 363/467 | Average reward: 0.140625 | Average sequence length: 127.58\n",
      "Step 364/467 | Example step 0 | Pass 0 | loss: -0.003211 | average reward: 0.0\n",
      "Step 364/467 | Example step 0 | Pass 1 | loss: 0.002864 | average reward: 0.125\n",
      "Step 364/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 364/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 364/467 | Average reward: 0.08984375 | Average sequence length: 133.01\n",
      "Step 365/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 365/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 365/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 365/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 365/467 | Average reward: 0.078125 | Average sequence length: 145.23\n",
      "Step 366/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 366/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 366/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 366/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 366/467 | Average reward: 0.0546875 | Average sequence length: 135.59\n",
      "Step 367/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 367/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 367/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 367/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 367/467 | Average reward: 0.08984375 | Average sequence length: 145.75\n",
      "Step 368/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 368/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 368/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 368/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 368/467 | Average reward: 0.09765625 | Average sequence length: 131.98\n",
      "Step 369/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 369/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 369/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 369/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 369/467 | Average reward: 0.0859375 | Average sequence length: 130.72\n",
      "Step 370/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 370/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 370/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 370/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 370/467 | Average reward: 0.07421875 | Average sequence length: 140.92\n",
      "Step 371/467 | Example step 0 | Pass 0 | loss: 0.011073 | average reward: 0.125\n",
      "Step 371/467 | Example step 0 | Pass 1 | loss: -0.003504 | average reward: 0.0\n",
      "Step 371/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 371/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 371/467 | Average reward: 0.11328125 | Average sequence length: 131.01\n",
      "Step 372/467 | Example step 0 | Pass 0 | loss: -0.003719 | average reward: 0.75\n",
      "Step 372/467 | Example step 0 | Pass 1 | loss: -0.003584 | average reward: 0.75\n",
      "Step 372/467 | Example step 1 | Pass 0 | loss: -0.000233 | average reward: 0.625\n",
      "Step 372/467 | Example step 1 | Pass 1 | loss: 0.008110 | average reward: 0.75\n",
      "Step 372/467 | Average reward: 0.1328125 | Average sequence length: 130.99\n",
      "Step 373/467 | Example step 0 | Pass 0 | loss: -0.011297 | average reward: 0.25\n",
      "Step 373/467 | Example step 0 | Pass 1 | loss: 0.008479 | average reward: 0.875\n",
      "Step 373/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 373/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 373/467 | Average reward: 0.0625 | Average sequence length: 132.24\n",
      "Step 374/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 374/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 374/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 374/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 374/467 | Average reward: 0.1328125 | Average sequence length: 125.20\n",
      "Step 375/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 375/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 375/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 375/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 375/467 | Average reward: 0.08203125 | Average sequence length: 124.58\n",
      "Step 376/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 376/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 376/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 376/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 376/467 | Average reward: 0.18359375 | Average sequence length: 122.83\n",
      "Step 377/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 377/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 377/467 | Example step 1 | Pass 0 | loss: -0.002440 | average reward: 0.0\n",
      "Step 377/467 | Example step 1 | Pass 1 | loss: 0.005647 | average reward: 0.125\n",
      "Step 377/467 | Average reward: 0.1015625 | Average sequence length: 131.62\n",
      "Step 378/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 378/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 378/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 378/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 378/467 | Average reward: 0.17578125 | Average sequence length: 135.99\n",
      "Step 379/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 379/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 379/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 379/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 379/467 | Average reward: 0.0390625 | Average sequence length: 132.14\n",
      "Step 380/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 380/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 380/467 | Example step 1 | Pass 0 | loss: -0.007059 | average reward: 0.375\n",
      "Step 380/467 | Example step 1 | Pass 1 | loss: -0.001746 | average reward: 0.25\n",
      "Step 380/467 | Average reward: 0.125 | Average sequence length: 123.05\n",
      "Step 381/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 381/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 381/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 381/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 381/467 | Average reward: 0.06640625 | Average sequence length: 122.84\n",
      "Step 382/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 382/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 382/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 382/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 382/467 | Average reward: 0.06640625 | Average sequence length: 137.45\n",
      "Step 383/467 | Example step 0 | Pass 0 | loss: 0.004288 | average reward: 0.125\n",
      "Step 383/467 | Example step 0 | Pass 1 | loss: -0.003628 | average reward: 0.0\n",
      "Step 383/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 383/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 383/467 | Average reward: 0.07421875 | Average sequence length: 133.89\n",
      "Step 384/467 | Example step 0 | Pass 0 | loss: 0.009220 | average reward: 0.25\n",
      "Step 384/467 | Example step 0 | Pass 1 | loss: -0.011767 | average reward: 0.0\n",
      "Step 384/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 384/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 384/467 | Average reward: 0.16015625 | Average sequence length: 127.12\n",
      "Step 385/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 385/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 385/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 385/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 385/467 | Average reward: 0.125 | Average sequence length: 145.51\n",
      "Step 386/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 386/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 386/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 386/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 386/467 | Average reward: 0.0703125 | Average sequence length: 142.45\n",
      "Step 387/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 387/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 387/467 | Example step 1 | Pass 0 | loss: -0.002381 | average reward: 0.875\n",
      "Step 387/467 | Example step 1 | Pass 1 | loss: -0.000986 | average reward: 0.875\n",
      "Step 387/467 | Average reward: 0.19921875 | Average sequence length: 139.61\n",
      "Step 388/467 | Example step 0 | Pass 0 | loss: -0.004986 | average reward: 0.0\n",
      "Step 388/467 | Example step 0 | Pass 1 | loss: 0.000695 | average reward: 0.125\n",
      "Step 388/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 388/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 388/467 | Average reward: 0.1171875 | Average sequence length: 130.57\n",
      "Step 389/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 389/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 389/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 389/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 389/467 | Average reward: 0.13671875 | Average sequence length: 121.98\n",
      "Step 390/467 | Example step 0 | Pass 0 | loss: 0.003163 | average reward: 0.375\n",
      "Step 390/467 | Example step 0 | Pass 1 | loss: -0.000550 | average reward: 0.25\n",
      "Step 390/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 390/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 390/467 | Average reward: 0.14453125 | Average sequence length: 125.47\n",
      "Step 391/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 391/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 391/467 | Example step 1 | Pass 0 | loss: -0.018236 | average reward: 0.375\n",
      "Step 391/467 | Example step 1 | Pass 1 | loss: -0.000836 | average reward: 0.5\n",
      "Step 391/467 | Average reward: 0.08203125 | Average sequence length: 126.52\n",
      "Step 392/467 | Example step 0 | Pass 0 | loss: -0.000530 | average reward: 0.125\n",
      "Step 392/467 | Example step 0 | Pass 1 | loss: -0.000708 | average reward: 0.125\n",
      "Step 392/467 | Example step 1 | Pass 0 | loss: -0.003779 | average reward: 0.0\n",
      "Step 392/467 | Example step 1 | Pass 1 | loss: 0.005589 | average reward: 0.125\n",
      "Step 392/467 | Average reward: 0.08984375 | Average sequence length: 153.40\n",
      "Step 393/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 393/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 393/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 393/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 393/467 | Average reward: 0.08203125 | Average sequence length: 152.50\n",
      "Step 394/467 | Example step 0 | Pass 0 | loss: -0.019331 | average reward: 0.625\n",
      "Step 394/467 | Example step 0 | Pass 1 | loss: -0.000506 | average reward: 0.75\n",
      "Step 394/467 | Example step 1 | Pass 0 | loss: -0.002439 | average reward: 0.0\n",
      "Step 394/467 | Example step 1 | Pass 1 | loss: 0.002331 | average reward: 0.125\n",
      "Step 394/467 | Average reward: 0.09375 | Average sequence length: 136.88\n",
      "Step 395/467 | Example step 0 | Pass 0 | loss: -0.002795 | average reward: 0.0\n",
      "Step 395/467 | Example step 0 | Pass 1 | loss: 0.005532 | average reward: 0.125\n",
      "Step 395/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 395/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 395/467 | Average reward: 0.01171875 | Average sequence length: 157.68\n",
      "Step 396/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 396/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 396/467 | Example step 1 | Pass 0 | loss: 0.001439 | average reward: 0.25\n",
      "Step 396/467 | Example step 1 | Pass 1 | loss: -0.005001 | average reward: 0.125\n",
      "Step 396/467 | Average reward: 0.0703125 | Average sequence length: 119.80\n",
      "Step 397/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 397/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 397/467 | Example step 1 | Pass 0 | loss: 0.004624 | average reward: 0.75\n",
      "Step 397/467 | Example step 1 | Pass 1 | loss: -0.003411 | average reward: 0.5\n",
      "Step 397/467 | Average reward: 0.109375 | Average sequence length: 123.11\n",
      "Step 398/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 398/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 398/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 398/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 398/467 | Average reward: 0.1171875 | Average sequence length: 129.00\n",
      "Step 399/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 399/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 399/467 | Example step 1 | Pass 0 | loss: -0.009720 | average reward: 0.0\n",
      "Step 399/467 | Example step 1 | Pass 1 | loss: 0.005807 | average reward: 0.375\n",
      "Step 399/467 | Average reward: 0.09765625 | Average sequence length: 143.27\n",
      "Step 400/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 400/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 400/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 400/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 400/467 | Average reward: 0.00390625 | Average sequence length: 130.97\n",
      "Step 401/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 401/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 401/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 401/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 401/467 | Average reward: 0.09765625 | Average sequence length: 118.79\n",
      "Step 402/467 | Example step 0 | Pass 0 | loss: -0.004876 | average reward: 0.125\n",
      "Step 402/467 | Example step 0 | Pass 1 | loss: 0.005264 | average reward: 0.25\n",
      "Step 402/467 | Example step 1 | Pass 0 | loss: 0.002373 | average reward: 1.0\n",
      "Step 402/467 | Example step 1 | Pass 1 | loss: -0.006679 | average reward: 0.875\n",
      "Step 402/467 | Average reward: 0.15234375 | Average sequence length: 124.37\n",
      "Step 403/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 403/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 403/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 403/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 403/467 | Average reward: 0.1796875 | Average sequence length: 141.97\n",
      "Step 404/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 404/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 404/467 | Example step 1 | Pass 0 | loss: -0.005776 | average reward: 0.375\n",
      "Step 404/467 | Example step 1 | Pass 1 | loss: 0.003564 | average reward: 0.625\n",
      "Step 404/467 | Average reward: 0.15625 | Average sequence length: 138.71\n",
      "Step 405/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 405/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 405/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 405/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 405/467 | Average reward: 0.09765625 | Average sequence length: 127.93\n",
      "Step 406/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 406/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 406/467 | Example step 1 | Pass 0 | loss: -0.005487 | average reward: 0.5\n",
      "Step 406/467 | Example step 1 | Pass 1 | loss: 0.004241 | average reward: 0.75\n",
      "Step 406/467 | Average reward: 0.13671875 | Average sequence length: 145.19\n",
      "Step 407/467 | Example step 0 | Pass 0 | loss: -0.007786 | average reward: 0.875\n",
      "Step 407/467 | Example step 0 | Pass 1 | loss: -0.016878 | average reward: 0.75\n",
      "Step 407/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 407/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 407/467 | Average reward: 0.09375 | Average sequence length: 135.25\n",
      "Step 408/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 408/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 408/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 408/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 408/467 | Average reward: 0.015625 | Average sequence length: 122.72\n",
      "Step 409/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 409/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 409/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 409/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 409/467 | Average reward: 0.109375 | Average sequence length: 131.58\n",
      "Step 410/467 | Example step 0 | Pass 0 | loss: -0.009064 | average reward: 0.5\n",
      "Step 410/467 | Example step 0 | Pass 1 | loss: -0.001500 | average reward: 0.5\n",
      "Step 410/467 | Example step 1 | Pass 0 | loss: 0.009009 | average reward: 0.25\n",
      "Step 410/467 | Example step 1 | Pass 1 | loss: -0.004726 | average reward: 0.0\n",
      "Step 410/467 | Average reward: 0.06640625 | Average sequence length: 142.13\n",
      "Step 411/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 411/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 411/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 411/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 411/467 | Average reward: 0.12890625 | Average sequence length: 130.16\n",
      "Step 412/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 412/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 412/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 412/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 412/467 | Average reward: 0.12890625 | Average sequence length: 127.26\n",
      "Step 413/467 | Example step 0 | Pass 0 | loss: -0.001585 | average reward: 0.125\n",
      "Step 413/467 | Example step 0 | Pass 1 | loss: -0.000912 | average reward: 0.125\n",
      "Step 413/467 | Example step 1 | Pass 0 | loss: -0.005526 | average reward: 0.375\n",
      "Step 413/467 | Example step 1 | Pass 1 | loss: -0.004808 | average reward: 0.25\n",
      "Step 413/467 | Average reward: 0.14453125 | Average sequence length: 138.75\n",
      "Step 414/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 414/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 414/467 | Example step 1 | Pass 0 | loss: -0.016519 | average reward: 0.75\n",
      "Step 414/467 | Example step 1 | Pass 1 | loss: -0.011601 | average reward: 0.875\n",
      "Step 414/467 | Average reward: 0.11328125 | Average sequence length: 122.99\n",
      "Step 415/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 415/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 415/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 415/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 415/467 | Average reward: 0.04296875 | Average sequence length: 118.50\n",
      "Step 416/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 416/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 416/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 416/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 416/467 | Average reward: 0.17578125 | Average sequence length: 141.07\n",
      "Step 417/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 417/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 417/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 417/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 417/467 | Average reward: 0.03125 | Average sequence length: 136.08\n",
      "Step 418/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 418/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 418/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 418/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 418/467 | Average reward: 0.08203125 | Average sequence length: 135.36\n",
      "Step 419/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 419/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 419/467 | Example step 1 | Pass 0 | loss: 0.003593 | average reward: 0.125\n",
      "Step 419/467 | Example step 1 | Pass 1 | loss: -0.001838 | average reward: 0.0\n",
      "Step 419/467 | Average reward: 0.015625 | Average sequence length: 143.50\n",
      "Step 420 | Pass@1: 0.0850, Pass@2: 0.1400, Pass@3: 0.1675, Pass@4: 0.1850, Pass@5: 0.2075, Pass@6: 0.2150, Pass@7: 0.2250, Pass@8: 0.2375\n",
      "Step 420/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 420/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 420/467 | Example step 1 | Pass 0 | loss: 0.000432 | average reward: 0.125\n",
      "Step 420/467 | Example step 1 | Pass 1 | loss: 0.001249 | average reward: 0.125\n",
      "Step 420/467 | Average reward: 0.02734375 | Average sequence length: 130.66\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000420.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000420.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "Step 421/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 421/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 421/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 421/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 421/467 | Average reward: 0.15234375 | Average sequence length: 129.95\n",
      "Step 422/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 422/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 422/467 | Example step 1 | Pass 0 | loss: 0.011626 | average reward: 0.5\n",
      "Step 422/467 | Example step 1 | Pass 1 | loss: -0.008460 | average reward: 0.125\n",
      "Step 422/467 | Average reward: 0.078125 | Average sequence length: 132.33\n",
      "Step 423/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 423/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 423/467 | Example step 1 | Pass 0 | loss: -0.005007 | average reward: 0.625\n",
      "Step 423/467 | Example step 1 | Pass 1 | loss: -0.006269 | average reward: 0.5\n",
      "Step 423/467 | Average reward: 0.13671875 | Average sequence length: 135.96\n",
      "Step 424/467 | Example step 0 | Pass 0 | loss: 0.002807 | average reward: 0.125\n",
      "Step 424/467 | Example step 0 | Pass 1 | loss: -0.001854 | average reward: 0.0\n",
      "Step 424/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 424/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 424/467 | Average reward: 0.03125 | Average sequence length: 137.14\n",
      "Step 425/467 | Example step 0 | Pass 0 | loss: 0.006651 | average reward: 1.0\n",
      "Step 425/467 | Example step 0 | Pass 1 | loss: -0.013152 | average reward: 0.625\n",
      "Step 425/467 | Example step 1 | Pass 0 | loss: 0.003598 | average reward: 0.875\n",
      "Step 425/467 | Example step 1 | Pass 1 | loss: -0.008419 | average reward: 0.5\n",
      "Step 425/467 | Average reward: 0.2421875 | Average sequence length: 135.82\n",
      "Step 426/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 426/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 426/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 426/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 426/467 | Average reward: 0.1171875 | Average sequence length: 125.48\n",
      "Step 427/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 427/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 427/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 427/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 427/467 | Average reward: 0.046875 | Average sequence length: 141.58\n",
      "Step 428/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 428/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 428/467 | Example step 1 | Pass 0 | loss: -0.008902 | average reward: 0.25\n",
      "Step 428/467 | Example step 1 | Pass 1 | loss: -0.004824 | average reward: 0.25\n",
      "Step 428/467 | Average reward: 0.1015625 | Average sequence length: 122.52\n",
      "Step 429/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 429/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 429/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 429/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 429/467 | Average reward: 0.140625 | Average sequence length: 115.29\n",
      "Step 430/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 430/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 430/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 430/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 430/467 | Average reward: 0.07421875 | Average sequence length: 131.69\n",
      "Step 431/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 431/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 431/467 | Example step 1 | Pass 0 | loss: 0.009191 | average reward: 0.375\n",
      "Step 431/467 | Example step 1 | Pass 1 | loss: -0.005805 | average reward: 0.125\n",
      "Step 431/467 | Average reward: 0.11328125 | Average sequence length: 124.38\n",
      "Step 432/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 432/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 432/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 432/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 432/467 | Average reward: 0.125 | Average sequence length: 135.59\n",
      "Step 433/467 | Example step 0 | Pass 0 | loss: -0.002368 | average reward: 0.0\n",
      "Step 433/467 | Example step 0 | Pass 1 | loss: -0.002350 | average reward: 0.125\n",
      "Step 433/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 433/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 433/467 | Average reward: 0.07421875 | Average sequence length: 137.06\n",
      "Step 434/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 434/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 434/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 434/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 434/467 | Average reward: 0.04296875 | Average sequence length: 133.81\n",
      "Step 435/467 | Example step 0 | Pass 0 | loss: 0.005733 | average reward: 0.125\n",
      "Step 435/467 | Example step 0 | Pass 1 | loss: -0.003899 | average reward: 0.0\n",
      "Step 435/467 | Example step 1 | Pass 0 | loss: 0.007628 | average reward: 0.5\n",
      "Step 435/467 | Example step 1 | Pass 1 | loss: -0.005156 | average reward: 0.125\n",
      "Step 435/467 | Average reward: 0.11328125 | Average sequence length: 151.55\n",
      "Step 436/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 436/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 436/467 | Example step 1 | Pass 0 | loss: -0.004239 | average reward: 0.125\n",
      "Step 436/467 | Example step 1 | Pass 1 | loss: -0.003620 | average reward: 0.25\n",
      "Step 436/467 | Average reward: 0.1328125 | Average sequence length: 145.58\n",
      "Step 437/467 | Example step 0 | Pass 0 | loss: 0.013965 | average reward: 0.375\n",
      "Step 437/467 | Example step 0 | Pass 1 | loss: -0.012408 | average reward: 0.0\n",
      "Step 437/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 437/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 437/467 | Average reward: 0.0390625 | Average sequence length: 140.64\n",
      "Step 438/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 438/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 438/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 438/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 438/467 | Average reward: 0.02734375 | Average sequence length: 122.55\n",
      "Step 439/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 439/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 439/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 439/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 439/467 | Average reward: 0.02734375 | Average sequence length: 136.98\n",
      "Step 440/467 | Example step 0 | Pass 0 | loss: -0.003192 | average reward: 0.125\n",
      "Step 440/467 | Example step 0 | Pass 1 | loss: -0.000553 | average reward: 0.125\n",
      "Step 440/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 440/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 440/467 | Average reward: 0.1875 | Average sequence length: 131.52\n",
      "Step 441/467 | Example step 0 | Pass 0 | loss: -0.002010 | average reward: 0.0\n",
      "Step 441/467 | Example step 0 | Pass 1 | loss: 0.005761 | average reward: 0.125\n",
      "Step 441/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 441/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 441/467 | Average reward: 0.0703125 | Average sequence length: 136.79\n",
      "Step 442/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 442/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 442/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 442/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 442/467 | Average reward: 0.0546875 | Average sequence length: 125.34\n",
      "Step 443/467 | Example step 0 | Pass 0 | loss: 0.001131 | average reward: 0.125\n",
      "Step 443/467 | Example step 0 | Pass 1 | loss: -0.002899 | average reward: 0.0\n",
      "Step 443/467 | Example step 1 | Pass 0 | loss: 0.015013 | average reward: 0.5\n",
      "Step 443/467 | Example step 1 | Pass 1 | loss: -0.006818 | average reward: 0.125\n",
      "Step 443/467 | Average reward: 0.0546875 | Average sequence length: 116.13\n",
      "Step 444/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 444/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 444/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 444/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 444/467 | Average reward: 0.06640625 | Average sequence length: 115.63\n",
      "Step 445/467 | Example step 0 | Pass 0 | loss: -0.007593 | average reward: 0.75\n",
      "Step 445/467 | Example step 0 | Pass 1 | loss: -0.000698 | average reward: 0.875\n",
      "Step 445/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 445/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 445/467 | Average reward: 0.19921875 | Average sequence length: 134.61\n",
      "Step 446/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 446/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 446/467 | Example step 1 | Pass 0 | loss: 0.001814 | average reward: 0.25\n",
      "Step 446/467 | Example step 1 | Pass 1 | loss: -0.004060 | average reward: 0.0\n",
      "Step 446/467 | Average reward: 0.0703125 | Average sequence length: 132.68\n",
      "Step 447/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 447/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 447/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 447/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 447/467 | Average reward: 0.1875 | Average sequence length: 141.07\n",
      "Step 448/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 448/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 448/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 448/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 448/467 | Average reward: 0.125 | Average sequence length: 128.39\n",
      "Step 449/467 | Example step 0 | Pass 0 | loss: -0.004741 | average reward: 0.0\n",
      "Step 449/467 | Example step 0 | Pass 1 | loss: 0.011816 | average reward: 0.25\n",
      "Step 449/467 | Example step 1 | Pass 0 | loss: -0.002655 | average reward: 0.125\n",
      "Step 449/467 | Example step 1 | Pass 1 | loss: 0.008485 | average reward: 0.625\n",
      "Step 449/467 | Average reward: 0.1171875 | Average sequence length: 131.55\n",
      "Step 450/467 | Example step 0 | Pass 0 | loss: 0.004725 | average reward: 0.125\n",
      "Step 450/467 | Example step 0 | Pass 1 | loss: -0.001893 | average reward: 0.0\n",
      "Step 450/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 450/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 450/467 | Average reward: 0.1015625 | Average sequence length: 133.89\n",
      "Step 451/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 451/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 451/467 | Example step 1 | Pass 0 | loss: -0.009131 | average reward: 0.0\n",
      "Step 451/467 | Example step 1 | Pass 1 | loss: 0.007716 | average reward: 0.25\n",
      "Step 451/467 | Average reward: 0.17578125 | Average sequence length: 124.82\n",
      "Step 452/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 452/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 452/467 | Example step 1 | Pass 0 | loss: 0.002093 | average reward: 1.0\n",
      "Step 452/467 | Example step 1 | Pass 1 | loss: -0.010312 | average reward: 0.875\n",
      "Step 452/467 | Average reward: 0.10546875 | Average sequence length: 143.97\n",
      "Step 453/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 453/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 453/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 453/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 453/467 | Average reward: 0.16796875 | Average sequence length: 132.37\n",
      "Step 454/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 454/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 454/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 454/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 454/467 | Average reward: 0.04296875 | Average sequence length: 130.63\n",
      "Step 455/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 455/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 455/467 | Example step 1 | Pass 0 | loss: -0.004019 | average reward: 0.5\n",
      "Step 455/467 | Example step 1 | Pass 1 | loss: -0.001689 | average reward: 0.625\n",
      "Step 455/467 | Average reward: 0.10546875 | Average sequence length: 130.71\n",
      "Step 456/467 | Example step 0 | Pass 0 | loss: 0.004132 | average reward: 0.125\n",
      "Step 456/467 | Example step 0 | Pass 1 | loss: -0.003189 | average reward: 0.0\n",
      "Step 456/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 456/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 456/467 | Average reward: 0.07421875 | Average sequence length: 134.61\n",
      "Step 457/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 457/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 457/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 457/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 457/467 | Average reward: 0.171875 | Average sequence length: 116.84\n",
      "Step 458/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 458/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 458/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 458/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 458/467 | Average reward: 0.0234375 | Average sequence length: 125.40\n",
      "Step 459/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 459/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 459/467 | Example step 1 | Pass 0 | loss: 0.001969 | average reward: 0.25\n",
      "Step 459/467 | Example step 1 | Pass 1 | loss: -0.009171 | average reward: 0.0\n",
      "Step 459/467 | Average reward: 0.11328125 | Average sequence length: 132.50\n",
      "Step 460/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 460/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 460/467 | Example step 1 | Pass 0 | loss: 0.001563 | average reward: 0.75\n",
      "Step 460/467 | Example step 1 | Pass 1 | loss: -0.008200 | average reward: 0.75\n",
      "Step 460/467 | Average reward: 0.1171875 | Average sequence length: 130.55\n",
      "Step 461/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 461/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 461/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 461/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 461/467 | Average reward: 0.0859375 | Average sequence length: 138.80\n",
      "Step 462/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 462/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 462/467 | Example step 1 | Pass 0 | loss: 0.000263 | average reward: 0.125\n",
      "Step 462/467 | Example step 1 | Pass 1 | loss: 0.000532 | average reward: 0.125\n",
      "Step 462/467 | Average reward: 0.1328125 | Average sequence length: 128.75\n",
      "Step 463/467 | Example step 0 | Pass 0 | loss: 0.010559 | average reward: 0.625\n",
      "Step 463/467 | Example step 0 | Pass 1 | loss: -0.019523 | average reward: 0.25\n",
      "Step 463/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 463/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 463/467 | Average reward: 0.20703125 | Average sequence length: 131.27\n",
      "Step 464/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 464/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 464/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 464/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 464/467 | Average reward: 0.078125 | Average sequence length: 138.75\n",
      "Step 465/467 | Example step 0 | Pass 0 | loss: -0.004292 | average reward: 0.75\n",
      "Step 465/467 | Example step 0 | Pass 1 | loss: -0.006105 | average reward: 0.75\n",
      "Step 465/467 | Example step 1 | Pass 0 | loss: -0.007306 | average reward: 0.5\n",
      "Step 465/467 | Example step 1 | Pass 1 | loss: 0.003265 | average reward: 0.75\n",
      "Step 465/467 | Average reward: 0.16796875 | Average sequence length: 132.18\n",
      "Step 466/467 | Example step 0 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 466/467 | Example step 0 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 466/467 | Example step 1 | Pass 0 | loss: -0.000000 | average reward: 0.0\n",
      "Step 466/467 | Example step 1 | Pass 1 | loss: -0.000000 | average reward: 0.0\n",
      "Step 466/467 | Average reward: 0.1328125 | Average sequence length: 131.91\n",
      "saved model to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/model_000466.pt\n",
      "saved metadata to /home/ubuntu/mynanochat/chatrl_checkpoints/d20/meta_000466.json\n",
      "Saved model checkpoint to /home/ubuntu/mynanochat/chatrl_checkpoints/d20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading history steps 940-941, summary, console lines 2372-2375 (0...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    lrm ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@1 ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@2 ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@3 ‚ñÅ‚ñá‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@4 ‚ñÅ‚ñÖ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@5 ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@6 ‚ñÅ‚ñÜ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@7 ‚ñÅ‚ñÖ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@8 ‚ñÅ‚ñÖ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: reward ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     +2 ...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    lrm 0.00214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@1 0.085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@2 0.14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@3 0.1675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@4 0.185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@5 0.2075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@6 0.215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@7 0.225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: pass@8 0.2375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: reward 0.13281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     +2 ...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mchallenge-36-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl/runs/mcfuvgi2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ericsilberstein-self/my-nanochat-rl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251126_120459-mcfuvgi2/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!torchrun --standalone --nproc_per_node=8 -m scripts.my_chat_rl -- \\\n",
    "--source=sft --model_tag=d20 --run=challenge-36-4"
   ]
  },
  {
   "attachments": {
    "58c2dbf0-7cef-4f8e-bc1b-1a11435ffdfb.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a7344e61-e6f7-4443-a38c-f404903ad14b",
   "metadata": {},
   "source": [
    "### Do chat eval on RL model\n",
    "\n",
    "My expectation (or at least hope) is to see accuracy on GSM8K go up from the centered accuracy of .05 (see `challenge-34-understand-reporting/run-evals-on-d20.ipynb`). Will the others stay around the same? Go up? Decline?\n",
    "\n",
    "Looking at run, going to do this eval on step 240 checkpoint instead of the final one because of this which I'll look into more later:\n",
    "\n",
    "![image.png](attachment:58c2dbf0-7cef-4f8e-bc1b-1a11435ffdfb.png)\n",
    "\n",
    "I'm not sure what the steps on the x-axis in the wandb graph mean, but I can see the one I'm interested in is the 5th point and we're evaluating every 60 steps: 0, 60, 120, 180, 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d7f065d-00d5-4629-b127-a83533339e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1126 12:51:04.240000 30132 torch/distributed/run.py:803] \n",
      "W1126 12:51:04.240000 30132 torch/distributed/run.py:803] *****************************************\n",
      "W1126 12:51:04.240000 30132 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1126 12:51:04.240000 30132 torch/distributed/run.py:803] *****************************************\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Autodetected device type: cuda\n",
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "loading the model from /home/ubuntu/mynanochat/chatrl_checkpoints/d20 with step 240\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n",
      "README.md: 9.00kB [00:00, 30.1MB/s]\n",
      "ARC-Easy/train-00000-of-00001.parquet: 100%|‚ñà‚ñà| 331k/331k [00:00<00:00, 943kB/s]\n",
      "ARC-Easy/test-00000-of-00001.parquet: 100%|‚ñà‚ñà| 346k/346k [00:00<00:00, 2.17MB/s]\n",
      "ARC-Easy/validation-00000-of-00001.parqu(‚Ä¶): 100%|‚ñà| 86.1k/86.1k [00:00<00:00, 4\n",
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà| 2251/2251 [00:00<00:00, 397581.94 examples/s]\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2376/2376 [00:00<00:00, 612329.73 examples/s]\n",
      "Generating validation split: 100%|‚ñà| 570/570 [00:00<00:00, 288842.97 examples/s]\n",
      "final: 1072/2376 (45.12%)\n",
      "ARC-Easy accuracy: 45.12%\n",
      "ARC-Challenge/train-00000-of-00001.parqu(‚Ä¶): 100%|‚ñà| 190k/190k [00:00<00:00, 699\n",
      "ARC-Challenge/test-00000-of-00001.parque(‚Ä¶): 100%|‚ñà| 204k/204k [00:00<00:00, 1.2\n",
      "ARC-Challenge/validation-00000-of-00001.(‚Ä¶): 100%|‚ñà| 55.7k/55.7k [00:00<00:00, 4\n",
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà| 1119/1119 [00:00<00:00, 238826.90 examples/s]\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 1172/1172 [00:00<00:00, 373450.15 examples/s]\n",
      "Generating validation split: 100%|‚ñà| 299/299 [00:00<00:00, 162447.78 examples/s]\n",
      "final: 366/1172 (31.23%)\n",
      "ARC-Challenge accuracy: 31.23%\n",
      "README.md: 53.2kB [00:00, 139MB/s]\n",
      "dataset_infos.json: 138kB [00:00, 277MB/s]\n",
      "all/test-00000-of-00001.parquet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 3.50M/3.50M [00:00<00:00, 7.93MB/s]\n",
      "all/validation-00000-of-00001.parquet: 100%|‚ñà| 408k/408k [00:00<00:00, 2.04MB/s]\n",
      "all/dev-00000-of-00001.parquet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76.5k/76.5k [00:00<00:00, 665kB/s]\n",
      "all/auxiliary_train-00000-of-00001.parqu(‚Ä¶): 100%|‚ñà| 47.5M/47.5M [00:00<00:00, 9\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà| 14042/14042 [00:00<00:00, 626291.12 examples/s]\n",
      "Generating validation split: 100%|‚ñà| 1531/1531 [00:00<00:00, 393400.69 examples/\n",
      "Generating dev split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 285/285 [00:00<00:00, 161931.27 examples/s]\n",
      "Generating auxiliary_train split: 100%|‚ñà| 99842/99842 [00:00<00:00, 442277.40 ex\n",
      "final: 4502/14042 (32.06%)\n",
      "MMLU accuracy: 32.06%\n",
      "\u001b[KRank 0 | 16/165 (9.70%)]]\n",
      "\u001b[KRank 3 | 19/165 (11.52%)]\n",
      "\u001b[KRank 4 | 16/165 (9.70%)]\n",
      "\u001b[KRank 1 | 18/165 (10.91%)]\n",
      "\u001b[KRank 6 | 13/165 (7.88%)]]\n",
      "\u001b[KRank 7 | 10/164 (6.10%)]]\n",
      "\u001b[KRank 5 | 7/165 (4.24%)])]\n",
      "\u001b[KRank 2 | 17/165 (10.30%)]\n",
      "==================================================\n",
      "final: 116/1319 (8.79%)\n",
      "GSM8K accuracy: 8.79%\n",
      "README.md: 6.52kB [00:00, 24.6MB/s]\n",
      "openai_humaneval/test-00000-of-00001.par(‚Ä¶): 100%|‚ñà| 83.9k/83.9k [00:00<00:00, 2\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164/164 [00:00<00:00, 36798.05 examples/s]\n",
      "\u001b[KRank 6 | 0/20 (0.00%)]]\n",
      "\u001b[KRank 3 | 0/21 (0.00%)]\n",
      "\u001b[KRank 7 | 2/20 (10.00%)]\n",
      "\u001b[KRank 0 | 2/21 (9.52%)]\n",
      "\u001b[KRank 1 | 0/21 (0.00%)]\n",
      "\u001b[KRank 5 | 0/20 (0.00%)]\n",
      "\u001b[KRank 4 | 1/20 (5.00%)]\n",
      "\u001b[KRank 2 | 0/21 (0.00%)]\n",
      "==================================================\n",
      "final: 5/164 (3.05%)\n",
      "HumanEval accuracy: 3.05%\n",
      "\u001b[KRank 0 | 29/32 (90.62%)]]\n",
      "\u001b[KRank 3 | 27/32 (84.38%)]]\n",
      "\u001b[KRank 4 | 32/32 (100.00%)]\n",
      "\u001b[KRank 6 | 28/32 (87.50%)]\n",
      "\u001b[KRank 1 | 30/32 (93.75%)]\n",
      "\u001b[KRank 7 | 28/32 (87.50%)]\n",
      "\u001b[KRank 2 | 29/32 (90.62%)]\n",
      "\u001b[KRank 5 | 29/32 (90.62%)]\n",
      "==================================================\n",
      "final: 232/256 (90.62%)\n",
      "SpellingBee accuracy: 90.62%\n"
     ]
    }
   ],
   "source": [
    "!torchrun --standalone --nproc_per_node=8 -m scripts.my_chat_eval -- \\\n",
    "--source=rl --model-tag=d20 --step=240"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5dc0f-060e-46d6-a01b-172f550441e7",
   "metadata": {},
   "source": [
    "### Rebuild final report\n",
    "\n",
    "Total time will be completely wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c601b56-2b97-4acf-9111-fe8b79f19c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report to /home/ubuntu/mynanochat/report/report.md\n",
      "Warning: /home/ubuntu/mynanochat/report/tokenizer-training.md does not exist, skipping\n",
      "Warning: /home/ubuntu/mynanochat/report/tokenizer-evaluation.md does not exist, skipping\n",
      "Warning: /home/ubuntu/mynanochat/report/base-model-training.md does not exist, skipping\n",
      "Warning: /home/ubuntu/mynanochat/report/midtraining.md does not exist, skipping\n",
      "Warning: /home/ubuntu/mynanochat/report/chat-sft.md does not exist, skipping\n",
      "Copying report.md to current directory for convenience\n"
     ]
    }
   ],
   "source": [
    "!python -m my_nanochat.my_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f504fe90-1bfc-4f3b-a46e-66f550be6673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# nanochat training report\n",
       "\n",
       "Generated: 2025-11-25 01:35:30\n",
       "\n",
       "## Environment\n",
       "\n",
       "### Git Information\n",
       "- Branch: master\n",
       "- Commit: 2cf49d1 (dirty)\n",
       "- Message: challenge 34: understand and add reporting - preparing to run evaluations on gpu\n",
       "\n",
       "### Hardware\n",
       "- Platform: Linux\n",
       "- CPUs: 104 cores (208 logical)\n",
       "- Memory: 1771.7 GB\n",
       "- GPUs: 8x NVIDIA H100 80GB HBM3\n",
       "- GPU Memory: 633.5 GB total\n",
       "- CUDA Version: 12.8\n",
       "\n",
       "### Software\n",
       "- Python: 3.10.12\n",
       "- PyTorch: 2.9.0+cu128\n",
       "\n",
       "Run started: 2025-11-25 01:35:33\n",
       "\n",
       "--\n",
       "\n",
       "## Base model loss\n",
       "timestamp: 2025-11-25 01:36:04\n",
       "\n",
       "- train bpb: 0.8164\n",
       "- val bpb: 0.8136\n",
       "- sample 0: <|bos|>The capital of France is Paris. It is the largest city in France and the second largest city in Europe\n",
       "- sample 1: <|bos|>The chemical symbol of gold is Au. It is a soft, malleable, ductile, and ductilely reactive metal\n",
       "- sample 2: <|bos|>If yesterday was Friday, then tomorrow will be Monday. If tomorrow is Monday, then tomorrow will be Tuesday. If tomorrow is\n",
       "- sample 3: <|bos|>The opposite of hot is cold. The opposite of cold is hot. The opposite of hot is cold.\n",
       "- sample 4: <|bos|>The planets of the solar system are: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune,\n",
       "- sample 5: <|bos|>My favorite color is red. It is the color of the blood of the martyrs. It is the\n",
       "- sample 6: <|bos|>If 5*x + 3 = 13, then x is a factor of 5. If 5*x + 3 = \n",
       "\n",
       "\n",
       "## Base model evaluation\n",
       "timestamp: 2025-11-25 01:39:38\n",
       "\n",
       "- Model: base_model (step 21400)\n",
       "- CORE metric: 0.2012\n",
       "- hellaswag_zeroshot: 0.2567\n",
       "- jeopardy: 0.1186\n",
       "- bigbench_qa_wikidata: 0.5366\n",
       "- arc_easy: 0.5292\n",
       "- arc_challenge: 0.1354\n",
       "- copa: 0.3800\n",
       "- commonsense_qa: 0.0377\n",
       "- piqa: 0.3591\n",
       "- openbook_qa: 0.1467\n",
       "- lambada_openai: 0.3745\n",
       "- hellaswag: 0.2628\n",
       "- winograd: 0.2821\n",
       "- winogrande: 0.0560\n",
       "- bigbench_dyck_languages: 0.1020\n",
       "- agi_eval_lsat_ar: 0.0272\n",
       "- bigbench_cs_algorithms: 0.3583\n",
       "- bigbench_operators: 0.1667\n",
       "- bigbench_repeat_copy_logic: 0.0000\n",
       "- squad: 0.2345\n",
       "- coqa: 0.1813\n",
       "- boolq: -0.2973\n",
       "- bigbench_language_identification: 0.1782\n",
       "\n",
       "\n",
       "## Chat evaluation mid\n",
       "timestamp: 2025-11-25 01:48:21\n",
       "\n",
       "- source: mid\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 8\n",
       "- model_tag: d20\n",
       "- step: None\n",
       "- max_problems: None\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.4318\n",
       "- ARC-Challenge: 0.3319\n",
       "- MMLU: 0.3307\n",
       "- GSM8K: 0.0341\n",
       "- HumanEval: 0.0671\n",
       "- SpellingBee: 0.9805\n",
       "- ChatCORE metric: 0.2568\n",
       "\n",
       "\n",
       "## Chat evaluation sft\n",
       "timestamp: 2025-11-25 01:55:32\n",
       "\n",
       "- source: sft\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 8\n",
       "- model_tag: d20\n",
       "- step: None\n",
       "- max_problems: None\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.4436\n",
       "- ARC-Challenge: 0.3183\n",
       "- MMLU: 0.3226\n",
       "- GSM8K: 0.0500\n",
       "- HumanEval: 0.0610\n",
       "- SpellingBee: 0.9727\n",
       "- ChatCORE metric: 0.2549\n",
       "\n",
       "\n",
       "## Chat RL\n",
       "timestamp: 2025-11-26 12:48:36\n",
       "\n",
       "- run: challenge-36-4\n",
       "- source: sft\n",
       "- dtype: bfloat16\n",
       "- device_type: \n",
       "- num_steps: -1\n",
       "- device_batch_size: 8\n",
       "- examples_per_step: 16\n",
       "- num_samples: 16\n",
       "- max_new_tokens: 256\n",
       "- temperature: 1.0000\n",
       "- top_k: 50\n",
       "- unembedding_lr: 0.0040\n",
       "- embedding_lr: 0.2000\n",
       "- matrix_lr: 0.0200\n",
       "- weight_decay: 0.0000\n",
       "- init_lr_frac: 0.0500\n",
       "- num_epochs: 1\n",
       "- save_every: 60\n",
       "- eval_every: 60\n",
       "- eval_examples: 400\n",
       "\n",
       "\n",
       "## Chat evaluation rl\n",
       "timestamp: 2025-11-26 12:54:38\n",
       "\n",
       "- source: rl\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 8\n",
       "- model_tag: d20\n",
       "- step: 240\n",
       "- max_problems: None\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.4512\n",
       "- ARC-Challenge: 0.3123\n",
       "- MMLU: 0.3206\n",
       "- GSM8K: 0.0879\n",
       "- HumanEval: 0.0305\n",
       "- SpellingBee: 0.9062\n",
       "- ChatCORE metric: 0.2450\n",
       "\n",
       "\n",
       "## Summary\n",
       "\n",
       "| Metric          | BASE     | MID      | SFT      | RL       |\n",
       "|-----------------|----------|----------|----------|----------|\n",
       "| CORE            | 0.2012   | -        | -        | -        |\n",
       "| ARC-Challenge   | -        | 0.3319   | 0.3183   | -        |\n",
       "| ARC-Easy        | -        | 0.4318   | 0.4436   | -        |\n",
       "| GSM8K           | -        | 0.0341   | 0.0500   | 0.0879   |\n",
       "| HumanEval       | -        | 0.0671   | 0.0610   | -        |\n",
       "| MMLU            | -        | 0.3307   | 0.3226   | -        |\n",
       "| ChatCORE        | -        | 0.2568   | 0.2549   | -        |\n",
       "\n",
       "Total wall clock time: 35h19m\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(open('report.md').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683d355-f8dd-4f42-95c2-e4f45ccd9f71",
   "metadata": {},
   "source": [
    "^ Why is it only filling in GSM8K for RL column? I can see the info was collected above.\n",
    "\n",
    "Changed in `my_report.py` and will run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68181b07-01f2-4484-a93f-a226382bdb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report to /home/ubuntu/mynanochat/report/report.md\n",
      "Warning: /home/ubuntu/mynanochat/report/tokenizer-training.md does not exist, skipping\n",
      "Warning: /home/ubuntu/mynanochat/report/tokenizer-evaluation.md does not exist, skipping\n",
      "Warning: /home/ubuntu/mynanochat/report/base-model-training.md does not exist, skipping\n",
      "Warning: /home/ubuntu/mynanochat/report/midtraining.md does not exist, skipping\n",
      "Warning: /home/ubuntu/mynanochat/report/chat-sft.md does not exist, skipping\n",
      "Copying report.md to current directory for convenience\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\"\n",
    "!python -m my_nanochat.my_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77189b35-1cc5-46af-b615-6e75a55b50b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# nanochat training report\n",
       "\n",
       "Generated: 2025-11-25 01:35:30\n",
       "\n",
       "## Environment\n",
       "\n",
       "### Git Information\n",
       "- Branch: master\n",
       "- Commit: 2cf49d1 (dirty)\n",
       "- Message: challenge 34: understand and add reporting - preparing to run evaluations on gpu\n",
       "\n",
       "### Hardware\n",
       "- Platform: Linux\n",
       "- CPUs: 104 cores (208 logical)\n",
       "- Memory: 1771.7 GB\n",
       "- GPUs: 8x NVIDIA H100 80GB HBM3\n",
       "- GPU Memory: 633.5 GB total\n",
       "- CUDA Version: 12.8\n",
       "\n",
       "### Software\n",
       "- Python: 3.10.12\n",
       "- PyTorch: 2.9.0+cu128\n",
       "\n",
       "Run started: 2025-11-25 01:35:33\n",
       "\n",
       "--\n",
       "\n",
       "## Base model loss\n",
       "timestamp: 2025-11-25 01:36:04\n",
       "\n",
       "- train bpb: 0.8164\n",
       "- val bpb: 0.8136\n",
       "- sample 0: <|bos|>The capital of France is Paris. It is the largest city in France and the second largest city in Europe\n",
       "- sample 1: <|bos|>The chemical symbol of gold is Au. It is a soft, malleable, ductile, and ductilely reactive metal\n",
       "- sample 2: <|bos|>If yesterday was Friday, then tomorrow will be Monday. If tomorrow is Monday, then tomorrow will be Tuesday. If tomorrow is\n",
       "- sample 3: <|bos|>The opposite of hot is cold. The opposite of cold is hot. The opposite of hot is cold.\n",
       "- sample 4: <|bos|>The planets of the solar system are: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune,\n",
       "- sample 5: <|bos|>My favorite color is red. It is the color of the blood of the martyrs. It is the\n",
       "- sample 6: <|bos|>If 5*x + 3 = 13, then x is a factor of 5. If 5*x + 3 = \n",
       "\n",
       "\n",
       "## Base model evaluation\n",
       "timestamp: 2025-11-25 01:39:38\n",
       "\n",
       "- Model: base_model (step 21400)\n",
       "- CORE metric: 0.2012\n",
       "- hellaswag_zeroshot: 0.2567\n",
       "- jeopardy: 0.1186\n",
       "- bigbench_qa_wikidata: 0.5366\n",
       "- arc_easy: 0.5292\n",
       "- arc_challenge: 0.1354\n",
       "- copa: 0.3800\n",
       "- commonsense_qa: 0.0377\n",
       "- piqa: 0.3591\n",
       "- openbook_qa: 0.1467\n",
       "- lambada_openai: 0.3745\n",
       "- hellaswag: 0.2628\n",
       "- winograd: 0.2821\n",
       "- winogrande: 0.0560\n",
       "- bigbench_dyck_languages: 0.1020\n",
       "- agi_eval_lsat_ar: 0.0272\n",
       "- bigbench_cs_algorithms: 0.3583\n",
       "- bigbench_operators: 0.1667\n",
       "- bigbench_repeat_copy_logic: 0.0000\n",
       "- squad: 0.2345\n",
       "- coqa: 0.1813\n",
       "- boolq: -0.2973\n",
       "- bigbench_language_identification: 0.1782\n",
       "\n",
       "\n",
       "## Chat evaluation mid\n",
       "timestamp: 2025-11-25 01:48:21\n",
       "\n",
       "- source: mid\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 8\n",
       "- model_tag: d20\n",
       "- step: None\n",
       "- max_problems: None\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.4318\n",
       "- ARC-Challenge: 0.3319\n",
       "- MMLU: 0.3307\n",
       "- GSM8K: 0.0341\n",
       "- HumanEval: 0.0671\n",
       "- SpellingBee: 0.9805\n",
       "- ChatCORE metric: 0.2568\n",
       "\n",
       "\n",
       "## Chat evaluation sft\n",
       "timestamp: 2025-11-25 01:55:32\n",
       "\n",
       "- source: sft\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 8\n",
       "- model_tag: d20\n",
       "- step: None\n",
       "- max_problems: None\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.4436\n",
       "- ARC-Challenge: 0.3183\n",
       "- MMLU: 0.3226\n",
       "- GSM8K: 0.0500\n",
       "- HumanEval: 0.0610\n",
       "- SpellingBee: 0.9727\n",
       "- ChatCORE metric: 0.2549\n",
       "\n",
       "\n",
       "## Chat RL\n",
       "timestamp: 2025-11-26 12:48:36\n",
       "\n",
       "- run: challenge-36-4\n",
       "- source: sft\n",
       "- dtype: bfloat16\n",
       "- device_type: \n",
       "- num_steps: -1\n",
       "- device_batch_size: 8\n",
       "- examples_per_step: 16\n",
       "- num_samples: 16\n",
       "- max_new_tokens: 256\n",
       "- temperature: 1.0000\n",
       "- top_k: 50\n",
       "- unembedding_lr: 0.0040\n",
       "- embedding_lr: 0.2000\n",
       "- matrix_lr: 0.0200\n",
       "- weight_decay: 0.0000\n",
       "- init_lr_frac: 0.0500\n",
       "- num_epochs: 1\n",
       "- save_every: 60\n",
       "- eval_every: 60\n",
       "- eval_examples: 400\n",
       "\n",
       "\n",
       "## Chat evaluation rl\n",
       "timestamp: 2025-11-26 12:54:38\n",
       "\n",
       "- source: rl\n",
       "- task_name: None\n",
       "- dtype: bfloat16\n",
       "- temperature: 0.0000\n",
       "- max_new_tokens: 512\n",
       "- num_samples: 1\n",
       "- top_k: 50\n",
       "- batch_size: 8\n",
       "- model_tag: d20\n",
       "- step: 240\n",
       "- max_problems: None\n",
       "- print_failed: False\n",
       "- device_type: \n",
       "- ARC-Easy: 0.4512\n",
       "- ARC-Challenge: 0.3123\n",
       "- MMLU: 0.3206\n",
       "- GSM8K: 0.0879\n",
       "- HumanEval: 0.0305\n",
       "- SpellingBee: 0.9062\n",
       "- ChatCORE metric: 0.2450\n",
       "\n",
       "\n",
       "## Summary\n",
       "\n",
       "| Metric          | BASE     | MID      | SFT      | RL       |\n",
       "|-----------------|----------|----------|----------|----------|\n",
       "| CORE            | 0.2012   | -        | -        | -        |\n",
       "| ARC-Challenge   | -        | 0.3319   | 0.3183   | 0.3123   |\n",
       "| ARC-Easy        | -        | 0.4318   | 0.4436   | 0.4512   |\n",
       "| GSM8K           | -        | 0.0341   | 0.0500   | 0.0879   |\n",
       "| HumanEval       | -        | 0.0671   | 0.0610   | 0.0305   |\n",
       "| MMLU            | -        | 0.3307   | 0.3226   | 0.3206   |\n",
       "| ChatCORE        | -        | 0.2568   | 0.2549   | 0.2450   |\n",
       "\n",
       "Total wall clock time: 35h19m\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(open('report.md').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd338f-11a9-448a-9c1f-bf5f279080bf",
   "metadata": {},
   "source": [
    "### Back on mac\n",
    "\n",
    "Was on GPU machine for 1.49 hours and spent $35.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8307aa06-2740-474e-924f-9edd449f595b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".0305 / .0610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fc8057-417a-4205-8f1b-d7ae098fba0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.004"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "164 * .0610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51b7d8a-8b31-4ac1-987d-231a56a2e09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "164 * .0305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8abb5-806e-41b9-85a5-6732fd029def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
