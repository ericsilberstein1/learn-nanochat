{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d527c565-820d-475c-8280-6283f6d09691",
   "metadata": {},
   "source": [
    "## RL train the d20 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c927e04-87e9-4eb3-833b-4764d07c693d",
   "metadata": {},
   "source": [
    "I'm going to approach this like `challenge-30-sft-train-d20/sft-train-d20.ipynb`. I'll use the 8xH100 in lambda cloud and run all the scripts from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396e3d6-bd6e-4e67-a6c0-0a0d33940880",
   "metadata": {},
   "source": [
    "Follow the instructions here to get the machine ready: `challenge-28-midtrain-d20/midtrain-d20.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1919aa-0b1a-4064-8b30-5c8bfa19f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2f2e3-b78c-42a2-afb2-1198e39dc9e2",
   "metadata": {},
   "source": [
    "### RL train with tiny number of steps\n",
    "\n",
    "Just to confirm the process runs through to completion, logs to wandb, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a015eff-977e-4b1f-9e31-1d82ad2bdfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --standalone --nproc_per_node=8 -m scripts.my_chat_rl -- \\\n",
    "--source=sft --model-tag=d20 --num-steps=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3297c137-278e-4ecc-ada7-0dfaa2314303",
   "metadata": {},
   "source": [
    "### RL train for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9811945-e06e-4768-85a0-fd60a672f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --standalone --nproc_per_node=8 -m scripts.my_chat_rl -- \\\n",
    "--source=sft --model-tag=d20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7344e61-e6f7-4443-a38c-f404903ad14b",
   "metadata": {},
   "source": [
    "### Do chat eval on RL model with GSM8K task\n",
    "\n",
    "My expectation (or at least hope) is to see accuracy go up from the centered accuracy of .05 (see `challenge-34-understand-reporting/run-evals-on-d20.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f065d-00d5-4629-b127-a83533339e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --standalone --nproc_per_node=8 -m scripts.my_chat_eval -- \\\n",
    "--source=rl --model-tag=d20 --task-name=GSM8K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5dc0f-060e-46d6-a01b-172f550441e7",
   "metadata": {},
   "source": [
    "### Rebuild final report\n",
    "\n",
    "Total time will be completely wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c601b56-2b97-4acf-9111-fe8b79f19c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m my_nanochat.my_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504fe90-1bfc-4f3b-a46e-66f550be6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(open('report.md').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
