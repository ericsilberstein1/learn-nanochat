{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4fb844-de00-4459-b225-d7fc63738640",
   "metadata": {},
   "source": [
    "## Server run notebook\n",
    "\n",
    "This is not the main notebook. See `instructions.ipynb`.\n",
    "\n",
    "I'll use this notebook to record and check things along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ade605-0222-491e-96b5-c56a8db8b9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 22 15:45:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:61:00.0 Off |                    0 |\n",
      "| N/A   39C    P0             72W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA H100 80GB HBM3          On  |   00000000:62:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             71W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA H100 80GB HBM3          On  |   00000000:63:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA H100 80GB HBM3          On  |   00000000:64:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             74W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA H100 80GB HBM3          On  |   00000000:6A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0             72W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA H100 80GB HBM3          On  |   00000000:6B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             72W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA H100 80GB HBM3          On  |   00000000:6C:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA H100 80GB HBM3          On  |   00000000:6D:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51fd9e-c493-4958-908c-d8c528219b7b",
   "metadata": {},
   "source": [
    "## hit this problem\n",
    "\n",
    "Doing the first test run. Looks like https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip is no longer accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a958c6-b861-4034-b44b-c16818dae4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rank2]:     result = func(*args)\n",
      "[rank2]:   File \"/usr/lib/python3.10/urllib/request.py\", line 643, in http_error_default\n",
      "[rank2]:     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "[rank2]: urllib.error.HTTPError: HTTP Error 403: Forbidden\n",
      "downloading https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip...\n",
      "[rank7]: Traceback (most recent call last):\n",
      "[rank7]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "[rank7]:     return _run_code(code, main_globals, None,\n",
      "[rank7]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "[rank7]:     exec(code, run_globals)\n",
      "[rank7]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_train.py\", line 205, in <module>\n",
      "[rank7]:     results = evaluate_model(orig_model, tokenizer, device, max_per_task=core_metric_max_per_task)\n",
      "[rank7]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_eval.py\", line 41, in evaluate_model\n",
      "[rank7]:     download_file_with_lock(EVAL_BUNDLE_URL, 'eval_bundle.zip', postprocess_fn=place_eval_bundle)\n",
      "[rank7]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/my_nanochat/my_common.py\", line 95, in download_file_with_lock\n",
      "[rank7]:     with urllib.request.urlopen(url) as response:\n",
      "[rank7]:   File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "[rank7]:     return opener.open(url, data, timeout)\n",
      "[rank7]:   File \"/usr/lib/python3.10/urllib/request.py\", line 525, in open\n",
      "[rank7]:     response = meth(req, response)\n",
      "[rank7]:   File \"/usr/lib/python3.10/urllib/request.py\", line 634, in http_response\n",
      "[rank7]:     response = self.parent.error(\n",
      "[rank7]:   File \"/usr/lib/python3.10/urllib/request.py\", line 563, in error\n",
      "[rank7]:     return self._call_chain(*args)\n",
      "[rank7]:   File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "[rank7]:     result = func(*args)\n",
      "[rank7]:   File \"/usr/lib/python3.10/urllib/request.py\", line 643, in http_error_default\n",
      "[rank7]:     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "[rank7]: urllib.error.HTTPError: HTTP Error 403: Forbidden\n",
      "downloading https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip...\n",
      "[rank5]: Traceback (most recent call last):\n",
      "[rank5]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "[rank5]:     return _run_code(code, main_globals, None,\n",
      "[rank5]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "[rank5]:     exec(code, run_globals)\n",
      "[rank5]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_train.py\", line 205, in <module>\n",
      "[rank5]:     results = evaluate_model(orig_model, tokenizer, device, max_per_task=core_metric_max_per_task)\n",
      "[rank5]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_eval.py\", line 41, in evaluate_model\n",
      "[rank5]:     download_file_with_lock(EVAL_BUNDLE_URL, 'eval_bundle.zip', postprocess_fn=place_eval_bundle)\n",
      "[rank5]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/my_nanochat/my_common.py\", line 95, in download_file_with_lock\n",
      "[rank5]:     with urllib.request.urlopen(url) as response:\n",
      "[rank5]:   File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "[rank5]:     return opener.open(url, data, timeout)\n",
      "[rank5]:   File \"/usr/lib/python3.10/urllib/request.py\", line 525, in open\n",
      "[rank5]:     response = meth(req, response)\n",
      "[rank5]:   File \"/usr/lib/python3.10/urllib/request.py\", line 634, in http_response\n",
      "[rank5]:     response = self.parent.error(\n",
      "[rank5]:   File \"/usr/lib/python3.10/urllib/request.py\", line 563, in error\n",
      "[rank5]:     return self._call_chain(*args)\n",
      "[rank5]:   File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "[rank5]:     result = func(*args)\n",
      "[rank5]:   File \"/usr/lib/python3.10/urllib/request.py\", line 643, in http_error_default\n",
      "[rank5]:     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "[rank5]: urllib.error.HTTPError: HTTP Error 403: Forbidden\n",
      "downloading https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip...\n",
      "[rank6]: Traceback (most recent call last):\n",
      "[rank6]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "[rank6]:     return _run_code(code, main_globals, None,\n",
      "[rank6]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "[rank6]:     exec(code, run_globals)\n",
      "[rank6]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_train.py\", line 205, in <module>\n",
      "[rank6]:     results = evaluate_model(orig_model, tokenizer, device, max_per_task=core_metric_max_per_task)\n",
      "[rank6]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_eval.py\", line 41, in evaluate_model\n",
      "[rank6]:     download_file_with_lock(EVAL_BUNDLE_URL, 'eval_bundle.zip', postprocess_fn=place_eval_bundle)\n",
      "[rank6]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/my_nanochat/my_common.py\", line 95, in download_file_with_lock\n",
      "[rank6]:     with urllib.request.urlopen(url) as response:\n",
      "[rank6]:   File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "[rank6]:     return opener.open(url, data, timeout)\n",
      "[rank6]:   File \"/usr/lib/python3.10/urllib/request.py\", line 525, in open\n",
      "[rank6]:     response = meth(req, response)\n",
      "[rank6]:   File \"/usr/lib/python3.10/urllib/request.py\", line 634, in http_response\n",
      "[rank6]:     response = self.parent.error(\n",
      "[rank6]:   File \"/usr/lib/python3.10/urllib/request.py\", line 563, in error\n",
      "[rank6]:     return self._call_chain(*args)\n",
      "[rank6]:   File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "[rank6]:     result = func(*args)\n",
      "[rank6]:   File \"/usr/lib/python3.10/urllib/request.py\", line 643, in http_error_default\n",
      "[rank6]:     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "[rank6]: urllib.error.HTTPError: HTTP Error 403: Forbidden\n",
      "downloading https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip...\n",
      "[rank3]: Traceback (most recent call last):\n",
      "[rank3]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "[rank3]:     return _run_code(code, main_globals, None,\n",
      "[rank3]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "[rank3]:     exec(code, run_globals)\n",
      "[rank3]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_train.py\", line 205, in <module>\n",
      "[rank3]:     results = evaluate_model(orig_model, tokenizer, device, max_per_task=core_metric_max_per_task)\n",
      "[rank3]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_eval.py\", line 41, in evaluate_model\n",
      "[rank3]:     download_file_with_lock(EVAL_BUNDLE_URL, 'eval_bundle.zip', postprocess_fn=place_eval_bundle)\n",
      "[rank3]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/my_nanochat/my_common.py\", line 95, in download_file_with_lock\n",
      "[rank3]:     with urllib.request.urlopen(url) as response:\n",
      "[rank3]:   File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "[rank3]:     return opener.open(url, data, timeout)\n",
      "[rank3]:   File \"/usr/lib/python3.10/urllib/request.py\", line 525, in open\n",
      "[rank3]:     response = meth(req, response)\n",
      "[rank3]:   File \"/usr/lib/python3.10/urllib/request.py\", line 634, in http_response\n",
      "[rank3]:     response = self.parent.error(\n",
      "[rank3]:   File \"/usr/lib/python3.10/urllib/request.py\", line 563, in error\n",
      "[rank3]:     return self._call_chain(*args)\n",
      "[rank3]:   File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "[rank3]:     result = func(*args)\n",
      "[rank3]:   File \"/usr/lib/python3.10/urllib/request.py\", line 643, in http_error_default\n",
      "[rank3]:     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "[rank3]: urllib.error.HTTPError: HTTP Error 403: Forbidden\n",
      "downloading https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip...\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_train.py\", line 205, in <module>\n",
      "    results = evaluate_model(orig_model, tokenizer, device, max_per_task=core_metric_max_per_task)\n",
      "  File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_eval.py\", line 41, in evaluate_model\n",
      "    download_file_with_lock(EVAL_BUNDLE_URL, 'eval_bundle.zip', postprocess_fn=place_eval_bundle)\n",
      "  File \"/home/ubuntu/learn-nanochat/my_nanochat/my_nanochat/my_common.py\", line 95, in download_file_with_lock\n",
      "    with urllib.request.urlopen(url) as response:\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 525, in open\n",
      "    response = meth(req, response)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 634, in http_response\n",
      "    response = self.parent.error(\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 563, in error\n",
      "    return self._call_chain(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/usr/lib/python3.10/urllib/request.py\", line 643, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 403: Forbidden\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "[rank0]:     return _run_code(code, main_globals, None,\n",
      "[rank0]:   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "[rank0]:     exec(code, run_globals)\n",
      "[rank0]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_train.py\", line 205, in <module>\n",
      "[rank0]:     results = evaluate_model(orig_model, tokenizer, device, max_per_task=core_metric_max_per_task)\n",
      "[rank0]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/scripts/my_base_eval.py\", line 41, in evaluate_model\n",
      "[rank0]:     download_file_with_lock(EVAL_BUNDLE_URL, 'eval_bundle.zip', postprocess_fn=place_eval_bundle)\n",
      "[rank0]:   File \"/home/ubuntu/learn-nanochat/my_nanochat/my_nanochat/my_common.py\", line 95, in download_file_with_lock\n",
      "[rank0]:     with urllib.request.urlopen(url) as response:\n",
      "[rank0]:   File \"/usr/lib/python3.10/urllib/request.py\", line 216, in urlopen\n",
      "[rank0]:     return opener.open(url, data, timeout)\n",
      "[rank0]:   File \"/usr/lib/python3.10/urllib/request.py\", line 525, in open\n",
      "[rank0]:     response = meth(req, response)\n",
      "[rank0]:   File \"/usr/lib/python3.10/urllib/request.py\", line 634, in http_response\n",
      "[rank0]:     response = self.parent.error(\n",
      "[rank0]:   File \"/usr/lib/python3.10/urllib/request.py\", line 563, in error\n",
      "[rank0]:     return self._call_chain(*args)\n",
      "[rank0]:   File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "[rank0]:     result = func(*args)\n",
      "[rank0]:   File \"/usr/lib/python3.10/urllib/request.py\", line 643, in http_error_default\n",
      "[rank0]:     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "[rank0]: urllib.error.HTTPError: HTTP Error 403: Forbidden\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mchallenge-38-1\u001b[0m at: \u001b[34m\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251222_154945-byeg46fu/logs\u001b[0m\n",
      "[rank1]:[W1222 15:52:01.322717052 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[rank4]:[W1222 15:52:01.649825257 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[rank0]:[W1222 15:52:01.719296376 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "[rank7]:[W1222 15:52:01.778273131 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[rank2]:[W1222 15:52:01.908061259 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[rank6]:[W1222 15:52:01.117893743 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[rank5]:[W1222 15:52:01.229616340 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "W1222 15:52:02.000000 21195 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 21232 closing signal SIGTERM\n",
      "W1222 15:52:02.001000 21195 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 21234 closing signal SIGTERM\n",
      "W1222 15:52:02.002000 21195 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 21235 closing signal SIGTERM\n",
      "W1222 15:52:02.002000 21195 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 21236 closing signal SIGTERM\n",
      "W1222 15:52:02.002000 21195 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 21237 closing signal SIGTERM\n",
      "W1222 15:52:02.003000 21195 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 21238 closing signal SIGTERM\n",
      "W1222 15:52:02.003000 21195 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 21239 closing signal SIGTERM\n",
      "E1222 15:52:05.223000 21195 torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 1 (pid: 21233) of binary: /home/ubuntu/learn-nanochat/.venv/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/learn-nanochat/.venv/bin/torchrun\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/distributed/run.py\", line 936, in main\n",
      "    run(args)\n",
      "  File \"/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/distributed/run.py\", line 927, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 156, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 293, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "scripts.my_base_train FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-12-22_15:52:02\n",
      "  host      : 192-222-52-230\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 21233)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!tail -200 /home/ubuntu/mynanochat2/run_outputs/base_train_output_001.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df23bad-063e-4033-bf8c-53f31764453a",
   "metadata": {},
   "source": [
    "### repeating test run\n",
    "\n",
    "...after scp'ing base_eval from my laptop\n",
    "\n",
    "logging to `base_train_output_002.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6486ab-03a9-4ca7-bf6b-4df213dc48a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb:            train/lrm ‚ñÅ\n",
      "wandb:            train/mfu ‚ñÅ\n",
      "wandb:    train/tok_per_sec ‚ñÅ\n",
      "wandb:                   +1 ...\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:          core_metric -0.02267\n",
      "wandb:                 step 10\n",
      "wandb: total_training_flops 63331869759897600\n",
      "wandb:  total_training_time 0\n",
      "wandb:             train/dt 22.59089\n",
      "wandb:      train/grad_norm 0.53604\n",
      "wandb:           train/loss 11.09035\n",
      "wandb:            train/lrm 1\n",
      "wandb:            train/mfu 3.54326\n",
      "wandb:    train/tok_per_sec 23207\n",
      "wandb:                   +1 ...\n",
      "wandb: \n",
      "wandb: üöÄ View run challenge-38-1 at: https://wandb.ai/ericsilberstein-self/my-nanochat/runs/0ie1fin2\n",
      "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ericsilberstein-self/my-nanochat\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20251222_155927-0ie1fin2/logs\n",
      "[W1222 16:01:23.002992110 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[W1222 16:01:23.007993651 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[W1222 16:01:24.529711010 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "!tail -25 /home/ubuntu/mynanochat2/run_outputs/base_train_output_002.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fc1e22-97ff-46d2-aba6-8f8737475f48",
   "metadata": {},
   "source": [
    "### confirm can load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f3494a-adfc-44c3-95da-552971a662c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_common import get_base_dir, autodetect_device_type, compute_init\n",
    "from my_nanochat.my_checkpoint_manager import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21b30aee-9aa5-4ec4-8765-0a03e6c36b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/learn-nanochat/.venv/lib/python3.10/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the model from /home/ubuntu/mynanochat2/base_checkpoints/d32 with step 10\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 32, 'n_head': 16, 'n_kv_head': 16, 'n_embd': 2048}\n"
     ]
    }
   ],
   "source": [
    "device_type = autodetect_device_type() \n",
    "_, _, _, _, device = compute_init(device_type)\n",
    "model, tokenizer, meta_data = load_model('base', model_tag='d32', device=device, phase='eval')\n",
    "autocast_ctx = torch.amp.autocast(device_type=device_type, dtype=torch.bfloat16) if device_type == \"cuda\" else nullcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2117a99-780d-4c60-a21f-57907e82ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1006, 345, 400, 311, 4236, 3328, 281, 261, 24142, 4398]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with autocast_ctx:\n",
    "    tokens = list(model.generate(tokenizer.encode(\"First take a right on Main St.\", prepend=tokenizer.get_bos_token_id()), max_tokens=10))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e939dd49-cfe5-4155-a0e0-90f134da8ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' We are can be introduced examples of the utmost background'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea6f8d-3bbc-4ea8-a2af-a52546e1cf41",
   "metadata": {},
   "source": [
    "that looks ok, also check wandb\n",
    "\n",
    "look ok, do real run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e3393-e915-4ea1-a6e3-340cab21a07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
